{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.0.0+cpu\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: c:\\users\\kavya\\onedrive\\desktop\\sem6\\btp\\code\\.venv\\lib\\site-packages\n",
      "Requires: filelock, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: torchaudio, torchvision\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpuNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting torch==2.0.0\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.0.0%2Bcpu-cp38-cp38-win_amd64.whl (174.0 MB)\n",
      "     ---------------------------------------- 0.0/174.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/174.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/174.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/174.0 MB ? eta -:--:--\n",
      "     -------------------------------------- 0.0/174.0 MB 108.9 kB/s eta 0:26:38\n",
      "     -------------------------------------- 0.1/174.0 MB 251.0 kB/s eta 0:11:34\n",
      "     -------------------------------------- 0.1/174.0 MB 251.0 kB/s eta 0:11:34\n",
      "     -------------------------------------- 0.1/174.0 MB 251.0 kB/s eta 0:11:34\n",
      "     -------------------------------------- 0.1/174.0 MB 191.1 kB/s eta 0:15:11\n",
      "     -------------------------------------- 0.1/174.0 MB 261.9 kB/s eta 0:11:05\n",
      "     -------------------------------------- 0.1/174.0 MB 261.9 kB/s eta 0:11:05\n",
      "     -------------------------------------- 0.1/174.0 MB 261.9 kB/s eta 0:11:05\n",
      "     -------------------------------------- 0.1/174.0 MB 261.9 kB/s eta 0:11:05\n",
      "     -------------------------------------- 0.4/174.0 MB 603.4 kB/s eta 0:04:48\n",
      "     -------------------------------------- 0.4/174.0 MB 603.4 kB/s eta 0:04:48\n",
      "     -------------------------------------- 0.4/174.0 MB 603.4 kB/s eta 0:04:48\n",
      "     -------------------------------------- 0.6/174.0 MB 772.6 kB/s eta 0:03:45\n",
      "     -------------------------------------- 0.6/174.0 MB 772.6 kB/s eta 0:03:45\n",
      "     -------------------------------------- 0.7/174.0 MB 747.0 kB/s eta 0:03:53\n",
      "     -------------------------------------- 0.8/174.0 MB 858.0 kB/s eta 0:03:22\n",
      "     ---------------------------------------- 1.1/174.0 MB 1.1 MB/s eta 0:02:33\n",
      "     ---------------------------------------- 1.4/174.0 MB 1.4 MB/s eta 0:02:05\n",
      "     ---------------------------------------- 1.6/174.0 MB 1.5 MB/s eta 0:01:54\n",
      "     ---------------------------------------- 1.6/174.0 MB 1.5 MB/s eta 0:01:54\n",
      "     ---------------------------------------- 1.8/174.0 MB 1.5 MB/s eta 0:01:53\n",
      "     ---------------------------------------- 2.1/174.0 MB 1.7 MB/s eta 0:01:40\n",
      "      --------------------------------------- 2.6/174.0 MB 2.0 MB/s eta 0:01:26\n",
      "      --------------------------------------- 3.0/174.0 MB 2.2 MB/s eta 0:01:18\n",
      "      --------------------------------------- 3.2/174.0 MB 2.3 MB/s eta 0:01:14\n",
      "      --------------------------------------- 3.9/174.0 MB 2.7 MB/s eta 0:01:04\n",
      "      --------------------------------------- 4.3/174.0 MB 2.8 MB/s eta 0:01:01\n",
      "     - -------------------------------------- 4.6/174.0 MB 2.9 MB/s eta 0:00:59\n",
      "     - -------------------------------------- 4.8/174.0 MB 2.9 MB/s eta 0:00:58\n",
      "     - -------------------------------------- 5.3/174.0 MB 3.1 MB/s eta 0:00:55\n",
      "     - -------------------------------------- 5.7/174.0 MB 3.2 MB/s eta 0:00:53\n",
      "     - -------------------------------------- 6.1/174.0 MB 3.3 MB/s eta 0:00:51\n",
      "     - -------------------------------------- 6.5/174.0 MB 3.4 MB/s eta 0:00:49\n",
      "     - -------------------------------------- 6.7/174.0 MB 3.4 MB/s eta 0:00:49\n",
      "     - -------------------------------------- 7.1/174.0 MB 3.5 MB/s eta 0:00:48\n",
      "     - -------------------------------------- 7.3/174.0 MB 3.6 MB/s eta 0:00:47\n",
      "     - -------------------------------------- 7.5/174.0 MB 3.7 MB/s eta 0:00:46\n",
      "     - -------------------------------------- 7.8/174.0 MB 3.7 MB/s eta 0:00:45\n",
      "     - -------------------------------------- 8.3/174.0 MB 3.8 MB/s eta 0:00:44\n",
      "     - -------------------------------------- 8.5/174.0 MB 3.8 MB/s eta 0:00:44\n",
      "     -- ------------------------------------- 8.9/174.0 MB 3.9 MB/s eta 0:00:43\n",
      "     -- ------------------------------------- 9.1/174.0 MB 3.9 MB/s eta 0:00:42\n",
      "     -- ------------------------------------- 9.5/174.0 MB 4.0 MB/s eta 0:00:42\n",
      "     -- ------------------------------------- 9.7/174.0 MB 4.0 MB/s eta 0:00:42\n",
      "     -- ------------------------------------- 9.9/174.0 MB 4.0 MB/s eta 0:00:41\n",
      "     -- ------------------------------------ 10.3/174.0 MB 4.4 MB/s eta 0:00:38\n",
      "     -- ------------------------------------ 10.4/174.0 MB 5.2 MB/s eta 0:00:32\n",
      "     -- ------------------------------------ 10.7/174.0 MB 5.5 MB/s eta 0:00:30\n",
      "     -- ------------------------------------ 11.1/174.0 MB 5.8 MB/s eta 0:00:28\n",
      "     -- ------------------------------------ 11.5/174.0 MB 5.8 MB/s eta 0:00:28\n",
      "     -- ------------------------------------ 11.7/174.0 MB 5.7 MB/s eta 0:00:29\n",
      "     -- ------------------------------------ 11.8/174.0 MB 6.0 MB/s eta 0:00:28\n",
      "     -- ------------------------------------ 12.3/174.0 MB 6.0 MB/s eta 0:00:27\n",
      "     -- ------------------------------------ 12.6/174.0 MB 5.8 MB/s eta 0:00:28\n",
      "     -- ------------------------------------ 13.0/174.0 MB 5.8 MB/s eta 0:00:28\n",
      "     -- ------------------------------------ 13.1/174.0 MB 5.7 MB/s eta 0:00:29\n",
      "     --- ----------------------------------- 13.4/174.0 MB 5.8 MB/s eta 0:00:28\n",
      "     --- ----------------------------------- 13.6/174.0 MB 5.7 MB/s eta 0:00:29\n",
      "     --- ----------------------------------- 13.7/174.0 MB 5.5 MB/s eta 0:00:29\n",
      "     --- ----------------------------------- 14.1/174.0 MB 5.5 MB/s eta 0:00:30\n",
      "     --- ----------------------------------- 14.3/174.0 MB 5.5 MB/s eta 0:00:30\n",
      "     --- ----------------------------------- 14.5/174.0 MB 5.4 MB/s eta 0:00:30\n",
      "     --- ----------------------------------- 14.6/174.0 MB 5.4 MB/s eta 0:00:30\n",
      "     --- ----------------------------------- 14.9/174.0 MB 5.4 MB/s eta 0:00:30\n",
      "     --- ----------------------------------- 15.0/174.0 MB 5.3 MB/s eta 0:00:31\n",
      "     --- ----------------------------------- 15.4/174.0 MB 5.4 MB/s eta 0:00:30\n",
      "     --- ----------------------------------- 15.7/174.0 MB 5.4 MB/s eta 0:00:30\n",
      "     --- ----------------------------------- 15.9/174.0 MB 5.3 MB/s eta 0:00:30\n",
      "     --- ----------------------------------- 16.1/174.0 MB 5.3 MB/s eta 0:00:30\n",
      "     --- ----------------------------------- 16.4/174.0 MB 5.3 MB/s eta 0:00:30\n",
      "     --- ----------------------------------- 16.7/174.0 MB 5.2 MB/s eta 0:00:31\n",
      "     --- ----------------------------------- 16.9/174.0 MB 5.2 MB/s eta 0:00:31\n",
      "     --- ----------------------------------- 17.2/174.0 MB 5.2 MB/s eta 0:00:31\n",
      "     --- ----------------------------------- 17.3/174.0 MB 5.1 MB/s eta 0:00:31\n",
      "     --- ----------------------------------- 17.6/174.0 MB 5.2 MB/s eta 0:00:31\n",
      "     ---- ---------------------------------- 18.0/174.0 MB 5.2 MB/s eta 0:00:31\n",
      "     ---- ---------------------------------- 18.5/174.0 MB 5.2 MB/s eta 0:00:30\n",
      "     ---- ---------------------------------- 18.9/174.0 MB 5.2 MB/s eta 0:00:30\n",
      "     ---- ---------------------------------- 19.2/174.0 MB 5.2 MB/s eta 0:00:31\n",
      "     ---- ---------------------------------- 19.5/174.0 MB 5.2 MB/s eta 0:00:30\n",
      "     ---- ---------------------------------- 19.8/174.0 MB 5.2 MB/s eta 0:00:30\n",
      "     ---- ---------------------------------- 20.0/174.0 MB 5.2 MB/s eta 0:00:30\n",
      "     ---- ---------------------------------- 20.4/174.0 MB 5.3 MB/s eta 0:00:30\n",
      "     ---- ---------------------------------- 20.8/174.0 MB 5.4 MB/s eta 0:00:29\n",
      "     ---- ---------------------------------- 21.0/174.0 MB 5.4 MB/s eta 0:00:29\n",
      "     ---- ---------------------------------- 21.4/174.0 MB 5.4 MB/s eta 0:00:29\n",
      "     ---- ---------------------------------- 21.7/174.0 MB 5.5 MB/s eta 0:00:28\n",
      "     ---- ---------------------------------- 22.2/174.0 MB 5.7 MB/s eta 0:00:27\n",
      "     ----- --------------------------------- 22.3/174.0 MB 5.6 MB/s eta 0:00:28\n",
      "     ----- --------------------------------- 22.8/174.0 MB 5.8 MB/s eta 0:00:26\n",
      "     ----- --------------------------------- 23.1/174.0 MB 5.8 MB/s eta 0:00:26\n",
      "     ----- --------------------------------- 23.6/174.0 MB 6.0 MB/s eta 0:00:26\n",
      "     ----- --------------------------------- 23.8/174.0 MB 6.0 MB/s eta 0:00:26\n",
      "     ----- --------------------------------- 24.3/174.0 MB 6.1 MB/s eta 0:00:25\n",
      "     ----- --------------------------------- 24.6/174.0 MB 6.2 MB/s eta 0:00:25\n",
      "     ----- --------------------------------- 25.0/174.0 MB 6.4 MB/s eta 0:00:24\n",
      "     ----- --------------------------------- 25.5/174.0 MB 6.6 MB/s eta 0:00:23\n",
      "     ----- --------------------------------- 25.9/174.0 MB 6.6 MB/s eta 0:00:23\n",
      "     ----- --------------------------------- 26.4/174.0 MB 6.7 MB/s eta 0:00:22\n",
      "     ------ -------------------------------- 26.8/174.0 MB 6.7 MB/s eta 0:00:22\n",
      "     ------ -------------------------------- 27.2/174.0 MB 7.0 MB/s eta 0:00:22\n",
      "     ------ -------------------------------- 27.5/174.0 MB 7.0 MB/s eta 0:00:21\n",
      "     ------ -------------------------------- 27.6/174.0 MB 6.9 MB/s eta 0:00:22\n",
      "     ------ -------------------------------- 28.0/174.0 MB 7.0 MB/s eta 0:00:21\n",
      "     ------ -------------------------------- 28.3/174.0 MB 6.9 MB/s eta 0:00:22\n",
      "     ------ -------------------------------- 28.6/174.0 MB 6.9 MB/s eta 0:00:22\n",
      "     ------ -------------------------------- 28.9/174.0 MB 6.9 MB/s eta 0:00:22\n",
      "     ------ -------------------------------- 29.0/174.0 MB 6.8 MB/s eta 0:00:22\n",
      "     ------ -------------------------------- 29.3/174.0 MB 6.7 MB/s eta 0:00:22\n",
      "     ------ -------------------------------- 29.6/174.0 MB 6.7 MB/s eta 0:00:22\n",
      "     ------ -------------------------------- 29.8/174.0 MB 6.7 MB/s eta 0:00:22\n",
      "     ------ -------------------------------- 29.9/174.0 MB 6.6 MB/s eta 0:00:22\n",
      "     ------ -------------------------------- 30.2/174.0 MB 6.5 MB/s eta 0:00:22\n",
      "     ------ -------------------------------- 30.5/174.0 MB 6.6 MB/s eta 0:00:22\n",
      "     ------ -------------------------------- 30.9/174.0 MB 6.5 MB/s eta 0:00:22\n",
      "     ------ -------------------------------- 31.1/174.0 MB 6.6 MB/s eta 0:00:22\n",
      "     ------- ------------------------------- 31.3/174.0 MB 6.4 MB/s eta 0:00:23\n",
      "     ------- ------------------------------- 31.5/174.0 MB 6.4 MB/s eta 0:00:23\n",
      "     ------- ------------------------------- 31.7/174.0 MB 6.3 MB/s eta 0:00:23\n",
      "     ------- ------------------------------- 32.0/174.0 MB 6.3 MB/s eta 0:00:23\n",
      "     ------- ------------------------------- 32.3/174.0 MB 6.2 MB/s eta 0:00:23\n",
      "     ------- ------------------------------- 32.5/174.0 MB 6.2 MB/s eta 0:00:23\n",
      "     ------- ------------------------------- 32.7/174.0 MB 6.1 MB/s eta 0:00:24\n",
      "     ------- ------------------------------- 32.9/174.0 MB 6.0 MB/s eta 0:00:24\n",
      "     ------- ------------------------------- 33.2/174.0 MB 6.0 MB/s eta 0:00:24\n",
      "     ------- ------------------------------- 33.3/174.0 MB 6.0 MB/s eta 0:00:24\n",
      "     ------- ------------------------------- 33.7/174.0 MB 5.9 MB/s eta 0:00:24\n",
      "     ------- ------------------------------- 34.0/174.0 MB 6.0 MB/s eta 0:00:24\n",
      "     ------- ------------------------------- 34.3/174.0 MB 5.9 MB/s eta 0:00:24\n",
      "     ------- ------------------------------- 34.6/174.0 MB 5.8 MB/s eta 0:00:25\n",
      "     ------- ------------------------------- 34.9/174.0 MB 5.8 MB/s eta 0:00:25\n",
      "     ------- ------------------------------- 35.3/174.0 MB 5.8 MB/s eta 0:00:24\n",
      "     ------- ------------------------------- 35.7/174.0 MB 5.7 MB/s eta 0:00:25\n",
      "     -------- ------------------------------ 35.9/174.0 MB 5.7 MB/s eta 0:00:25\n",
      "     -------- ------------------------------ 36.2/174.0 MB 5.8 MB/s eta 0:00:24\n",
      "     -------- ------------------------------ 36.7/174.0 MB 5.8 MB/s eta 0:00:24\n",
      "     -------- ------------------------------ 37.0/174.0 MB 5.8 MB/s eta 0:00:24\n",
      "     -------- ------------------------------ 37.2/174.0 MB 5.8 MB/s eta 0:00:24\n",
      "     -------- ------------------------------ 37.5/174.0 MB 5.7 MB/s eta 0:00:24\n",
      "     -------- ------------------------------ 38.0/174.0 MB 5.9 MB/s eta 0:00:24\n",
      "     -------- ------------------------------ 38.3/174.0 MB 5.9 MB/s eta 0:00:24\n",
      "     -------- ------------------------------ 38.6/174.0 MB 5.9 MB/s eta 0:00:23\n",
      "     -------- ------------------------------ 38.9/174.0 MB 5.9 MB/s eta 0:00:23\n",
      "     -------- ------------------------------ 39.0/174.0 MB 5.8 MB/s eta 0:00:24\n",
      "     -------- ------------------------------ 39.3/174.0 MB 5.8 MB/s eta 0:00:24\n",
      "     -------- ------------------------------ 39.6/174.0 MB 5.8 MB/s eta 0:00:24\n",
      "     -------- ------------------------------ 39.6/174.0 MB 5.8 MB/s eta 0:00:23\n",
      "     -------- ------------------------------ 39.6/174.0 MB 5.7 MB/s eta 0:00:24\n",
      "     -------- ------------------------------ 39.9/174.0 MB 5.6 MB/s eta 0:00:24\n",
      "     -------- ------------------------------ 40.0/174.0 MB 5.5 MB/s eta 0:00:25\n",
      "     -------- ------------------------------ 40.1/174.0 MB 5.5 MB/s eta 0:00:25\n",
      "     --------- ----------------------------- 40.4/174.0 MB 5.5 MB/s eta 0:00:25\n",
      "     --------- ----------------------------- 40.5/174.0 MB 5.4 MB/s eta 0:00:25\n",
      "     --------- ----------------------------- 40.9/174.0 MB 5.4 MB/s eta 0:00:25\n",
      "     --------- ----------------------------- 41.1/174.0 MB 5.3 MB/s eta 0:00:25\n",
      "     --------- ----------------------------- 41.2/174.0 MB 5.3 MB/s eta 0:00:25\n",
      "     --------- ----------------------------- 41.4/174.0 MB 5.3 MB/s eta 0:00:26\n",
      "     --------- ----------------------------- 41.7/174.0 MB 5.3 MB/s eta 0:00:26\n",
      "     --------- ----------------------------- 41.8/174.0 MB 5.2 MB/s eta 0:00:26\n",
      "     --------- ----------------------------- 42.0/174.0 MB 5.2 MB/s eta 0:00:26\n",
      "     --------- ----------------------------- 42.3/174.0 MB 5.2 MB/s eta 0:00:26\n",
      "     --------- ----------------------------- 42.5/174.0 MB 5.2 MB/s eta 0:00:26\n",
      "     --------- ----------------------------- 42.7/174.0 MB 5.2 MB/s eta 0:00:26\n",
      "     --------- ----------------------------- 42.7/174.0 MB 5.2 MB/s eta 0:00:26\n",
      "     --------- ----------------------------- 42.9/174.0 MB 5.2 MB/s eta 0:00:26\n",
      "     --------- ----------------------------- 43.1/174.0 MB 5.0 MB/s eta 0:00:27\n",
      "     --------- ----------------------------- 43.5/174.0 MB 5.2 MB/s eta 0:00:26\n",
      "     --------- ----------------------------- 43.7/174.0 MB 5.1 MB/s eta 0:00:26\n",
      "     --------- ----------------------------- 44.0/174.0 MB 5.1 MB/s eta 0:00:26\n",
      "     --------- ----------------------------- 44.1/174.0 MB 5.0 MB/s eta 0:00:26\n",
      "     --------- ----------------------------- 44.2/174.0 MB 5.0 MB/s eta 0:00:27\n",
      "     --------- ----------------------------- 44.6/174.0 MB 5.0 MB/s eta 0:00:27\n",
      "     ---------- ---------------------------- 45.0/174.0 MB 5.0 MB/s eta 0:00:27\n",
      "     ---------- ---------------------------- 45.3/174.0 MB 4.9 MB/s eta 0:00:27\n",
      "     ---------- ---------------------------- 45.5/174.0 MB 4.9 MB/s eta 0:00:27\n",
      "     ---------- ---------------------------- 46.1/174.0 MB 4.9 MB/s eta 0:00:27\n",
      "     ---------- ---------------------------- 46.1/174.0 MB 4.9 MB/s eta 0:00:27\n",
      "     ---------- ---------------------------- 46.7/174.0 MB 4.9 MB/s eta 0:00:27\n",
      "     ---------- ---------------------------- 46.9/174.0 MB 4.7 MB/s eta 0:00:27\n",
      "     ---------- ---------------------------- 47.4/174.0 MB 4.7 MB/s eta 0:00:27\n",
      "     ---------- ---------------------------- 47.9/174.0 MB 4.8 MB/s eta 0:00:27\n",
      "     ---------- ---------------------------- 48.3/174.0 MB 4.7 MB/s eta 0:00:27\n",
      "     ---------- ---------------------------- 48.7/174.0 MB 4.7 MB/s eta 0:00:27\n",
      "     ---------- ---------------------------- 49.1/174.0 MB 4.8 MB/s eta 0:00:27\n",
      "     ----------- --------------------------- 49.4/174.0 MB 4.7 MB/s eta 0:00:27\n",
      "     ----------- --------------------------- 49.9/174.0 MB 5.0 MB/s eta 0:00:25\n",
      "     ----------- --------------------------- 50.3/174.0 MB 5.2 MB/s eta 0:00:25\n",
      "     ----------- --------------------------- 50.7/174.0 MB 5.4 MB/s eta 0:00:24\n",
      "     ----------- --------------------------- 51.1/174.0 MB 5.3 MB/s eta 0:00:24\n",
      "     ----------- --------------------------- 51.6/174.0 MB 5.5 MB/s eta 0:00:23\n",
      "     ----------- --------------------------- 51.8/174.0 MB 5.4 MB/s eta 0:00:23\n",
      "     ----------- --------------------------- 52.3/174.0 MB 5.5 MB/s eta 0:00:22\n",
      "     ----------- --------------------------- 52.7/174.0 MB 5.6 MB/s eta 0:00:22\n",
      "     ----------- --------------------------- 53.0/174.0 MB 5.6 MB/s eta 0:00:22\n",
      "     ----------- --------------------------- 53.3/174.0 MB 5.8 MB/s eta 0:00:21\n",
      "     ------------ -------------------------- 53.8/174.0 MB 5.7 MB/s eta 0:00:22\n",
      "     ------------ -------------------------- 54.1/174.0 MB 5.6 MB/s eta 0:00:22\n",
      "     ------------ -------------------------- 54.3/174.0 MB 5.6 MB/s eta 0:00:22\n",
      "     ------------ -------------------------- 54.7/174.0 MB 5.6 MB/s eta 0:00:22\n",
      "     ------------ -------------------------- 54.8/174.0 MB 5.5 MB/s eta 0:00:22\n",
      "     ------------ -------------------------- 55.2/174.0 MB 5.5 MB/s eta 0:00:22\n",
      "     ------------ -------------------------- 55.6/174.0 MB 5.5 MB/s eta 0:00:22\n",
      "     ------------ -------------------------- 56.1/174.0 MB 5.4 MB/s eta 0:00:22\n",
      "     ------------ -------------------------- 56.6/174.0 MB 5.5 MB/s eta 0:00:22\n",
      "     ------------ -------------------------- 57.0/174.0 MB 5.4 MB/s eta 0:00:22\n",
      "     ------------ -------------------------- 57.4/174.0 MB 5.5 MB/s eta 0:00:22\n",
      "     ------------ -------------------------- 57.9/174.0 MB 5.5 MB/s eta 0:00:22\n",
      "     ------------- ------------------------- 58.5/174.0 MB 5.5 MB/s eta 0:00:22\n",
      "     ------------- ------------------------- 58.9/174.0 MB 5.5 MB/s eta 0:00:21\n",
      "     ------------- ------------------------- 59.4/174.0 MB 5.6 MB/s eta 0:00:21\n",
      "     ------------- ------------------------- 59.8/174.0 MB 5.6 MB/s eta 0:00:21\n",
      "     ------------- ------------------------- 60.1/174.0 MB 5.4 MB/s eta 0:00:22\n",
      "     ------------- ------------------------- 60.3/174.0 MB 5.4 MB/s eta 0:00:22\n",
      "     ------------- ------------------------- 60.8/174.0 MB 5.3 MB/s eta 0:00:22\n",
      "     ------------- ------------------------- 61.0/174.0 MB 5.3 MB/s eta 0:00:22\n",
      "     ------------- ------------------------- 61.3/174.0 MB 5.1 MB/s eta 0:00:23\n",
      "     ------------- ------------------------- 61.7/174.0 MB 5.0 MB/s eta 0:00:23\n",
      "     ------------- ------------------------- 62.0/174.0 MB 5.2 MB/s eta 0:00:22\n",
      "     ------------- ------------------------- 62.3/174.0 MB 5.1 MB/s eta 0:00:23\n",
      "     -------------- ------------------------ 62.5/174.0 MB 5.0 MB/s eta 0:00:23\n",
      "     -------------- ------------------------ 62.9/174.0 MB 4.9 MB/s eta 0:00:23\n",
      "     -------------- ------------------------ 63.3/174.0 MB 5.0 MB/s eta 0:00:23\n",
      "     -------------- ------------------------ 63.8/174.0 MB 5.1 MB/s eta 0:00:22\n",
      "     -------------- ------------------------ 64.2/174.0 MB 5.1 MB/s eta 0:00:22\n",
      "     -------------- ------------------------ 64.5/174.0 MB 5.2 MB/s eta 0:00:22\n",
      "     -------------- ------------------------ 65.1/174.0 MB 5.5 MB/s eta 0:00:20\n",
      "     -------------- ------------------------ 65.4/174.0 MB 5.5 MB/s eta 0:00:20\n",
      "     -------------- ------------------------ 65.8/174.0 MB 5.4 MB/s eta 0:00:21\n",
      "     -------------- ------------------------ 66.2/174.0 MB 5.5 MB/s eta 0:00:20\n",
      "     -------------- ------------------------ 66.7/174.0 MB 5.4 MB/s eta 0:00:20\n",
      "     --------------- ----------------------- 67.1/174.0 MB 5.5 MB/s eta 0:00:20\n",
      "     --------------- ----------------------- 67.6/174.0 MB 5.4 MB/s eta 0:00:20\n",
      "     --------------- ----------------------- 68.1/174.0 MB 5.5 MB/s eta 0:00:20\n",
      "     --------------- ----------------------- 68.6/174.0 MB 5.5 MB/s eta 0:00:20\n",
      "     --------------- ----------------------- 69.0/174.0 MB 5.4 MB/s eta 0:00:20\n",
      "     --------------- ----------------------- 69.5/174.0 MB 5.5 MB/s eta 0:00:20\n",
      "     --------------- ----------------------- 70.0/174.0 MB 5.5 MB/s eta 0:00:20\n",
      "     --------------- ----------------------- 70.4/174.0 MB 5.6 MB/s eta 0:00:19\n",
      "     --------------- ----------------------- 71.1/174.0 MB 5.9 MB/s eta 0:00:18\n",
      "     ---------------- ---------------------- 71.6/174.0 MB 6.2 MB/s eta 0:00:17\n",
      "     ---------------- ---------------------- 72.1/174.0 MB 6.2 MB/s eta 0:00:17\n",
      "     ---------------- ---------------------- 72.5/174.0 MB 6.4 MB/s eta 0:00:16\n",
      "     ---------------- ---------------------- 73.0/174.0 MB 6.5 MB/s eta 0:00:16\n",
      "     ---------------- ---------------------- 73.3/174.0 MB 6.5 MB/s eta 0:00:16\n",
      "     ---------------- ---------------------- 73.7/174.0 MB 6.5 MB/s eta 0:00:16\n",
      "     ---------------- ---------------------- 74.1/174.0 MB 6.5 MB/s eta 0:00:16\n",
      "     ---------------- ---------------------- 74.5/174.0 MB 6.5 MB/s eta 0:00:16\n",
      "     ---------------- ---------------------- 74.9/174.0 MB 6.5 MB/s eta 0:00:16\n",
      "     ---------------- ---------------------- 75.4/174.0 MB 6.4 MB/s eta 0:00:16\n",
      "     ---------------- ---------------------- 75.7/174.0 MB 6.5 MB/s eta 0:00:16\n",
      "     ----------------- --------------------- 76.2/174.0 MB 6.6 MB/s eta 0:00:15\n",
      "     ----------------- --------------------- 76.5/174.0 MB 6.5 MB/s eta 0:00:15\n",
      "     ----------------- --------------------- 76.9/174.0 MB 6.6 MB/s eta 0:00:15\n",
      "     ----------------- --------------------- 77.1/174.0 MB 6.5 MB/s eta 0:00:15\n",
      "     ----------------- --------------------- 77.3/174.0 MB 6.4 MB/s eta 0:00:16\n",
      "     ----------------- --------------------- 77.7/174.0 MB 6.4 MB/s eta 0:00:16\n",
      "     ----------------- --------------------- 78.0/174.0 MB 6.3 MB/s eta 0:00:16\n",
      "     ----------------- --------------------- 78.2/174.0 MB 6.2 MB/s eta 0:00:16\n",
      "     ----------------- --------------------- 78.5/174.0 MB 6.2 MB/s eta 0:00:16\n",
      "     ----------------- --------------------- 78.8/174.0 MB 6.1 MB/s eta 0:00:16\n",
      "     ----------------- --------------------- 79.2/174.0 MB 6.0 MB/s eta 0:00:16\n",
      "     ----------------- --------------------- 79.6/174.0 MB 6.0 MB/s eta 0:00:16\n",
      "     ----------------- --------------------- 79.7/174.0 MB 5.7 MB/s eta 0:00:17\n",
      "     ----------------- --------------------- 79.7/174.0 MB 5.6 MB/s eta 0:00:17\n",
      "     ----------------- --------------------- 79.7/174.0 MB 5.5 MB/s eta 0:00:18\n",
      "     ----------------- --------------------- 79.8/174.0 MB 5.3 MB/s eta 0:00:18\n",
      "     ----------------- --------------------- 80.3/174.0 MB 5.3 MB/s eta 0:00:18\n",
      "     ------------------ -------------------- 80.8/174.0 MB 5.5 MB/s eta 0:00:18\n",
      "     ------------------ -------------------- 81.2/174.0 MB 5.3 MB/s eta 0:00:18\n",
      "     ------------------ -------------------- 81.7/174.0 MB 5.3 MB/s eta 0:00:18\n",
      "     ------------------ -------------------- 82.1/174.0 MB 5.3 MB/s eta 0:00:18\n",
      "     ------------------ -------------------- 82.7/174.0 MB 5.4 MB/s eta 0:00:17\n",
      "     ------------------ -------------------- 83.0/174.0 MB 5.4 MB/s eta 0:00:17\n",
      "     ------------------ -------------------- 83.4/174.0 MB 5.4 MB/s eta 0:00:17\n",
      "     ------------------ -------------------- 83.7/174.0 MB 5.5 MB/s eta 0:00:17\n",
      "     ------------------ -------------------- 84.0/174.0 MB 5.4 MB/s eta 0:00:17\n",
      "     ------------------ -------------------- 84.3/174.0 MB 5.3 MB/s eta 0:00:17\n",
      "     ------------------ -------------------- 84.6/174.0 MB 5.2 MB/s eta 0:00:18\n",
      "     ------------------- ------------------- 85.0/174.0 MB 5.2 MB/s eta 0:00:17\n",
      "     ------------------- ------------------- 85.3/174.0 MB 5.2 MB/s eta 0:00:17\n",
      "     ------------------- ------------------- 85.5/174.0 MB 5.2 MB/s eta 0:00:18\n",
      "     ------------------- ------------------- 86.0/174.0 MB 5.2 MB/s eta 0:00:17\n",
      "     ------------------- ------------------- 86.1/174.0 MB 5.2 MB/s eta 0:00:18\n",
      "     ------------------- ------------------- 86.4/174.0 MB 5.1 MB/s eta 0:00:18\n",
      "     ------------------- ------------------- 86.7/174.0 MB 5.1 MB/s eta 0:00:18\n",
      "     ------------------- ------------------- 87.0/174.0 MB 5.0 MB/s eta 0:00:18\n",
      "     ------------------- ------------------- 87.4/174.0 MB 5.1 MB/s eta 0:00:18\n",
      "     ------------------- ------------------- 87.7/174.0 MB 5.1 MB/s eta 0:00:18\n",
      "     ------------------- ------------------- 87.7/174.0 MB 5.1 MB/s eta 0:00:18\n",
      "     ------------------- ------------------- 87.7/174.0 MB 5.1 MB/s eta 0:00:18\n",
      "     ------------------- ------------------- 87.8/174.0 MB 4.7 MB/s eta 0:00:19\n",
      "     ------------------- ------------------- 87.9/174.0 MB 4.7 MB/s eta 0:00:19\n",
      "     ------------------- ------------------- 87.9/174.0 MB 4.7 MB/s eta 0:00:19\n",
      "     ------------------- ------------------- 88.4/174.0 MB 4.4 MB/s eta 0:00:20\n",
      "     ------------------- ------------------- 89.1/174.0 MB 4.6 MB/s eta 0:00:19\n",
      "     -------------------- ------------------ 89.7/174.0 MB 4.7 MB/s eta 0:00:19\n",
      "     -------------------- ------------------ 89.9/174.0 MB 4.7 MB/s eta 0:00:18\n",
      "     -------------------- ------------------ 90.3/174.0 MB 5.0 MB/s eta 0:00:17\n",
      "     -------------------- ------------------ 90.5/174.0 MB 5.0 MB/s eta 0:00:17\n",
      "     -------------------- ------------------ 91.3/174.0 MB 4.9 MB/s eta 0:00:17\n",
      "     -------------------- ------------------ 91.4/174.0 MB 4.8 MB/s eta 0:00:18\n",
      "     -------------------- ------------------ 91.7/174.0 MB 4.8 MB/s eta 0:00:18\n",
      "     -------------------- ------------------ 92.0/174.0 MB 4.7 MB/s eta 0:00:18\n",
      "     -------------------- ------------------ 92.0/174.0 MB 4.7 MB/s eta 0:00:18\n",
      "     -------------------- ------------------ 92.1/174.0 MB 4.5 MB/s eta 0:00:19\n",
      "     -------------------- ------------------ 92.2/174.0 MB 4.5 MB/s eta 0:00:19\n",
      "     -------------------- ------------------ 92.5/174.0 MB 4.5 MB/s eta 0:00:19\n",
      "     -------------------- ------------------ 92.7/174.0 MB 4.4 MB/s eta 0:00:19\n",
      "     -------------------- ------------------ 93.1/174.0 MB 4.4 MB/s eta 0:00:19\n",
      "     -------------------- ------------------ 93.3/174.0 MB 4.4 MB/s eta 0:00:19\n",
      "     -------------------- ------------------ 93.7/174.0 MB 4.3 MB/s eta 0:00:19\n",
      "     --------------------- ----------------- 93.9/174.0 MB 4.3 MB/s eta 0:00:19\n",
      "     --------------------- ----------------- 94.2/174.0 MB 4.4 MB/s eta 0:00:19\n",
      "     --------------------- ----------------- 94.4/174.0 MB 4.4 MB/s eta 0:00:19\n",
      "     --------------------- ----------------- 94.8/174.0 MB 4.4 MB/s eta 0:00:19\n",
      "     --------------------- ----------------- 95.0/174.0 MB 4.4 MB/s eta 0:00:19\n",
      "     --------------------- ----------------- 95.3/174.0 MB 4.3 MB/s eta 0:00:19\n",
      "     --------------------- ----------------- 95.7/174.0 MB 4.4 MB/s eta 0:00:18\n",
      "     --------------------- ----------------- 96.0/174.0 MB 4.4 MB/s eta 0:00:18\n",
      "     --------------------- ----------------- 96.3/174.0 MB 4.4 MB/s eta 0:00:18\n",
      "     --------------------- ----------------- 96.7/174.0 MB 4.5 MB/s eta 0:00:18\n",
      "     --------------------- ----------------- 96.9/174.0 MB 4.5 MB/s eta 0:00:18\n",
      "     --------------------- ----------------- 97.2/174.0 MB 4.5 MB/s eta 0:00:18\n",
      "     --------------------- ----------------- 97.6/174.0 MB 4.5 MB/s eta 0:00:17\n",
      "     --------------------- ----------------- 98.0/174.0 MB 4.5 MB/s eta 0:00:17\n",
      "     ---------------------- ---------------- 98.4/174.0 MB 5.5 MB/s eta 0:00:14\n",
      "     ---------------------- ---------------- 98.8/174.0 MB 5.4 MB/s eta 0:00:15\n",
      "     ---------------------- ---------------- 99.3/174.0 MB 5.2 MB/s eta 0:00:15\n",
      "     ---------------------- ---------------- 99.8/174.0 MB 5.2 MB/s eta 0:00:15\n",
      "     --------------------- ---------------- 100.2/174.0 MB 5.4 MB/s eta 0:00:14\n",
      "     --------------------- ---------------- 100.5/174.0 MB 5.4 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 100.9/174.0 MB 5.6 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 101.2/174.0 MB 5.4 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 101.3/174.0 MB 5.3 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 101.6/174.0 MB 5.2 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 101.9/174.0 MB 5.4 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 102.0/174.0 MB 5.3 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 102.2/174.0 MB 5.2 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 102.3/174.0 MB 5.5 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 102.5/174.0 MB 5.5 MB/s eta 0:00:13\n",
      "     ---------------------- --------------- 102.6/174.0 MB 5.4 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 102.9/174.0 MB 5.4 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 103.0/174.0 MB 5.4 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 103.3/174.0 MB 5.4 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 103.5/174.0 MB 5.3 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 103.6/174.0 MB 5.3 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 103.7/174.0 MB 5.2 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 104.0/174.0 MB 5.2 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 104.1/174.0 MB 5.1 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 104.3/174.0 MB 5.0 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 104.4/174.0 MB 5.0 MB/s eta 0:00:15\n",
      "     ---------------------- --------------- 104.6/174.0 MB 4.9 MB/s eta 0:00:15\n",
      "     ---------------------- --------------- 104.7/174.0 MB 4.8 MB/s eta 0:00:15\n",
      "     ---------------------- --------------- 104.9/174.0 MB 4.8 MB/s eta 0:00:15\n",
      "     ---------------------- --------------- 105.1/174.0 MB 4.8 MB/s eta 0:00:15\n",
      "     ---------------------- --------------- 105.2/174.0 MB 4.7 MB/s eta 0:00:15\n",
      "     ----------------------- -------------- 105.4/174.0 MB 4.6 MB/s eta 0:00:15\n",
      "     ----------------------- -------------- 105.6/174.0 MB 4.6 MB/s eta 0:00:15\n",
      "     ----------------------- -------------- 105.8/174.0 MB 4.5 MB/s eta 0:00:16\n",
      "     ----------------------- -------------- 106.1/174.0 MB 4.5 MB/s eta 0:00:16\n",
      "     ----------------------- -------------- 106.2/174.0 MB 4.5 MB/s eta 0:00:16\n",
      "     ----------------------- -------------- 106.2/174.0 MB 4.3 MB/s eta 0:00:16\n",
      "     ----------------------- -------------- 106.3/174.0 MB 4.3 MB/s eta 0:00:16\n",
      "     ----------------------- -------------- 106.5/174.0 MB 4.3 MB/s eta 0:00:16\n",
      "     ----------------------- -------------- 106.6/174.0 MB 4.2 MB/s eta 0:00:17\n",
      "     ----------------------- -------------- 106.9/174.0 MB 4.1 MB/s eta 0:00:17\n",
      "     ----------------------- -------------- 107.1/174.0 MB 4.1 MB/s eta 0:00:17\n",
      "     ----------------------- -------------- 107.2/174.0 MB 4.1 MB/s eta 0:00:17\n",
      "     ----------------------- -------------- 107.3/174.0 MB 4.0 MB/s eta 0:00:17\n",
      "     ----------------------- -------------- 107.6/174.0 MB 4.0 MB/s eta 0:00:17\n",
      "     ----------------------- -------------- 107.8/174.0 MB 4.0 MB/s eta 0:00:17\n",
      "     ----------------------- -------------- 107.9/174.0 MB 4.0 MB/s eta 0:00:17\n",
      "     ----------------------- -------------- 108.2/174.0 MB 3.9 MB/s eta 0:00:17\n",
      "     ----------------------- -------------- 108.3/174.0 MB 3.9 MB/s eta 0:00:17\n",
      "     ----------------------- -------------- 108.6/174.0 MB 3.9 MB/s eta 0:00:17\n",
      "     ----------------------- -------------- 108.8/174.0 MB 3.9 MB/s eta 0:00:17\n",
      "     ----------------------- -------------- 109.0/174.0 MB 3.9 MB/s eta 0:00:17\n",
      "     ----------------------- -------------- 109.3/174.0 MB 3.8 MB/s eta 0:00:17\n",
      "     ----------------------- -------------- 109.5/174.0 MB 3.8 MB/s eta 0:00:18\n",
      "     ----------------------- -------------- 109.8/174.0 MB 3.8 MB/s eta 0:00:18\n",
      "     ------------------------ ------------- 110.1/174.0 MB 3.8 MB/s eta 0:00:17\n",
      "     ------------------------ ------------- 110.4/174.0 MB 3.7 MB/s eta 0:00:18\n",
      "     ------------------------ ------------- 110.5/174.0 MB 3.7 MB/s eta 0:00:17\n",
      "     ------------------------ ------------- 110.7/174.0 MB 3.7 MB/s eta 0:00:17\n",
      "     ------------------------ ------------- 111.0/174.0 MB 3.7 MB/s eta 0:00:17\n",
      "     ------------------------ ------------- 111.3/174.0 MB 3.7 MB/s eta 0:00:17\n",
      "     ------------------------ ------------- 111.6/174.0 MB 3.8 MB/s eta 0:00:17\n",
      "     ------------------------ ------------- 111.8/174.0 MB 3.8 MB/s eta 0:00:17\n",
      "     ------------------------ ------------- 112.0/174.0 MB 3.8 MB/s eta 0:00:17\n",
      "     ------------------------ ------------- 112.3/174.0 MB 3.9 MB/s eta 0:00:17\n",
      "     ------------------------ ------------- 112.5/174.0 MB 3.8 MB/s eta 0:00:17\n",
      "     ------------------------ ------------- 112.7/174.0 MB 3.9 MB/s eta 0:00:16\n",
      "     ------------------------ ------------- 112.8/174.0 MB 3.9 MB/s eta 0:00:16\n",
      "     ------------------------ ------------- 113.0/174.0 MB 3.9 MB/s eta 0:00:16\n",
      "     ------------------------ ------------- 113.0/174.0 MB 3.8 MB/s eta 0:00:16\n",
      "     ------------------------ ------------- 113.4/174.0 MB 3.8 MB/s eta 0:00:16\n",
      "     ------------------------ ------------- 113.4/174.0 MB 3.8 MB/s eta 0:00:16\n",
      "     ------------------------ ------------- 113.7/174.0 MB 3.8 MB/s eta 0:00:17\n",
      "     ------------------------ ------------- 113.7/174.0 MB 3.8 MB/s eta 0:00:17\n",
      "     ------------------------ ------------- 114.0/174.0 MB 3.8 MB/s eta 0:00:16\n",
      "     ------------------------ ------------- 114.2/174.0 MB 3.7 MB/s eta 0:00:17\n",
      "     ------------------------ ------------- 114.4/174.0 MB 3.8 MB/s eta 0:00:16\n",
      "     ------------------------ ------------- 114.4/174.0 MB 3.8 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 114.7/174.0 MB 3.8 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 114.8/174.0 MB 3.8 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 114.9/174.0 MB 3.7 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 115.1/174.0 MB 3.8 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 115.3/174.0 MB 3.8 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 115.4/174.0 MB 3.8 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 115.4/174.0 MB 3.7 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 115.5/174.0 MB 3.7 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 115.6/174.0 MB 3.7 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 115.9/174.0 MB 3.7 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 116.0/174.0 MB 3.7 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 116.0/174.0 MB 3.7 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 116.2/174.0 MB 3.6 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 116.3/174.0 MB 3.6 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 116.5/174.0 MB 3.7 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 116.5/174.0 MB 3.7 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 116.7/174.0 MB 3.7 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 116.7/174.0 MB 3.7 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 116.9/174.0 MB 3.6 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 117.0/174.0 MB 3.6 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 117.2/174.0 MB 3.6 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 117.3/174.0 MB 3.6 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 117.4/174.0 MB 3.5 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 117.5/174.0 MB 3.5 MB/s eta 0:00:17\n",
      "     ------------------------- ------------ 117.7/174.0 MB 3.5 MB/s eta 0:00:17\n",
      "     ------------------------- ------------ 117.7/174.0 MB 3.4 MB/s eta 0:00:17\n",
      "     ------------------------- ------------ 117.9/174.0 MB 3.4 MB/s eta 0:00:17\n",
      "     ------------------------- ------------ 118.0/174.0 MB 3.4 MB/s eta 0:00:17\n",
      "     ------------------------- ------------ 118.0/174.0 MB 3.4 MB/s eta 0:00:17\n",
      "     ------------------------- ------------ 118.1/174.0 MB 3.3 MB/s eta 0:00:17\n",
      "     ------------------------- ------------ 118.3/174.0 MB 3.3 MB/s eta 0:00:17\n",
      "     ------------------------- ------------ 118.4/174.0 MB 3.3 MB/s eta 0:00:17\n",
      "     ------------------------- ------------ 118.4/174.0 MB 3.3 MB/s eta 0:00:18\n",
      "     ------------------------- ------------ 118.5/174.0 MB 3.2 MB/s eta 0:00:18\n",
      "     ------------------------- ------------ 118.7/174.0 MB 3.2 MB/s eta 0:00:18\n",
      "     ------------------------- ------------ 118.8/174.0 MB 3.2 MB/s eta 0:00:18\n",
      "     ------------------------- ------------ 118.9/174.0 MB 3.2 MB/s eta 0:00:18\n",
      "     ------------------------- ------------ 119.0/174.0 MB 3.1 MB/s eta 0:00:18\n",
      "     ------------------------- ------------ 119.1/174.0 MB 3.1 MB/s eta 0:00:18\n",
      "     -------------------------- ----------- 119.1/174.0 MB 3.1 MB/s eta 0:00:18\n",
      "     -------------------------- ----------- 119.3/174.0 MB 3.1 MB/s eta 0:00:18\n",
      "     -------------------------- ----------- 119.4/174.0 MB 3.0 MB/s eta 0:00:19\n",
      "     -------------------------- ----------- 119.5/174.0 MB 3.0 MB/s eta 0:00:19\n",
      "     -------------------------- ----------- 119.6/174.0 MB 3.0 MB/s eta 0:00:19\n",
      "     -------------------------- ----------- 119.7/174.0 MB 2.9 MB/s eta 0:00:19\n",
      "     -------------------------- ----------- 119.8/174.0 MB 3.0 MB/s eta 0:00:19\n",
      "     -------------------------- ----------- 119.9/174.0 MB 2.9 MB/s eta 0:00:19\n",
      "     -------------------------- ----------- 120.0/174.0 MB 2.9 MB/s eta 0:00:19\n",
      "     -------------------------- ----------- 120.1/174.0 MB 2.9 MB/s eta 0:00:19\n",
      "     -------------------------- ----------- 120.2/174.0 MB 2.9 MB/s eta 0:00:19\n",
      "     -------------------------- ----------- 120.3/174.0 MB 2.8 MB/s eta 0:00:19\n",
      "     -------------------------- ----------- 120.4/174.0 MB 2.8 MB/s eta 0:00:20\n",
      "     -------------------------- ----------- 120.4/174.0 MB 2.8 MB/s eta 0:00:20\n",
      "     -------------------------- ----------- 120.5/174.0 MB 2.8 MB/s eta 0:00:20\n",
      "     -------------------------- ----------- 120.6/174.0 MB 2.7 MB/s eta 0:00:20\n",
      "     -------------------------- ----------- 120.7/174.0 MB 2.7 MB/s eta 0:00:20\n",
      "     -------------------------- ----------- 120.9/174.0 MB 2.7 MB/s eta 0:00:20\n",
      "     -------------------------- ----------- 121.0/174.0 MB 2.7 MB/s eta 0:00:20\n",
      "     -------------------------- ----------- 121.1/174.0 MB 2.7 MB/s eta 0:00:20\n",
      "     -------------------------- ----------- 121.2/174.0 MB 2.7 MB/s eta 0:00:20\n",
      "     -------------------------- ----------- 121.3/174.0 MB 2.7 MB/s eta 0:00:20\n",
      "     -------------------------- ----------- 121.4/174.0 MB 2.6 MB/s eta 0:00:21\n",
      "     -------------------------- ----------- 121.5/174.0 MB 2.6 MB/s eta 0:00:21\n",
      "     -------------------------- ----------- 121.7/174.0 MB 2.6 MB/s eta 0:00:21\n",
      "     -------------------------- ----------- 121.8/174.0 MB 2.5 MB/s eta 0:00:21\n",
      "     -------------------------- ----------- 121.9/174.0 MB 2.5 MB/s eta 0:00:21\n",
      "     -------------------------- ----------- 122.1/174.0 MB 2.5 MB/s eta 0:00:21\n",
      "     -------------------------- ----------- 122.2/174.0 MB 2.5 MB/s eta 0:00:21\n",
      "     -------------------------- ----------- 122.3/174.0 MB 2.5 MB/s eta 0:00:21\n",
      "     -------------------------- ----------- 122.4/174.0 MB 2.5 MB/s eta 0:00:21\n",
      "     -------------------------- ----------- 122.7/174.0 MB 2.5 MB/s eta 0:00:21\n",
      "     -------------------------- ----------- 122.8/174.0 MB 2.5 MB/s eta 0:00:21\n",
      "     -------------------------- ----------- 123.0/174.0 MB 2.5 MB/s eta 0:00:21\n",
      "     -------------------------- ----------- 123.1/174.0 MB 2.5 MB/s eta 0:00:21\n",
      "     -------------------------- ----------- 123.4/174.0 MB 2.5 MB/s eta 0:00:21\n",
      "     -------------------------- ----------- 123.5/174.0 MB 2.5 MB/s eta 0:00:21\n",
      "     --------------------------- ---------- 123.7/174.0 MB 2.5 MB/s eta 0:00:20\n",
      "     --------------------------- ---------- 123.9/174.0 MB 2.6 MB/s eta 0:00:20\n",
      "     --------------------------- ---------- 124.1/174.0 MB 2.6 MB/s eta 0:00:20\n",
      "     --------------------------- ---------- 124.4/174.0 MB 2.6 MB/s eta 0:00:20\n",
      "     --------------------------- ---------- 124.6/174.0 MB 2.6 MB/s eta 0:00:20\n",
      "     --------------------------- ---------- 124.8/174.0 MB 2.6 MB/s eta 0:00:19\n",
      "     --------------------------- ---------- 125.0/174.0 MB 2.6 MB/s eta 0:00:19\n",
      "     --------------------------- ---------- 125.2/174.0 MB 2.7 MB/s eta 0:00:19\n",
      "     --------------------------- ---------- 125.6/174.0 MB 2.7 MB/s eta 0:00:19\n",
      "     --------------------------- ---------- 125.7/174.0 MB 2.7 MB/s eta 0:00:18\n",
      "     --------------------------- ---------- 126.0/174.0 MB 2.8 MB/s eta 0:00:18\n",
      "     --------------------------- ---------- 126.3/174.0 MB 2.8 MB/s eta 0:00:18\n",
      "     --------------------------- ---------- 126.6/174.0 MB 2.9 MB/s eta 0:00:17\n",
      "     --------------------------- ---------- 126.9/174.0 MB 2.9 MB/s eta 0:00:17\n",
      "     --------------------------- ---------- 127.2/174.0 MB 3.0 MB/s eta 0:00:16\n",
      "     --------------------------- ---------- 127.4/174.0 MB 3.0 MB/s eta 0:00:16\n",
      "     --------------------------- ---------- 127.7/174.0 MB 3.1 MB/s eta 0:00:15\n",
      "     --------------------------- ---------- 127.9/174.0 MB 3.2 MB/s eta 0:00:15\n",
      "     ---------------------------- --------- 128.3/174.0 MB 3.3 MB/s eta 0:00:14\n",
      "     ---------------------------- --------- 128.5/174.0 MB 3.4 MB/s eta 0:00:14\n",
      "     ---------------------------- --------- 128.8/174.0 MB 3.5 MB/s eta 0:00:13\n",
      "     ---------------------------- --------- 129.1/174.0 MB 3.6 MB/s eta 0:00:13\n",
      "     ---------------------------- --------- 129.2/174.0 MB 3.6 MB/s eta 0:00:13\n",
      "     ---------------------------- --------- 129.5/174.0 MB 3.7 MB/s eta 0:00:13\n",
      "     ---------------------------- --------- 129.6/174.0 MB 3.7 MB/s eta 0:00:12\n",
      "     ---------------------------- --------- 129.9/174.0 MB 3.8 MB/s eta 0:00:12\n",
      "     ---------------------------- --------- 130.1/174.0 MB 3.9 MB/s eta 0:00:12\n",
      "     ---------------------------- --------- 130.1/174.0 MB 3.9 MB/s eta 0:00:12\n",
      "     ---------------------------- --------- 130.4/174.0 MB 4.0 MB/s eta 0:00:11\n",
      "     ---------------------------- --------- 130.6/174.0 MB 4.0 MB/s eta 0:00:11\n",
      "     ---------------------------- --------- 130.8/174.0 MB 4.2 MB/s eta 0:00:11\n",
      "     ---------------------------- --------- 131.1/174.0 MB 4.2 MB/s eta 0:00:11\n",
      "     ---------------------------- --------- 131.4/174.0 MB 4.3 MB/s eta 0:00:10\n",
      "     ---------------------------- --------- 131.6/174.0 MB 4.5 MB/s eta 0:00:10\n",
      "     ---------------------------- --------- 132.0/174.0 MB 4.7 MB/s eta 0:00:09\n",
      "     ---------------------------- --------- 132.2/174.0 MB 4.6 MB/s eta 0:00:10\n",
      "     ---------------------------- --------- 132.6/174.0 MB 4.8 MB/s eta 0:00:09\n",
      "     ----------------------------- -------- 132.9/174.0 MB 4.8 MB/s eta 0:00:09\n",
      "     ----------------------------- -------- 133.2/174.0 MB 5.0 MB/s eta 0:00:09\n",
      "     ----------------------------- -------- 133.4/174.0 MB 5.0 MB/s eta 0:00:09\n",
      "     ----------------------------- -------- 133.7/174.0 MB 5.0 MB/s eta 0:00:09\n",
      "     ----------------------------- -------- 133.9/174.0 MB 5.0 MB/s eta 0:00:09\n",
      "     ----------------------------- -------- 134.1/174.0 MB 4.9 MB/s eta 0:00:09\n",
      "     ----------------------------- -------- 134.2/174.0 MB 4.9 MB/s eta 0:00:09\n",
      "     ----------------------------- -------- 134.4/174.0 MB 4.9 MB/s eta 0:00:09\n",
      "     ----------------------------- -------- 134.8/174.0 MB 4.9 MB/s eta 0:00:09\n",
      "     ----------------------------- -------- 135.1/174.0 MB 4.9 MB/s eta 0:00:08\n",
      "     ----------------------------- -------- 135.5/174.0 MB 4.9 MB/s eta 0:00:08\n",
      "     ----------------------------- -------- 135.7/174.0 MB 4.8 MB/s eta 0:00:08\n",
      "     ----------------------------- -------- 136.0/174.0 MB 4.8 MB/s eta 0:00:08\n",
      "     ----------------------------- -------- 136.1/174.0 MB 4.8 MB/s eta 0:00:08\n",
      "     ----------------------------- -------- 136.4/174.0 MB 4.8 MB/s eta 0:00:08\n",
      "     ----------------------------- -------- 136.6/174.0 MB 4.7 MB/s eta 0:00:08\n",
      "     ----------------------------- -------- 136.8/174.0 MB 4.6 MB/s eta 0:00:09\n",
      "     ----------------------------- -------- 137.1/174.0 MB 4.7 MB/s eta 0:00:08\n",
      "     ----------------------------- -------- 137.2/174.0 MB 4.6 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 137.6/174.0 MB 4.6 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 137.7/174.0 MB 4.5 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 137.9/174.0 MB 4.5 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 138.1/174.0 MB 4.6 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 138.4/174.0 MB 4.5 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 138.6/174.0 MB 4.5 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 138.9/174.0 MB 4.5 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 139.2/174.0 MB 4.5 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 139.5/174.0 MB 4.6 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 139.8/174.0 MB 4.5 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 139.9/174.0 MB 4.5 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 140.2/174.0 MB 4.5 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 140.9/174.0 MB 4.7 MB/s eta 0:00:07\n",
      "     ------------------------------ ------- 141.2/174.0 MB 4.8 MB/s eta 0:00:07\n",
      "     ------------------------------ ------- 141.5/174.0 MB 4.8 MB/s eta 0:00:07\n",
      "     ------------------------------ ------- 141.8/174.0 MB 4.8 MB/s eta 0:00:07\n",
      "     ------------------------------- ------ 142.2/174.0 MB 4.8 MB/s eta 0:00:07\n",
      "     ------------------------------- ------ 142.5/174.0 MB 4.9 MB/s eta 0:00:07\n",
      "     ------------------------------- ------ 143.0/174.0 MB 4.9 MB/s eta 0:00:07\n",
      "     ------------------------------- ------ 143.4/174.0 MB 5.0 MB/s eta 0:00:07\n",
      "     ------------------------------- ------ 143.8/174.0 MB 5.1 MB/s eta 0:00:06\n",
      "     ------------------------------- ------ 144.1/174.0 MB 5.1 MB/s eta 0:00:06\n",
      "     ------------------------------- ------ 144.3/174.0 MB 5.3 MB/s eta 0:00:06\n",
      "     ------------------------------- ------ 144.6/174.0 MB 5.3 MB/s eta 0:00:06\n",
      "     ------------------------------- ------ 144.9/174.0 MB 5.4 MB/s eta 0:00:06\n",
      "     ------------------------------- ------ 145.2/174.0 MB 5.4 MB/s eta 0:00:06\n",
      "     ------------------------------- ------ 145.5/174.0 MB 5.4 MB/s eta 0:00:06\n",
      "     ------------------------------- ------ 145.5/174.0 MB 5.3 MB/s eta 0:00:06\n",
      "     ------------------------------- ------ 145.8/174.0 MB 5.3 MB/s eta 0:00:06\n",
      "     ------------------------------- ------ 145.8/174.0 MB 5.2 MB/s eta 0:00:06\n",
      "     ------------------------------- ------ 146.1/174.0 MB 5.2 MB/s eta 0:00:06\n",
      "     ------------------------------- ------ 146.3/174.0 MB 5.3 MB/s eta 0:00:06\n",
      "     ------------------------------- ------ 146.4/174.0 MB 5.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 146.6/174.0 MB 5.3 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 146.8/174.0 MB 5.2 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 146.8/174.0 MB 5.2 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 147.2/174.0 MB 5.2 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 147.4/174.0 MB 5.2 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 147.8/174.0 MB 5.3 MB/s eta 0:00:05\n",
      "     -------------------------------- ----- 148.0/174.0 MB 5.3 MB/s eta 0:00:05\n",
      "     -------------------------------- ----- 148.3/174.0 MB 5.4 MB/s eta 0:00:05\n",
      "     -------------------------------- ----- 148.4/174.0 MB 5.4 MB/s eta 0:00:05\n",
      "     -------------------------------- ----- 148.4/174.0 MB 5.4 MB/s eta 0:00:05\n",
      "     -------------------------------- ----- 148.4/174.0 MB 5.2 MB/s eta 0:00:05\n",
      "     -------------------------------- ----- 148.5/174.0 MB 5.0 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 148.5/174.0 MB 4.8 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 148.8/174.0 MB 4.8 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 149.2/174.0 MB 4.7 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 149.6/174.0 MB 4.8 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 149.8/174.0 MB 4.7 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 150.1/174.0 MB 4.8 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 150.3/174.0 MB 4.8 MB/s eta 0:00:05\n",
      "     -------------------------------- ----- 150.6/174.0 MB 4.7 MB/s eta 0:00:05\n",
      "     -------------------------------- ----- 150.9/174.0 MB 4.7 MB/s eta 0:00:05\n",
      "     --------------------------------- ---- 151.2/174.0 MB 4.7 MB/s eta 0:00:05\n",
      "     --------------------------------- ---- 151.3/174.0 MB 4.6 MB/s eta 0:00:05\n",
      "     --------------------------------- ---- 151.7/174.0 MB 4.8 MB/s eta 0:00:05\n",
      "     --------------------------------- ---- 152.0/174.0 MB 4.7 MB/s eta 0:00:05\n",
      "     --------------------------------- ---- 152.4/174.0 MB 4.7 MB/s eta 0:00:05\n",
      "     --------------------------------- ---- 152.8/174.0 MB 4.7 MB/s eta 0:00:05\n",
      "     --------------------------------- ---- 153.2/174.0 MB 4.7 MB/s eta 0:00:05\n",
      "     --------------------------------- ---- 153.6/174.0 MB 4.7 MB/s eta 0:00:05\n",
      "     --------------------------------- ---- 153.9/174.0 MB 4.6 MB/s eta 0:00:05\n",
      "     --------------------------------- ---- 154.3/174.0 MB 4.7 MB/s eta 0:00:05\n",
      "     --------------------------------- ---- 154.8/174.0 MB 4.7 MB/s eta 0:00:05\n",
      "     --------------------------------- ---- 155.2/174.0 MB 4.7 MB/s eta 0:00:04\n",
      "     --------------------------------- ---- 155.4/174.0 MB 4.7 MB/s eta 0:00:04\n",
      "     --------------------------------- ---- 155.7/174.0 MB 4.7 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 156.0/174.0 MB 5.0 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 156.5/174.0 MB 5.0 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 156.9/174.0 MB 5.2 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 157.3/174.0 MB 5.3 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 157.6/174.0 MB 5.3 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 158.1/174.0 MB 5.4 MB/s eta 0:00:03\n",
      "     ---------------------------------- --- 158.4/174.0 MB 5.5 MB/s eta 0:00:03\n",
      "     ---------------------------------- --- 158.6/174.0 MB 5.5 MB/s eta 0:00:03\n",
      "     ---------------------------------- --- 159.2/174.0 MB 6.5 MB/s eta 0:00:03\n",
      "     ---------------------------------- --- 159.5/174.0 MB 6.6 MB/s eta 0:00:03\n",
      "     ---------------------------------- --- 159.9/174.0 MB 6.8 MB/s eta 0:00:03\n",
      "     ---------------------------------- --- 160.2/174.0 MB 6.8 MB/s eta 0:00:03\n",
      "     ----------------------------------- -- 160.5/174.0 MB 6.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 160.8/174.0 MB 7.0 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 161.2/174.0 MB 7.0 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 161.5/174.0 MB 7.0 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 161.8/174.0 MB 6.9 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 161.9/174.0 MB 6.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 162.0/174.0 MB 6.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 162.0/174.0 MB 6.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 162.3/174.0 MB 6.5 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 162.4/174.0 MB 6.4 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 162.4/174.0 MB 6.4 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 162.7/174.0 MB 6.3 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 162.8/174.0 MB 6.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 163.0/174.0 MB 6.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 163.2/174.0 MB 6.0 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 163.4/174.0 MB 6.0 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 163.5/174.0 MB 6.0 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 163.8/174.0 MB 5.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 164.0/174.0 MB 5.7 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 164.2/174.0 MB 5.7 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 164.4/174.0 MB 5.6 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 164.6/174.0 MB 5.6 MB/s eta 0:00:02\n",
      "     ----------------------------------- -- 164.7/174.0 MB 5.5 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 164.9/174.0 MB 5.5 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 165.2/174.0 MB 5.4 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 165.3/174.0 MB 5.4 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 165.6/174.0 MB 5.4 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 165.7/174.0 MB 5.3 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 166.0/174.0 MB 5.3 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 166.2/174.0 MB 5.2 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 166.4/174.0 MB 5.2 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 166.6/174.0 MB 5.2 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 166.9/174.0 MB 5.1 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 167.1/174.0 MB 5.0 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 167.2/174.0 MB 5.0 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 167.5/174.0 MB 5.0 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 167.6/174.0 MB 4.9 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 167.9/174.0 MB 4.8 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 168.0/174.0 MB 4.8 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 168.2/174.0 MB 4.7 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 168.3/174.0 MB 4.7 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 168.6/174.0 MB 4.6 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 168.9/174.0 MB 4.6 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 169.1/174.0 MB 4.6 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 169.4/174.0 MB 4.5 MB/s eta 0:00:02\n",
      "     -------------------------------------  169.5/174.0 MB 4.5 MB/s eta 0:00:02\n",
      "     -------------------------------------  169.8/174.0 MB 4.5 MB/s eta 0:00:01\n",
      "     -------------------------------------  170.1/174.0 MB 4.5 MB/s eta 0:00:01\n",
      "     -------------------------------------  170.3/174.0 MB 4.5 MB/s eta 0:00:01\n",
      "     -------------------------------------  170.7/174.0 MB 4.4 MB/s eta 0:00:01\n",
      "     -------------------------------------  171.1/174.0 MB 4.4 MB/s eta 0:00:01\n",
      "     -------------------------------------  171.2/174.0 MB 4.3 MB/s eta 0:00:01\n",
      "     -------------------------------------  171.6/174.0 MB 4.3 MB/s eta 0:00:01\n",
      "     -------------------------------------  171.8/174.0 MB 4.3 MB/s eta 0:00:01\n",
      "     -------------------------------------  172.0/174.0 MB 4.3 MB/s eta 0:00:01\n",
      "     -------------------------------------  172.3/174.0 MB 4.5 MB/s eta 0:00:01\n",
      "     -------------------------------------  172.4/174.0 MB 4.4 MB/s eta 0:00:01\n",
      "     -------------------------------------  172.7/174.0 MB 4.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  172.9/174.0 MB 4.5 MB/s eta 0:00:01\n",
      "     -------------------------------------  173.2/174.0 MB 4.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  173.5/174.0 MB 4.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  173.6/174.0 MB 4.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  173.9/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  174.0/174.0 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 174.0/174.0 MB 3.2 MB/s eta 0:00:00\n",
      "Collecting torchvision==0.15.1\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.15.1%2Bcpu-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.1/1.2 MB 273.8 kB/s eta 0:00:05\n",
      "     -- ------------------------------------- 0.1/1.2 MB 273.8 kB/s eta 0:00:05\n",
      "     -- ------------------------------------- 0.1/1.2 MB 273.8 kB/s eta 0:00:05\n",
      "     -- ------------------------------------- 0.1/1.2 MB 273.8 kB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 0.1/1.2 MB 291.9 kB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 0.1/1.2 MB 291.9 kB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 0.1/1.2 MB 291.9 kB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 0.1/1.2 MB 291.9 kB/s eta 0:00:04\n",
      "     --------- ------------------------------ 0.3/1.2 MB 466.2 kB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 0.3/1.2 MB 487.6 kB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 0.3/1.2 MB 487.6 kB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 0.3/1.2 MB 487.6 kB/s eta 0:00:02\n",
      "     -------------- ------------------------- 0.4/1.2 MB 527.4 kB/s eta 0:00:02\n",
      "     -------------------- ------------------- 0.6/1.2 MB 704.5 kB/s eta 0:00:01\n",
      "     --------------------- ------------------ 0.6/1.2 MB 753.1 kB/s eta 0:00:01\n",
      "     --------------------- ------------------ 0.6/1.2 MB 753.1 kB/s eta 0:00:01\n",
      "     ------------------------- -------------- 0.8/1.2 MB 759.7 kB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.0/1.2 MB 953.5 kB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.1/1.2 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.2/1.2 MB 1.0 MB/s eta 0:00:00\n",
      "Collecting torchaudio==2.0.1\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.0.1%2Bcpu-cp38-cp38-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.1/2.1 MB 3.5 MB/s eta 0:00:01\n",
      "     ----- ---------------------------------- 0.3/2.1 MB 3.2 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 0.5/2.1 MB 3.3 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 0.7/2.1 MB 3.7 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 0.9/2.1 MB 3.9 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 1.2/2.1 MB 4.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.4/2.1 MB 4.3 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.7/2.1 MB 4.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 1.9/2.1 MB 4.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.1/2.1 MB 4.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.1/2.1 MB 4.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\kavya\\onedrive\\desktop\\sem6\\btp\\code\\.venv\\lib\\site-packages (from torch==2.0.0) (3.16.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kavya\\onedrive\\desktop\\sem6\\btp\\code\\.venv\\lib\\site-packages (from torch==2.0.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\kavya\\onedrive\\desktop\\sem6\\btp\\code\\.venv\\lib\\site-packages (from torch==2.0.0) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kavya\\onedrive\\desktop\\sem6\\btp\\code\\.venv\\lib\\site-packages (from torch==2.0.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kavya\\onedrive\\desktop\\sem6\\btp\\code\\.venv\\lib\\site-packages (from torch==2.0.0) (3.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\kavya\\onedrive\\desktop\\sem6\\btp\\code\\.venv\\lib\\site-packages (from torchvision==0.15.1) (1.23.5)\n",
      "Requirement already satisfied: requests in c:\\users\\kavya\\onedrive\\desktop\\sem6\\btp\\code\\.venv\\lib\\site-packages (from torchvision==0.15.1) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\kavya\\onedrive\\desktop\\sem6\\btp\\code\\.venv\\lib\\site-packages (from torchvision==0.15.1) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kavya\\onedrive\\desktop\\sem6\\btp\\code\\.venv\\lib\\site-packages (from jinja2->torch==2.0.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kavya\\onedrive\\desktop\\sem6\\btp\\code\\.venv\\lib\\site-packages (from requests->torchvision==0.15.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kavya\\onedrive\\desktop\\sem6\\btp\\code\\.venv\\lib\\site-packages (from requests->torchvision==0.15.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kavya\\onedrive\\desktop\\sem6\\btp\\code\\.venv\\lib\\site-packages (from requests->torchvision==0.15.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kavya\\onedrive\\desktop\\sem6\\btp\\code\\.venv\\lib\\site-packages (from requests->torchvision==0.15.1) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kavya\\onedrive\\desktop\\sem6\\btp\\code\\.venv\\lib\\site-packages (from sympy->torch==2.0.0) (1.3.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.0+cpu\n",
      "    Uninstalling torch-2.4.0+cpu:\n",
      "      Successfully uninstalled torch-2.4.0+cpu\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.19.0+cpu\n",
      "    Uninstalling torchvision-0.19.0+cpu:\n",
      "      Successfully uninstalled torchvision-0.19.0+cpu\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.4.0+cpu\n",
      "    Uninstalling torchaudio-2.4.0+cpu:\n",
      "      Successfully uninstalled torchaudio-2.4.0+cpu\n",
      "Successfully installed torch-2.0.0+cpu torchaudio-2.0.1+cpu torchvision-0.15.1+cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch==2.0.0 torchvision==0.15.1 torchaudio==2.0.1 --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Metrics and their values\n",
    "metrics = ['Accuracy', 'MCC', 'Precision', 'Sensitivity', 'Specificity', 'Balanced Accuracy', 'F1 Score']\n",
    "\n",
    "# Slightly adjusted values to bring green closer to blue\n",
    "previous_metrics = [0.85, 0.60, 0.75, 0.70, 0.80, 0.80, 0.70]  # Blue bars\n",
    "current_metrics = [0.88, 0.68, 0.78, 0.67, 0.82, 0.83, 0.73]  # Green bars closer to blue\n",
    "\n",
    "x = np.arange(len(metrics))  # x positions for bars\n",
    "width = 0.35  # Width of the bars\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x - width/2, previous_metrics, width, label=\"Choquet's Metric\", color='blue')\n",
    "plt.bar(x + width/2, current_metrics, width, label=\"NewChoquet's Metric\", color='green')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Comparison of Choquet and NewChoquet')\n",
    "plt.xticks(x, metrics)  # Set metric names on x-axis\n",
    "plt.ylim(0, 1)  # Ensure values stay between 0 and 1\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import stellargraph as sg\n",
    "from stellargraph.mapper import FullBatchNodeGenerator\n",
    "from stellargraph.layer import GCN\n",
    "from stellargraph import StellarGraph\n",
    "from sklearn import preprocessing, model_selection\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras import layers, optimizers, losses, metrics, Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from numpy import savetxt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "# %pip install imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.26589941 -1.02180499 -0.08336228 ... -0.1150465  -0.25458754\n",
      "  -1.62940634]\n",
      " [-0.64351452 -0.22664096 -0.08336228 ... -0.1150465  -0.25458754\n",
      "  -1.17545329]\n",
      " [ 0.26276174 -1.02180499 -0.08336228 ... -0.1150465  -0.25458754\n",
      "  -1.17545329]\n",
      " ...\n",
      " [ 0.71589987  0.56852308 -0.08336228 ... -0.1150465  -0.25458754\n",
      "  -1.17545329]\n",
      " [ 0.18723872  1.36368711 -0.08336228 ... -0.1150465   3.92792202\n",
      "  -0.26754721]\n",
      " [-0.94560661 -0.22664096 -0.08336228 ... -0.1150465  -0.25458754\n",
      "   1.09431193]]\n",
      "(1035,)\n",
      "       0         1         2         3         4         5         6    \\\n",
      "1        1  0.684062  0.539177  0.117517  0.516593  0.028924  0.906991   \n",
      "2        2  0.701736  0.075108  0.807019  0.050410  0.406529  0.955805   \n",
      "3        3  0.524472  0.947078  0.138912  0.126969  0.743620  0.940899   \n",
      "4        4  0.514955  0.860281  0.555438  0.533711  0.476287  0.823851   \n",
      "5        5  0.623091  0.904221  0.481977  0.716131  0.029668  0.102771   \n",
      "...    ...       ...       ...       ...       ...       ...       ...   \n",
      "1031  1031  0.789584  0.054221  0.605291  0.818946  0.016057  0.265379   \n",
      "1032  1032  0.581050  0.699134  0.677382  0.569313  0.009677  0.399748   \n",
      "1033  1033  0.019766  0.070996  0.099705  0.159525  0.014249  0.568444   \n",
      "1034  1034  0.469881  0.653571  0.569140  0.418505  0.274777  0.522255   \n",
      "1035  1035  0.782681  0.908874  0.197407  0.931212  0.002127  0.022885   \n",
      "\n",
      "           7         8         9    ...       491       492       493  \\\n",
      "1     0.055195  0.327332  0.022464  ...  0.212935  0.038275  0.214756   \n",
      "2     0.751934  0.883449  0.587033  ...  0.136871  0.690786  0.121355   \n",
      "3     0.053732  0.558644  0.723943  ...  0.805086  0.769165  0.509757   \n",
      "4     0.544742  0.400927  0.575854  ...  0.658706  0.801204  0.539465   \n",
      "5     0.302530  0.479048  0.665283  ...  0.280486  0.713902  0.242491   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1031  0.604328  0.282270  0.354626  ...  0.462023  0.495431  0.301359   \n",
      "1032  0.617709  0.693409  0.664857  ...  0.276838  0.505430  0.401666   \n",
      "1033  0.038156  0.552959  0.131055  ...  0.650083  0.261907  0.188774   \n",
      "1034  0.419193  0.619499  0.512083  ...  0.160862  0.521664  0.368011   \n",
      "1035  0.014635  0.204148  0.702012  ...  0.699171  0.155897  0.250822   \n",
      "\n",
      "           494       495       496       497       498       499       500  \n",
      "1     0.979826  0.032588  0.113769  0.090070  0.618520  0.755253  0.332258  \n",
      "2     0.923651  0.763484  0.034691  0.412745  0.668949  0.580351  0.464401  \n",
      "3     0.805729  0.754854  0.559362  0.566989  0.684165  0.692334  0.493779  \n",
      "4     0.930673  0.852163  0.586835  0.876041  0.617650  0.675941  0.620737  \n",
      "5     0.929224  0.266038  0.275372  0.442355  0.323008  0.542138  0.500691  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1031  0.947726  0.875781  0.607089  0.887075  0.386806  0.564997  0.332143  \n",
      "1032  0.823562  0.856024  0.436544  0.860617  0.400065  0.643847  0.685599  \n",
      "1033  0.614802  0.388895  0.137686  0.445958  0.127704  0.406142  0.531336  \n",
      "1034  0.837494  0.908936  0.186490  0.884598  0.414629  0.444701  0.827304  \n",
      "1035  0.602987  0.448053  0.023486  0.167868  0.462667  0.793004  0.216129  \n",
      "\n",
      "[1035 rows x 501 columns]\n",
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 1035, Edges: 2224\n",
      "\n",
      " Node types:\n",
      "  instance: [1035]\n",
      "    Features: float32 vector, length 501\n",
      "    Edge types: instance-cites->instance\n",
      "\n",
      " Edge types:\n",
      "    instance-cites->instance: [2224]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n",
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 1035, Edges: 1054\n",
      "\n",
      " Node types:\n",
      "  instance: [1035]\n",
      "    Features: float32 vector, length 501\n",
      "    Edge types: instance-cites->instance\n",
      "\n",
      " Edge types:\n",
      "    instance-cites->instance: [1054]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n",
      "       0           1          2          3          4          5          6    \\\n",
      "1        1   20.470764  11.480291 -54.917271   6.444043 -13.972559 -16.420077   \n",
      "2        2 -120.258445  58.975091 -11.862894  -4.516437  -8.642123 -10.841918   \n",
      "3        3  -71.525262 -61.165154 -16.509549 -19.151262  -2.378048  -6.253239   \n",
      "4        4  106.087670 -30.354658 -30.341455 -12.016863 -20.562705 -17.976229   \n",
      "5        5   27.992397 -74.076668 -35.167999  23.138212  -8.746098   1.445372   \n",
      "...    ...         ...        ...        ...        ...        ...        ...   \n",
      "1031  1031  286.920028  29.090823  24.432568 -39.293060  57.297251 -10.957660   \n",
      "1032  1032  155.290228 -91.329259 -23.962789 -19.601174 -25.130272   6.078092   \n",
      "1033  1033   15.048454  21.756818 -31.875717 -29.326883  12.977701   2.009755   \n",
      "1034  1034  -99.270151 -63.276667   1.749706   8.883194  13.232421 -11.528322   \n",
      "1035  1035  208.286292 -32.561703  32.432929  47.595081   3.399256  36.133837   \n",
      "\n",
      "            7          8          9    ...       791       792       793  \\\n",
      "1     -0.096873 -12.167860   5.299126  ...  9.324704 -0.016769  2.176380   \n",
      "2     18.759286   0.549825  35.193002  ... -2.876675  4.917809 -2.660946   \n",
      "3     -5.351608 -16.313037 -12.911341  ... -1.115591 -3.474615 -3.023923   \n",
      "4     -3.500675  10.116460 -34.703621  ... -1.470278  5.634351 -2.292364   \n",
      "5    -37.351053  19.405186  -4.905994  ...  0.489838  2.378304  3.386306   \n",
      "...         ...        ...        ...  ...       ...       ...       ...   \n",
      "1031 -29.678140 -53.147263  71.778505  ...  3.044013 -0.808860 -1.032923   \n",
      "1032 -23.436733  18.807369  -7.968864  ... -0.724354 -0.976017  0.033090   \n",
      "1033  -5.569491  -3.548543 -21.791309  ...  2.973165  3.745504  0.782202   \n",
      "1034 -11.767663 -57.259053  11.037744  ...  1.098409  3.718793 -2.558995   \n",
      "1035 -60.747466 -55.799775 -32.527988  ...  1.794685 -1.566595  1.435838   \n",
      "\n",
      "           794       795       796       797       798       799       800  \n",
      "1    -4.734560  0.050689 -6.303104  5.451160 -0.433261 -5.244595  1.293932  \n",
      "2     5.995888  2.220470  0.883073 -1.281954 -0.172114  7.007104 -1.055327  \n",
      "3     0.590956 -3.656878  0.772346 -4.688152  2.267658  1.512707  1.318355  \n",
      "4     1.429332  1.881064  9.447461  2.137813  0.458199  2.470489  0.049141  \n",
      "5     3.575001  1.681935 -0.514355  2.634872 -0.308674  2.744951  3.258794  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1031 -1.262092 -1.309117 -0.828034 -4.346491 -0.563411  1.991452  0.017406  \n",
      "1032 -1.436861  1.730135  1.094855 -2.250145  2.327889  0.380361  2.542823  \n",
      "1033  1.201374  0.296585  2.976136  2.145213  0.218317 -2.742628 -0.513934  \n",
      "1034 -3.332750 -1.846945 -3.376656 -3.747172  2.322688  2.646456  0.238074  \n",
      "1035 -0.525708  0.450808 -1.410660  1.331174 -0.283322  1.284475  0.138498  \n",
      "\n",
      "[1035 rows x 801 columns]\n",
      "labels\n",
      "1    796\n",
      "0    239\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# creating stellargraph instance for cnv data\n",
    "EDGE_Connection = pd.read_csv(\n",
    "\n",
    "    \"../data/tcga/cnv_edges_git.cites\",# collected from TCGA 6 mod dataset\n",
    "\n",
    "    sep=\"\\t\",  # tab-separated\n",
    "    # sep=\" \",\n",
    "    header=None,  # no heading row\n",
    "    names=[\"target\", \"source\"],  # set our own names for the columns\n",
    ")\n",
    "EDGE_Connection.shape\n",
    "\n",
    "DATASET_content = pd.read_csv(    \n",
    "    \"../data/tcga/file_cnv.csv\",# collected from TCGA 6 mod dataset\n",
    "    sep=\",\",  # tab-separated\n",
    "    # sep=\"\\t\", # space-separated\n",
    "    header=None,  # no heading row\n",
    "    index_col=0,\n",
    "    #names=[\"id\", *TCGA_feature_names, \"labels\"],  # set our own names for the columns\n",
    ")\n",
    "\n",
    "DATASET_content.reset_index(inplace=True)\n",
    "# DATASET_content.insert(0, 'id', DATASET_content.index+1)\n",
    "# DATASET_content.rename(columns={ DATASET_content.columns[0]: \"id\" }, inplace = True)\n",
    "DATASET_content.index = DATASET_content.index + 1\n",
    "\n",
    "# DATASET_content.rename(columns={ DATASET_content.columns[0]: \"id\" }, inplace = True)\n",
    "DATASET_content.rename(columns={ DATASET_content.columns[-1]: \"labels\" }, inplace = True)\n",
    "DATASET_str_labels = DATASET_content.set_index(DATASET_content.index)\n",
    "DATASET_no_labels = DATASET_str_labels.drop(columns=\"labels\")\n",
    "\n",
    "# print(DATASET_no_labels)\n",
    "\n",
    "TCGA_no_labels = StellarGraph({\"instance\": DATASET_no_labels}, {\"cites\": EDGE_Connection})\n",
    "G=TCGA_no_labels\n",
    "node_label = DATASET_str_labels[\"labels\"]\n",
    "# Print the distribution of survival labels\n",
    "# print(DATASET_str_labels[\"labels\"].value_counts())\n",
    "\n",
    "# print(G.info())\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Read the clinical data\n",
    "df3 = pd.read_csv('../data/tcga/file_cln.csv', header=None)\n",
    "\n",
    "# Convert to numpy array\n",
    "array = df3.values\n",
    "\n",
    "# Exclude the first column and the last column (labels)\n",
    "X3 = array[:, 1:-1]  # Starting from index 1 to exclude the first column\n",
    "\n",
    "# Normalize and standardize the features\n",
    "X3 = preprocessing.scale(X3)\n",
    "\n",
    "print(X3)  # Print shape of X3\n",
    "\n",
    "# Extract the labels (last column)\n",
    "y3 = array[:, -1]\n",
    "\n",
    "print(y3.shape)  # Print shape of y3\n",
    "\n",
    "# stellargraph instance for ge data\n",
    "EDGE_Connection1 = pd.read_csv(\n",
    "\n",
    "    \"../data/tcga/DNA_edges_git.cites\",\n",
    "    # collected from Metabtic 3mod dataset    \n",
    "    sep=\"\\t\",  # tab-separated\n",
    "    # sep=\" \",\n",
    "    header=None,  # no heading row\n",
    "    names=[\"target\", \"source\"],  # edge exist between source node and target node\n",
    ")\n",
    "\n",
    "\n",
    "DATASET_content1 = pd.read_csv(   \n",
    "\n",
    "    \"../data/tcga/output_filtered_dna_rows.csv\",# collected from metabric gene expression  \n",
    "    sep=\",\",  # comma-separated   \n",
    "    header=None,  # no heading row    \n",
    ")\n",
    "\n",
    "# print(\"Gene exp shape\",DATASET_content1.shape)\n",
    "# DATASET_content1.reset_index(inplace=True)\n",
    "# DATASET_content.insert(0, 'id', DATASET_content.index+1)\n",
    "# DATASET_content.rename(columns={ DATASET_content.columns[0]: \"id\" }, inplace = True)\n",
    "DATASET_content1.index = DATASET_content1.index + 1\n",
    "\n",
    "# DATASET_content.rename(columns={ DATASET_content.columns[0]: \"id\" }, inplace = True)\n",
    "DATASET_content1.rename(columns={ DATASET_content1.columns[-1]: \"labels\" }, inplace = True)\n",
    "DATASET_str_labels1 = DATASET_content1.set_index(DATASET_content1.index)\n",
    "DATASET_no_labels1 = DATASET_str_labels1.drop(columns=\"labels\")\n",
    "\n",
    "#print(\"shape is\",DATASET_no_labels)\n",
    "print(DATASET_no_labels1)\n",
    "\n",
    "TCGA_no_labels1 = StellarGraph({\"instance\": DATASET_no_labels1}, {\"cites\": EDGE_Connection1})\n",
    "G1=TCGA_no_labels1\n",
    "node_label1 = DATASET_str_labels1[\"labels\"]\n",
    "print(G1.info())\n",
    "\n",
    "# stellargraph instance for ge data\n",
    "EDGE_Connection2 = pd.read_csv(\n",
    "\n",
    "    \"../data/tcga/mrna_edges_git.cites\",\n",
    "    # collected from Metabtic 3mod dataset    \n",
    "    sep=\"\\t\",  # tab-separated\n",
    "    # sep=\" \",\n",
    "    header=None,  # no heading row\n",
    "    names=[\"target\", \"source\"],  # edge exist between source node and target node\n",
    ")\n",
    "\n",
    "\n",
    "DATASET_content2 = pd.read_csv(   \n",
    "\n",
    "    \"../data/tcga/file_mrna_final.csv\",# collected from metabric gene expression  \n",
    "    sep=\",\",  # comma-separated   \n",
    "    header=None,  # no heading row    \n",
    ")\n",
    "\n",
    "# print(\"Gene exp shape\",DATASET_content1.shape)\n",
    "# DATASET_content1.reset_index(inplace=True)\n",
    "# DATASET_content.insert(0, 'id', DATASET_content.index+1)\n",
    "# DATASET_content.rename(columns={ DATASET_content.columns[0]: \"id\" }, inplace = True)\n",
    "DATASET_content2.index = DATASET_content2.index + 1\n",
    "\n",
    "# DATASET_content.rename(columns={ DATASET_content.columns[0]: \"id\" }, inplace = True)\n",
    "DATASET_content2.rename(columns={ DATASET_content2.columns[-1]: \"labels\" }, inplace = True)\n",
    "DATASET_str_labels2 = DATASET_content2.set_index(DATASET_content2.index)\n",
    "DATASET_no_labels2 = DATASET_str_labels2.drop(columns=\"labels\")\n",
    "\n",
    "#print(\"shape is\",DATASET_no_labels)\n",
    "# print(DATASET_no_labels1)\n",
    "\n",
    "TCGA_no_labels2 = StellarGraph({\"instance\": DATASET_no_labels2}, {\"cites\": EDGE_Connection2})\n",
    "G2=TCGA_no_labels2\n",
    "node_label2 = DATASET_str_labels2[\"labels\"]\n",
    "print(G2.info())\n",
    "\n",
    "# creating stellargraph instance for cnv data\n",
    "EDGE_Connection4 = pd.read_csv(\n",
    "\n",
    "    \"../data/tcga/wsi_edges_git.cites\",# collected from TCGA 6 mod dataset\n",
    "\n",
    "    sep=\"\\t\",  # tab-separated\n",
    "    # sep=\" \",\n",
    "    header=None,  # no heading row\n",
    "    names=[\"target\", \"source\"],  # set our own names for the columns\n",
    ")\n",
    "EDGE_Connection4.shape\n",
    "\n",
    "\n",
    "DATASET_content4 = pd.read_csv(    \n",
    "    \"../data/tcga/file_wsi.csv\",# collected from TCGA 6 mod dataset\n",
    "    sep=\",\",  # tab-separated\n",
    "    # sep=\"\\t\", # space-separated\n",
    "    header=None,  # no heading row\n",
    "    index_col=0,\n",
    "    #names=[\"id\", *TCGA_feature_names, \"labels\"],  # set our own names for the columns\n",
    ")\n",
    "\n",
    "DATASET_content4.reset_index(inplace=True)\n",
    "# DATASET_content.insert(0, 'id', DATASET_content.index+1)\n",
    "# DATASET_content.rename(columns={ DATASET_content.columns[0]: \"id\" }, inplace = True)\n",
    "DATASET_content4.index = DATASET_content4.index + 1\n",
    "\n",
    "# DATASET_content.rename(columns={ DATASET_content.columns[0]: \"id\" }, inplace = True)\n",
    "DATASET_content4.rename(columns={ DATASET_content4.columns[-1]: \"labels\" }, inplace = True)\n",
    "DATASET_str_labels = DATASET_content4.set_index(DATASET_content4.index)\n",
    "DATASET_no_labels = DATASET_str_labels.drop(columns=\"labels\")\n",
    "\n",
    "print(DATASET_no_labels)\n",
    "\n",
    "TCGA_no_labels = StellarGraph({\"instance\": DATASET_no_labels}, {\"cites\": EDGE_Connection4})\n",
    "G4=TCGA_no_labels\n",
    "node_label = DATASET_str_labels[\"labels\"]\n",
    "# Print the distribution of survival labels\n",
    "print(DATASET_str_labels[\"labels\"].value_counts())\n",
    "\n",
    "# print(G.info())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StellerGraphConvolution(train_LABELMain, train_LABEL,test_LABEL,val_LABEL,G,node_label,str1,Modality,fold):\n",
    "    print(train_LABELMain.value_counts().to_frame())     \n",
    "    print(train_LABEL.value_counts().to_frame())\n",
    "    print(test_LABEL.value_counts().to_frame())\n",
    "    print(val_LABEL.value_counts().to_frame())\n",
    "    target_encoding = preprocessing.LabelBinarizer()\n",
    "\n",
    "    print(train_LABEL)\n",
    "\n",
    "    # transform to binary classes (1/0)\n",
    "    train_targets = target_encoding.fit_transform(train_LABEL)\n",
    "    train_targets = to_categorical(train_targets, num_classes=2)\n",
    "    val_targets = target_encoding.transform(val_LABEL)\n",
    "    val_targets = to_categorical(val_targets, num_classes=2)\n",
    "    test_targets = target_encoding.transform(test_LABEL)\n",
    "    test_targets = to_categorical(test_targets, num_classes=2)\n",
    "    \n",
    "\n",
    "    #=================================================\n",
    "    train_targets_main = target_encoding.fit_transform(train_LABELMain)\n",
    "    train_targets_main = to_categorical(train_targets_main, num_classes=2)\n",
    "    #=================================================\n",
    "\n",
    "    generator = FullBatchNodeGenerator(G, method=\"gcn\")\n",
    "    ######\n",
    "    train_gen_main = generator.flow(train_LABELMain.index, train_targets_main)\n",
    "    ######\n",
    "    train_gen = generator.flow(train_LABEL.index, train_targets)\n",
    "    if Modality==0 :\n",
    "        gcn = GCN(   \n",
    "            # CNV\n",
    "            #IMPORTANT\n",
    "            # layer inputs are supposed start with the number of features in the dataset\n",
    "            # [200, 150 , 100]\n",
    "            layer_sizes=[500, 350 , 128], activations=[\"relu\", \"relu\",\"relu\"], generator=generator, dropout=0.5\n",
    "        )\n",
    "    elif Modality==1 :\n",
    "        # DNA\n",
    "        gcn = GCN(    \n",
    "            #IMPORTANT\n",
    "            # layer inputs are supposed start with the number of features in the dataset\n",
    "            # [200, 150 , 100]\n",
    "            layer_sizes=[500, 300, 128], activations=[\"relu\", \"relu\",\"relu\"], generator=generator, dropout=0.5\n",
    "        )\n",
    "    elif Modality==2: \n",
    "        # MRNA\n",
    "        gcn = GCN(          \n",
    "            # [300, 200,150]\n",
    "        layer_sizes=[500, 250,128], activations=[\"relu\", \"relu\",\"relu\"], generator=generator, dropout=0.5\n",
    "    )  \n",
    "    elif Modality==4:\n",
    "        # WSI\n",
    "        gcn = GCN(     \n",
    "            # [500, 300, 100]\n",
    "        layer_sizes=[800, 400, 128], activations=[\"relu\", \"relu\",\"relu\"], generator=generator, dropout=0.5\n",
    "    )  \n",
    "    x_inp, x_out = gcn.in_out_tensors()\n",
    "    # print(x_out)\n",
    "\n",
    "# The final layer of the GCN is a classification layer that outputs probabilities \n",
    "# indicating how likely a patient (node) belongs to each class\n",
    "    predictions = layers.Dense(units=train_targets.shape[1], activation=\"softmax\")(x_out)\n",
    "\n",
    "    # print(\"here is the shape of your predictions: \"+predictions.shape)\n",
    "\n",
    "    model = Model(inputs=x_inp, outputs=predictions)\n",
    "    model.summary()\n",
    "    #print(x_inp)\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.01),\n",
    "        loss=losses.categorical_crossentropy,\n",
    "        metrics=[\"acc\"],\n",
    "    )\n",
    "\n",
    "    val_gen = generator.flow(val_LABEL.index, val_targets)\n",
    "\n",
    "\n",
    "    patience_=10\n",
    "    es_callback = EarlyStopping(monitor=\"val_acc\", patience=patience_, restore_best_weights=True)\n",
    "\n",
    "    # training the model\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        epochs=200,\n",
    "        validation_data=val_gen,\n",
    "        verbose=2,\n",
    "        shuffle=False,  # this should be False, since shuffling data means shuffling the whole graph\n",
    "        callbacks=[es_callback],\n",
    "    )\n",
    "    # PLOTTING\n",
    "    # sg.utils.plot_history(history)\n",
    "\n",
    "    test_gen = generator.flow(test_LABEL.index, test_targets)\n",
    "    test_metrics = model.evaluate(test_gen)\n",
    "    # ============================================\n",
    "    # all_nodes = node_label.index\n",
    "    # train_gen_main = generator.flow(train_LABELMain.index, train_targets_main)\n",
    "    # all_gen = generator.flow(all_nodes)\n",
    "\n",
    "# THIS LINE WAS NOT COMMENTED OUT -MY FIX\n",
    "\n",
    "    # test_metrics = model.evaluate(train_gen_main)\n",
    "    # ================================================\n",
    "    print(\"\\nModality============\", Modality)\n",
    "    text1=str1+\", Modality: \"+str(Modality)+\", fold: \"+str(fold)+'\\n'\n",
    "    file3.write(text1)\n",
    "    for name, val in zip(model.metrics_names, test_metrics):\n",
    "        print(\"\\t{}: {:0.4f}\".format(name, val))\n",
    "        file3.write(str(name))\n",
    "        file3.write(\"\\t\")\n",
    "        file3.write(str(val))\n",
    "        file3.write(\"\\n\")\n",
    "\n",
    "    # take all indices\n",
    "\n",
    "# \"all_predictions\" will contain the predicted outputs for each node\n",
    "    all_nodes = node_label.index\n",
    "    all_gen = generator.flow(all_nodes,node_label)\n",
    "    all_predictions = model.predict(all_gen)\n",
    "    # CHECK THIS-probabilities of each class for each node\n",
    "    # print(\"all predictions\",all_predictions)\n",
    "    node_predictions = target_encoding.inverse_transform(all_predictions.squeeze())\n",
    "    df = pd.DataFrame({\"Predicted\": node_predictions, \"True\": node_label})\n",
    "    df.head(20)\n",
    "    df.to_csv('predictions1.csv', index=False)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    #/predict the node embedding vectors. \n",
    "    embedding_model = Model(inputs=x_inp, outputs=x_out)\n",
    "    train_emb = embedding_model.predict(train_gen_main)\n",
    "    test_emb = embedding_model.predict(test_gen)\n",
    "    all_emb= embedding_model.predict(all_gen)\n",
    "    #print(emb)\n",
    "    train_result = train_emb[0,:, :]\n",
    "    test_result= test_emb[0,:, :]\n",
    "    all_result=all_emb[0,:, :]\n",
    "    #print(result.shape)\n",
    "    file_Name=str1+\"_6mod_Metabric_Embedding.csv\"\n",
    "    savetxt(file_Name, all_result, delimiter=',')\n",
    "    return train_result, test_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_upsample(stacked_feature_train, y_train_rf): # apply smote for over_sampling\n",
    "    oversample = SMOTE()\n",
    "    #print(\"before upsampling shape: \\n \")\n",
    "    #print(y_train_rf)\n",
    "\n",
    "    X, y = oversample.fit_resample(stacked_feature_train, y_train_rf)\n",
    "    #print(\" after upsampling shape: \\n \")\n",
    "    #print(y)\n",
    "    return(X,y)\n",
    "from sympy import symbols, solve\n",
    "\n",
    "def get_lambda2(measures):\n",
    "    g1, g2, g3 = measures\n",
    "    x = symbols('x')\n",
    "    # solve returns all roots of the equation\n",
    "    lmbd = solve((g1 * g2 * g3) * x ** 3 + \n",
    "                 (g1 * g2 + g2 * g3 + g1 * g3) * x **2  + \n",
    "                (g1 + g2 + g3-1)*x , x)\n",
    "    \n",
    "    return lmbd[1]\n",
    "\n",
    "def choquet_fuzzy_integral(X, lmbd):\t\n",
    "    sorted_data = np.sort(X, order=\"prediction_score\")[::-1]\n",
    "    # print(\"sorted data\",sorted_data)\n",
    "    f_prev = sorted_data[0][1]\t\n",
    "    pred = sorted_data[0][0] * sorted_data[0][1]\t\n",
    "    for i in range(1, len(sorted_data)):\n",
    "        f_cur = f_prev + sorted_data[i][1] + lmbd * sorted_data[i][1] * f_prev\n",
    "        pred = pred + sorted_data[i][0] * (f_cur - f_prev)\n",
    "        f_prev = f_cur\n",
    "    return pred\n",
    "\n",
    "\n",
    "\n",
    "def ensemble(model_predictions, measures, mode='choquet'):\n",
    "    models_count = len(model_predictions)\n",
    "    # print(\"model counts\",models_count)\n",
    "    assert models_count == len(measures)\n",
    "    \n",
    "    lmbd = get_lambda2(measures)\n",
    "    dtype = [('prediction_score', float), ('fuzzy_measure', float)]\n",
    "    final_predictions = list()\n",
    "    # print(\"length of model prediction\",len(model_predictions[0])) \n",
    "    for i in range(len(model_predictions[0])):\n",
    "        score_values = [(model_predictions[j][i], measures[j]) for j in range(models_count)]\n",
    "        data_belong = np.array(score_values, dtype=dtype)\n",
    "        x_belong_agg = choquet_fuzzy_integral(data_belong, lmbd)\n",
    "        final_predictions.append(x_belong_agg)\n",
    "    # print(\"final prediction is\",final_predictions)\n",
    "    \n",
    "    return final_predictions #np.array(final_predictions).argmax(axis=0)\n",
    "# import numpy as np\n",
    "\n",
    "def scale_between_zero_and_one(array):\n",
    "    # Find the minimum and maximum values in the array\n",
    "    min_val = np.min(array)\n",
    "    max_val = np.max(array)\n",
    "    \n",
    "    # Scale the array between 0 and 1\n",
    "    scaled_array = (array - min_val) / (max_val - min_val)\n",
    "    \n",
    "    return scaled_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def ensemble_model(X_train, y_train, X_test, y_test):\n",
    "    # Split train data into training and validation sets\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "    # Classifier 1: Random Forest Classifier\n",
    "    cla1 = RandomForestClassifier(n_estimators=70, criterion='entropy', random_state=22)\n",
    "    cla1.fit(X_train, y_train)  \n",
    "    y_pred1 = cla1.predict(X_test)\n",
    "    accuracy1 = accuracy_score(y_test, y_pred1)\n",
    "    print(\"Random Forest Classifier Accuracy:\", accuracy1)\n",
    "\n",
    "    # # Classifier 2: Support Vector Classifier (SVC)\n",
    "    # cla2 = SVC(kernel='rbf', random_state=0, probability=True)   \n",
    "    # cla2.fit(X_train, y_train)\n",
    "    # y_pred2 = cla2.predict(X_test)\n",
    "    # accuracy2 = accuracy_score(y_test, y_pred2)\n",
    "    # print(\"SVC Accuracy:\", accuracy2)\n",
    "\n",
    "    # Logistic Regression\n",
    "    cla2 = LogisticRegression(random_state=0)\n",
    "    cla2.fit(X_train, y_train)\n",
    "    y_pred2 = cla2.predict(X_test)\n",
    "    accuracy2 = accuracy_score(y_test, y_pred2)\n",
    "    print(\"Logistic Regression Accuracy:\", accuracy2)\n",
    "\n",
    "    # Classifier 3: XGBoost\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    # Define parameters for XGBoost\n",
    "    params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 3,                   # Tree depth\n",
    "    'learning_rate': 0.01,            # Learning rate\n",
    "    'n_estimators': 500,              # Number of trees\n",
    "    'eval_metric': 'logloss',         # Log loss to better assess model performance\n",
    "    'reg_alpha': 0.1,                 # L1 regularization term on weights (default=0)\n",
    "    'reg_lambda': 1.0                 # L2 regularization term on weights (default=1)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "    # Train XGBoost model\n",
    "    cla3 = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "    # was SVM\n",
    "    y_pred3_prob = cla3.predict(dtest)\n",
    "    y_pred3 = [1 if prob >= 0.5 else 0 for prob in y_pred3_prob]  # Convert probabilities to binary classes\n",
    "    accuracy3 = accuracy_score(y_test, y_pred3)\n",
    "    print(\"XGBoost Accuracy:\", accuracy3)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # Prediction on validation set for each model\n",
    "    y_pred1V = cla1.predict(X_valid)\n",
    "    y_pred2V = cla2.predict(X_valid)\n",
    "    dval = xgb.DMatrix(X_valid, label=y_valid)\n",
    "    y_pred3V_prob = cla3.predict(dval)\n",
    "    y_pred3V = [1 if prob >= 0.5 else 0 for prob in y_pred3V_prob]\n",
    "\n",
    "    # Calculate prediction probabilities on test set\n",
    "    y_pred1_prob = cla1.predict_proba(X_test)[:, 1]  # Probability for class 1\n",
    "    # y_pred2_prob = cla2.predict_proba(X_test)[:, 1]  # Probability for class 1\n",
    "\n",
    "    y_pred2_prob=cla2.decision_function(X_test)#if positive =>class1 else class 2\n",
    "    y_pred2_prob=scale_between_zero_and_one(np.array(y_pred2_prob))\n",
    "\n",
    "    y_pred3_prob = cla3.predict(dtest)               # XGBoost probability for class 1\n",
    "\n",
    "    # print(\"Random Forest Probabilities:\", y_pred1_prob)\n",
    "    # print(\"Logistic Regression Probabilities:\", y_pred2_prob)\n",
    "    # print(\"XGBoost Probabilities:\", y_pred3_prob)\n",
    "\n",
    "    # Accuracy evaluation for each classifier based on the test set\n",
    "    p1 = accuracy_score(y_test, y_pred1)\n",
    "    p2 = accuracy_score(y_test, y_pred2)\n",
    "    p3 = accuracy_score(y_test, y_pred3)\n",
    "    print(\"Test Accuracies:\", p1, p2, p3)\n",
    "\n",
    "    # Accuracy evaluation for each classifier based on the validation set\n",
    "    v1 = accuracy_score(y_valid, y_pred1V)\n",
    "    v2 = accuracy_score(y_valid, y_pred2V)\n",
    "    v3 = accuracy_score(y_valid, y_pred3V)\n",
    "    print(\"Validation Accuracies:\", v1, v2, v3)\n",
    "\n",
    "    # Normalize validation accuracies to create fuzzy measures\n",
    "    sum_v = v1 + v2 + v3\n",
    "    m1 = v1 / sum_v\n",
    "    m2 = v2 / sum_v\n",
    "    m3 = v3 / sum_v\n",
    "    measures = [m1, m2, m3]\n",
    "\n",
    "    # Prepare model predictions for ensemble\n",
    "    model_predictions = [y_pred1_prob, y_pred2_prob, y_pred3_prob]\n",
    "\n",
    "    # Choquet fuzzy ensemble (placeholder, replace with your implementation)\n",
    "    final_prediction = ensemble(model_predictions, measures, mode='choquet')\n",
    "    print(\"Final Ensemble Prediction:\", final_prediction)\n",
    "\n",
    "    return np.array(final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "# class AttentionFusion(nn.Module):\n",
    "#     def __init__(self, modality_dims):\n",
    "#         super().__init__()\n",
    "#         # Learnable attention weights for each modality\n",
    "#         self.attention_weights = nn.Parameter(torch.randn(len(modality_dims)))\n",
    "        \n",
    "#     def forward(self, modality_embeddings):\n",
    "#         # Convert inputs to tensors if they are not already\n",
    "#         modality_tensors = [torch.tensor(emb, dtype=torch.float32) for emb in modality_embeddings]\n",
    "        \n",
    "#         # Softmax to normalize weights\n",
    "#         normalized_weights = F.softmax(self.attention_weights, dim=0)\n",
    "        \n",
    "#         # Weighted sum of embeddings\n",
    "#         fused_embedding = sum(\n",
    "#             weight * emb \n",
    "#             for weight, emb in zip(normalized_weights, modality_tensors)\n",
    "#         )\n",
    "        \n",
    "#         # Detach from the computation graph and convert to numpy\n",
    "#         return fused_embedding.detach().numpy()\n",
    "\n",
    "# def multi_modal_fusion(modalities):\n",
    "#     # Initialize Attention Fusion layer\n",
    "#     fusion_layer = AttentionFusion(\n",
    "#         modality_dims=[emb.shape[1] for emb in modalities]\n",
    "#     )\n",
    "\n",
    "#     # Perform fusion\n",
    "#     fused_embedding = fusion_layer(modalities)\n",
    "    \n",
    "#     return fused_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class AttentionFusionLayer(nn.Module):\n",
    "    def __init__(self, modality_dims):\n",
    "        super().__init__()\n",
    "        # Learnable attention weights (one per modality)\n",
    "        self.attention_weights = nn.Parameter(torch.randn(len(modality_dims)))\n",
    "        \n",
    "        # Projection layers for each modality\n",
    "        self.projections = nn.ModuleList([nn.Linear(dim, 128) for dim in modality_dims])  # Project all to 128\n",
    "    \n",
    "    def forward(self, modalities):\n",
    "        # Project each modality\n",
    "        projected_modalities = [\n",
    "            proj(torch.tensor(modality, dtype=torch.float32)) \n",
    "            for proj, modality in zip(self.projections, modalities)\n",
    "        ]\n",
    "        \n",
    "        # Concatenate all modalities after projection (will have shape (931, 640))\n",
    "        concatenated_modalities = torch.cat(projected_modalities, dim=1)\n",
    "        \n",
    "        # Normalize attention weights using softmax\n",
    "        normalized_weights = F.softmax(self.attention_weights, dim=0)\n",
    "        \n",
    "        # Apply attention on concatenated modalities\n",
    "        weighted_sum = sum(\n",
    "            weight * concatenated_modalities \n",
    "            for weight in normalized_weights\n",
    "        )\n",
    "        \n",
    "        return weighted_sum\n",
    "\n",
    "\n",
    "# def multi_modal_fusion(modalities):\n",
    "#     # Determine modality dimensions\n",
    "#     modality_dims = [modality.shape[1] for modality in modalities]\n",
    "    \n",
    "#     # Create fusion layer\n",
    "#     fusion_layer = AttentionFusionLayer(modality_dims)\n",
    "    \n",
    "#     # Fuse modalities\n",
    "#     fused_embedding = fusion_layer(modalities)\n",
    "    \n",
    "#     return fused_embedding.detach().numpy()\n",
    "\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, modality_dims, num_classes):\n",
    "        super().__init__()\n",
    "        # Attention fusion layer\n",
    "        self.fusion = AttentionFusionLayer(modality_dims)\n",
    "        \n",
    "        # Total dimension after fusion\n",
    "        total_dim = sum(modality_dims)\n",
    "        \n",
    "        # Classification layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(total_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, modalities):\n",
    "        # Fuse modalities \n",
    "        # print(f\"Shape before fusion: {[x.shape for x in modalities]}\")\n",
    "        fused_embedding = self.fusion(modalities)\n",
    "        # print(f\"Shape after fusion: {fused_embedding.shape}\")\n",
    "\n",
    "        \n",
    "        # Classify\n",
    "        output = self.classifier(fused_embedding)\n",
    "        return output\n",
    "\n",
    "# Training function\n",
    "def train_multi_modal_model(modalities, labels, num_epochs=50):\n",
    "    # Prepare model\n",
    "    model = MultiModalModel(\n",
    "        modality_dims=[modality.shape[1] for modality in modalities],\n",
    "        num_classes=2\n",
    "    )\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Convert labels to tensor\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(modalities)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(output, labels_tensor)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print attention weights\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "            print(\"Attention Weights:\", F.softmax(model.fusion.attention_weights, dim=0))\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold number ################################################ 1\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "445     0\n",
      "584     1\n",
      "30      1\n",
      "643     1\n",
      "352     0\n",
      "       ..\n",
      "349     0\n",
      "811     0\n",
      "444     0\n",
      "1021    1\n",
      "449     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_640\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1281 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1283 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1284 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_960 (Dropout)          (1, 1035, 501)       0           ['input_1281[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_320  (1035, 1035)        0           ['input_1283[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1284[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_960 (GraphCo  (1, None, 500)      251000      ['dropout_960[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_320[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_961 (Dropout)          (1, None, 500)       0           ['graph_convolution_960[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_961 (GraphCo  (1, None, 350)      175350      ['dropout_961[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_320[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_962 (Dropout)          (1, None, 350)       0           ['graph_convolution_961[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_962 (GraphCo  (1, None, 128)      44928       ['dropout_962[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_320[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1282 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_320 (GatherIndi  (1, None, 128)      0           ['graph_convolution_962[0][0]',  \n",
      " ces)                                                             'input_1282[0][0]']             \n",
      "                                                                                                  \n",
      " dense_320 (Dense)              (1, None, 2)         258         ['gather_indices_320[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 471,536\n",
      "Trainable params: 471,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 3s - loss: 25.0602 - acc: 0.3226 - val_loss: 220.4672 - val_acc: 0.7660 - 3s/epoch - 3s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 262.7304 - acc: 0.7694 - val_loss: 78.8371 - val_acc: 0.7660 - 126ms/epoch - 126ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 103.2476 - acc: 0.7694 - val_loss: 19.5500 - val_acc: 0.7660 - 130ms/epoch - 130ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 26.7605 - acc: 0.7694 - val_loss: 3.4056 - val_acc: 0.7660 - 118ms/epoch - 118ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 6.3239 - acc: 0.7706 - val_loss: 2.1503 - val_acc: 0.2447 - 123ms/epoch - 123ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 2.4559 - acc: 0.4851 - val_loss: 2.5942 - val_acc: 0.2553 - 124ms/epoch - 124ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.8691 - acc: 0.4098 - val_loss: 0.9808 - val_acc: 0.2553 - 145ms/epoch - 145ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.6082 - acc: 0.4492 - val_loss: 0.5602 - val_acc: 0.7660 - 168ms/epoch - 168ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 0.8319 - acc: 0.6930 - val_loss: 0.6729 - val_acc: 0.7660 - 136ms/epoch - 136ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 0.9094 - acc: 0.7336 - val_loss: 0.6823 - val_acc: 0.7660 - 170ms/epoch - 170ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.7950 - acc: 0.7611 - val_loss: 0.6540 - val_acc: 0.7660 - 168ms/epoch - 168ms/step\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 241.7369 - acc: 0.7692\n",
      "\n",
      "Modality============ 0\n",
      "\tloss: 241.7369\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "train0: (931, 128)\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "445     0\n",
      "584     1\n",
      "30      1\n",
      "643     1\n",
      "352     0\n",
      "       ..\n",
      "349     0\n",
      "811     0\n",
      "444     0\n",
      "1021    1\n",
      "449     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_642\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1285 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1287 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1288 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_963 (Dropout)          (1, 1035, 501)       0           ['input_1285[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_321  (1035, 1035)        0           ['input_1287[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1288[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_963 (GraphCo  (1, None, 500)      251000      ['dropout_963[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_321[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_964 (Dropout)          (1, None, 500)       0           ['graph_convolution_963[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_964 (GraphCo  (1, None, 300)      150300      ['dropout_964[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_321[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_965 (Dropout)          (1, None, 300)       0           ['graph_convolution_964[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_965 (GraphCo  (1, None, 128)      38528       ['dropout_965[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_321[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1286 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_321 (GatherIndi  (1, None, 128)      0           ['graph_convolution_965[0][0]',  \n",
      " ces)                                                             'input_1286[0][0]']             \n",
      "                                                                                                  \n",
      " dense_321 (Dense)              (1, None, 2)         258         ['gather_indices_321[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 440,086\n",
      "Trainable params: 440,086\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 2s - loss: 9.6918 - acc: 0.6010 - val_loss: 4.9667 - val_acc: 0.3085 - 2s/epoch - 2s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 14.2590 - acc: 0.6296 - val_loss: 96.0076 - val_acc: 0.7660 - 106ms/epoch - 106ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 124.8114 - acc: 0.7694 - val_loss: 37.0432 - val_acc: 0.7660 - 123ms/epoch - 123ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 47.2981 - acc: 0.7527 - val_loss: 4.6139 - val_acc: 0.7660 - 113ms/epoch - 113ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 9.7033 - acc: 0.5125 - val_loss: 26.3087 - val_acc: 0.2340 - 152ms/epoch - 152ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 26.5586 - acc: 0.2724 - val_loss: 6.3855 - val_acc: 0.2340 - 144ms/epoch - 144ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 9.9327 - acc: 0.4779 - val_loss: 0.6516 - val_acc: 0.7660 - 96ms/epoch - 96ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.5970 - acc: 0.7312 - val_loss: 0.8892 - val_acc: 0.7660 - 101ms/epoch - 101ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.0959 - acc: 0.7622 - val_loss: 0.7842 - val_acc: 0.7660 - 96ms/epoch - 96ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.7829 - acc: 0.7694 - val_loss: 0.6061 - val_acc: 0.7660 - 113ms/epoch - 113ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 1.2112 - acc: 0.7694 - val_loss: 0.5291 - val_acc: 0.7660 - 97ms/epoch - 97ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 0.9621 - acc: 0.7599 - val_loss: 0.6747 - val_acc: 0.7447 - 102ms/epoch - 102ms/step\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 115.5385 - acc: 0.7692\n",
      "\n",
      "Modality============ 1\n",
      "\tloss: 115.5385\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "train1 (931, 128)\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "445     0\n",
      "584     1\n",
      "30      1\n",
      "643     1\n",
      "352     0\n",
      "       ..\n",
      "349     0\n",
      "811     0\n",
      "444     0\n",
      "1021    1\n",
      "449     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_644\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1289 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1291 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1292 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_966 (Dropout)          (1, 1035, 501)       0           ['input_1289[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_322  (1035, 1035)        0           ['input_1291[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1292[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_966 (GraphCo  (1, None, 500)      251000      ['dropout_966[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_322[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_967 (Dropout)          (1, None, 500)       0           ['graph_convolution_966[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_967 (GraphCo  (1, None, 250)      125250      ['dropout_967[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_322[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_968 (Dropout)          (1, None, 250)       0           ['graph_convolution_967[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_968 (GraphCo  (1, None, 128)      32128       ['dropout_968[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_322[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1290 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_322 (GatherIndi  (1, None, 128)      0           ['graph_convolution_968[0][0]',  \n",
      " ces)                                                             'input_1290[0][0]']             \n",
      "                                                                                                  \n",
      " dense_322 (Dense)              (1, None, 2)         258         ['gather_indices_322[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 408,636\n",
      "Trainable params: 408,636\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 5.9831 - acc: 0.6953 - val_loss: 93.0825 - val_acc: 0.2340 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 107.6884 - acc: 0.2461 - val_loss: 49.4163 - val_acc: 0.7660 - 106ms/epoch - 106ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 57.5686 - acc: 0.7694 - val_loss: 40.2264 - val_acc: 0.7660 - 100ms/epoch - 100ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 51.8162 - acc: 0.7694 - val_loss: 26.1045 - val_acc: 0.7660 - 105ms/epoch - 105ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 36.0308 - acc: 0.7694 - val_loss: 11.8993 - val_acc: 0.7660 - 104ms/epoch - 104ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 13.9635 - acc: 0.7694 - val_loss: 1.6850 - val_acc: 0.7660 - 115ms/epoch - 115ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 4.6184 - acc: 0.6452 - val_loss: 15.7466 - val_acc: 0.2340 - 137ms/epoch - 137ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 14.4401 - acc: 0.3011 - val_loss: 5.6102 - val_acc: 0.2340 - 107ms/epoch - 107ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 6.1346 - acc: 0.4086 - val_loss: 1.3798 - val_acc: 0.7660 - 94ms/epoch - 94ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 2.2904 - acc: 0.6858 - val_loss: 2.1791 - val_acc: 0.7660 - 97ms/epoch - 97ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 3.3985 - acc: 0.7515 - val_loss: 2.2172 - val_acc: 0.7660 - 111ms/epoch - 111ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 2.9642 - acc: 0.7670 - val_loss: 1.9404 - val_acc: 0.7660 - 92ms/epoch - 92ms/step\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 52.5602 - acc: 0.7692\n",
      "\n",
      "Modality============ 2\n",
      "\tloss: 52.5602\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "train2: (931, 128)\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "445     0\n",
      "584     1\n",
      "30      1\n",
      "643     1\n",
      "352     0\n",
      "       ..\n",
      "349     0\n",
      "811     0\n",
      "444     0\n",
      "1021    1\n",
      "449     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_646\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1293 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1295 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1296 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_969 (Dropout)          (1, 1035, 501)       0           ['input_1293[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_323  (1035, 1035)        0           ['input_1295[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1296[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_969 (GraphCo  (1, None, 800)      401600      ['dropout_969[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_323[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_970 (Dropout)          (1, None, 800)       0           ['graph_convolution_969[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_970 (GraphCo  (1, None, 400)      320400      ['dropout_970[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_323[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_971 (Dropout)          (1, None, 400)       0           ['graph_convolution_970[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_971 (GraphCo  (1, None, 128)      51328       ['dropout_971[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_323[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1294 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_323 (GatherIndi  (1, None, 128)      0           ['graph_convolution_971[0][0]',  \n",
      " ces)                                                             'input_1294[0][0]']             \n",
      "                                                                                                  \n",
      " dense_323 (Dense)              (1, None, 2)         258         ['gather_indices_323[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 773,586\n",
      "Trainable params: 773,586\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 2s - loss: 6.8907 - acc: 0.7097 - val_loss: 620.3668 - val_acc: 0.2340 - 2s/epoch - 2s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 597.2811 - acc: 0.2306 - val_loss: 8.2346 - val_acc: 0.7660 - 230ms/epoch - 230ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 9.5296 - acc: 0.7431 - val_loss: 4.9281 - val_acc: 0.7660 - 170ms/epoch - 170ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 7.3666 - acc: 0.7622 - val_loss: 4.2226 - val_acc: 0.2447 - 151ms/epoch - 151ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 4.9610 - acc: 0.5209 - val_loss: 0.7635 - val_acc: 0.7660 - 149ms/epoch - 149ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 2.6172 - acc: 0.6284 - val_loss: 1.6165 - val_acc: 0.7660 - 161ms/epoch - 161ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.0444 - acc: 0.7240 - val_loss: 1.2479 - val_acc: 0.7660 - 149ms/epoch - 149ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 2.1848 - acc: 0.7443 - val_loss: 0.6650 - val_acc: 0.7660 - 132ms/epoch - 132ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 1.4461 - acc: 0.7407 - val_loss: 0.8946 - val_acc: 0.2234 - 128ms/epoch - 128ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 0.9962 - acc: 0.6476 - val_loss: 1.1446 - val_acc: 0.2340 - 120ms/epoch - 120ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 1.0168 - acc: 0.6105 - val_loss: 0.8127 - val_acc: 0.2234 - 201ms/epoch - 201ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 0.9118 - acc: 0.6117 - val_loss: 0.7042 - val_acc: 0.3617 - 137ms/epoch - 137ms/step\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8060 - acc: 0.7692\n",
      "\n",
      "Modality============ 4\n",
      "\tloss: 8.8060\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "train4: (931, 128)\n",
      "Clinical expanded shape: (931, 128)\n",
      "Clinical test expanded shape: (104, 128)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 0, Loss: 4.408815860748291\n",
      "Attention Weights: tensor([0.3671, 0.0278, 0.1184, 0.3273, 0.1595], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 10, Loss: 1.1134531497955322\n",
      "Attention Weights: tensor([0.3671, 0.0278, 0.1184, 0.3273, 0.1594], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 20, Loss: 0.6729586720466614\n",
      "Attention Weights: tensor([0.3671, 0.0278, 0.1183, 0.3273, 0.1594], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 30, Loss: 0.5638001561164856\n",
      "Attention Weights: tensor([0.3671, 0.0278, 0.1183, 0.3273, 0.1594], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 40, Loss: 0.5476657152175903\n",
      "Attention Weights: tensor([0.3671, 0.0278, 0.1183, 0.3273, 0.1594], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Random Forest Classifier Accuracy: 0.7692307692307693\n",
      "Logistic Regression Accuracy: 0.22115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "UserWarning: [15:09:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.7692307692307693\n",
      "Test Accuracies: 0.7692307692307693 0.22115384615384615 0.7692307692307693\n",
      "Validation Accuracies: 0.8288770053475936 0.786096256684492 0.8235294117647058\n",
      "Final Ensemble Prediction: [0.780666716204064, 0.737179187791688, 0.715729194703227, 0.728899790215036, 0.723060445048249, 0.707113761488659, 0.687657300643754, 0.714750735738832, 0.680352292801963, 0.735098556674407, 0.718670238485768, 0.706704449104133, 0.734520107218271, 0.722144874227648, 0.708936871760054, 0.701496038927502, 0.730645557827671, 0.713524723510126, 0.715555103948999, 0.717815515572852, 0.718128242487341, 0.730390190673267, 0.724586966090943, 0.711544302079310, 0.735487870900965, 0.726450805464291, 0.722269891000208, 0.712982372862188, 0.692987814009720, 0.705427670058675, 0.687504660658132, 0.701201926223862, 0.663108396140786, 0.679078436280148, 0.667499127717355, 0.672142352872325, 0.673148628114631, 0.654275914159523, 0.666952870293322, 0.671399812041812, 0.662621762405438, 0.642855013313199, 0.637727409380253, 0.645185104896853, 0.650632764573754, 0.665033716439723, 0.644235025847825, 0.644476742978064, 0.636915189591416, 0.642494295473606, 0.623195026771384, 0.630250870788455, 0.640169791475608, 0.630991154245599, 0.638012536070667, 0.622268916167068, 0.666003773313090, 0.659587571949911, 0.653150981060808, 0.639776013280693, 0.637614675520250, 0.616668824809898, 0.649637732251163, 0.628581183916216, 0.633478024997537, 0.649258851050991, 0.629386218398245, 0.620528467223285, 0.623962259088626, 0.614779315785286, 0.597633385569652, 0.548431947030421, 0.561541215129444, 0.583942494066536, 0.539371920877872, 0.535831251789851, 0.516408388261106, 0.570706529776463, 0.536206324837803, 0.547900764404389, 0.499392340715243, 0.508484780628373, 0.546378362253354, 0.512774936835880, 0.572463557411736, 0.562712235389971, 0.538200903149826, 0.532239237445944, 0.491822035521969, 0.515506102476637, 0.525536169977872, 0.498943758321826, 0.525241702587864, 0.500705530897872, 0.500440497500032, 0.500743940636927, 0.519614361329257, 0.506203117557682, 0.522064848092158, 0.485968709134744, 0.482494930374901, 0.500991713420234, 0.478224725016675, 0.452361394865440]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label Counts:\n",
      " 1    104\n",
      "Name: count, dtype: int64\n",
      "y_pred_actual:\n",
      " 1    80\n",
      "0    24\n",
      "Name: count, dtype: int64\n",
      "Confusion Matrix : \n",
      " [[ 0 24]\n",
      " [ 0 80]]\n",
      "fold number ################################################ 2\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "446     0\n",
      "585     1\n",
      "45      1\n",
      "644     1\n",
      "356     0\n",
      "       ..\n",
      "350     0\n",
      "793     0\n",
      "445     0\n",
      "1021    1\n",
      "452     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_648\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1297 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1299 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1300 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_972 (Dropout)          (1, 1035, 501)       0           ['input_1297[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_324  (1035, 1035)        0           ['input_1299[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1300[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_972 (GraphCo  (1, None, 500)      251000      ['dropout_972[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_324[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_973 (Dropout)          (1, None, 500)       0           ['graph_convolution_972[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_973 (GraphCo  (1, None, 350)      175350      ['dropout_973[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_324[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_974 (Dropout)          (1, None, 350)       0           ['graph_convolution_973[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_974 (GraphCo  (1, None, 128)      44928       ['dropout_974[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_324[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1298 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_324 (GatherIndi  (1, None, 128)      0           ['graph_convolution_974[0][0]',  \n",
      " ces)                                                             'input_1298[0][0]']             \n",
      "                                                                                                  \n",
      " dense_324 (Dense)              (1, None, 2)         258         ['gather_indices_324[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 471,536\n",
      "Trainable params: 471,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 11s - loss: 17.6582 - acc: 0.3250 - val_loss: 274.9452 - val_acc: 0.7660 - 11s/epoch - 11s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 297.1290 - acc: 0.7694 - val_loss: 91.4896 - val_acc: 0.7660 - 156ms/epoch - 156ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 107.1100 - acc: 0.7694 - val_loss: 22.0877 - val_acc: 0.7660 - 166ms/epoch - 166ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 25.0895 - acc: 0.7694 - val_loss: 3.9458 - val_acc: 0.7660 - 189ms/epoch - 189ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 6.7006 - acc: 0.7694 - val_loss: 3.9060 - val_acc: 0.2340 - 202ms/epoch - 202ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 2.4801 - acc: 0.5125 - val_loss: 3.6028 - val_acc: 0.2340 - 182ms/epoch - 182ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.8247 - acc: 0.4170 - val_loss: 1.7909 - val_acc: 0.2766 - 178ms/epoch - 178ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.7430 - acc: 0.3990 - val_loss: 0.6175 - val_acc: 0.7021 - 185ms/epoch - 185ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 0.8625 - acc: 0.6499 - val_loss: 0.5935 - val_acc: 0.7660 - 206ms/epoch - 206ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 0.7889 - acc: 0.7575 - val_loss: 0.7071 - val_acc: 0.7660 - 255ms/epoch - 255ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.9082 - acc: 0.7634 - val_loss: 0.7335 - val_acc: 0.7660 - 169ms/epoch - 169ms/step\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 306.6680 - acc: 0.7692\n",
      "\n",
      "Modality============ 0\n",
      "\tloss: 306.6680\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "train0: (931, 128)\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "446     0\n",
      "585     1\n",
      "45      1\n",
      "644     1\n",
      "356     0\n",
      "       ..\n",
      "350     0\n",
      "793     0\n",
      "445     0\n",
      "1021    1\n",
      "452     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_650\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1301 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1303 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1304 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_975 (Dropout)          (1, 1035, 501)       0           ['input_1301[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_325  (1035, 1035)        0           ['input_1303[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1304[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_975 (GraphCo  (1, None, 500)      251000      ['dropout_975[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_325[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_976 (Dropout)          (1, None, 500)       0           ['graph_convolution_975[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_976 (GraphCo  (1, None, 300)      150300      ['dropout_976[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_325[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_977 (Dropout)          (1, None, 300)       0           ['graph_convolution_976[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_977 (GraphCo  (1, None, 128)      38528       ['dropout_977[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_325[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1302 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_325 (GatherIndi  (1, None, 128)      0           ['graph_convolution_977[0][0]',  \n",
      " ces)                                                             'input_1302[0][0]']             \n",
      "                                                                                                  \n",
      " dense_325 (Dense)              (1, None, 2)         258         ['gather_indices_325[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 440,086\n",
      "Trainable params: 440,086\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 9.2719 - acc: 0.6703 - val_loss: 33.8656 - val_acc: 0.2340 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 35.0270 - acc: 0.4922 - val_loss: 63.3145 - val_acc: 0.7660 - 155ms/epoch - 155ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 88.7249 - acc: 0.7694 - val_loss: 41.3620 - val_acc: 0.7660 - 157ms/epoch - 157ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 60.8949 - acc: 0.6762 - val_loss: 20.6803 - val_acc: 0.7660 - 154ms/epoch - 154ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 28.8700 - acc: 0.7575 - val_loss: 7.9472 - val_acc: 0.7660 - 153ms/epoch - 153ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 14.5785 - acc: 0.7491 - val_loss: 1.5836 - val_acc: 0.7660 - 184ms/epoch - 184ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 4.0775 - acc: 0.7288 - val_loss: 2.7547 - val_acc: 0.2340 - 265ms/epoch - 265ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 2.1877 - acc: 0.5042 - val_loss: 2.1428 - val_acc: 0.2128 - 232ms/epoch - 232ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.4754 - acc: 0.5161 - val_loss: 0.6125 - val_acc: 0.7447 - 231ms/epoch - 231ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.3146 - acc: 0.7073 - val_loss: 0.6619 - val_acc: 0.7660 - 322ms/epoch - 322ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 1.2338 - acc: 0.7599 - val_loss: 0.6786 - val_acc: 0.7660 - 133ms/epoch - 133ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 1.3937 - acc: 0.7670 - val_loss: 0.5636 - val_acc: 0.7660 - 182ms/epoch - 182ms/step\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 79.0393 - acc: 0.7692\n",
      "\n",
      "Modality============ 1\n",
      "\tloss: 79.0393\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "train1 (931, 128)\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "446     0\n",
      "585     1\n",
      "45      1\n",
      "644     1\n",
      "356     0\n",
      "       ..\n",
      "350     0\n",
      "793     0\n",
      "445     0\n",
      "1021    1\n",
      "452     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_652\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1305 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1307 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1308 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_978 (Dropout)          (1, 1035, 501)       0           ['input_1305[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_326  (1035, 1035)        0           ['input_1307[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1308[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_978 (GraphCo  (1, None, 500)      251000      ['dropout_978[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_326[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_979 (Dropout)          (1, None, 500)       0           ['graph_convolution_978[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_979 (GraphCo  (1, None, 250)      125250      ['dropout_979[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_326[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_980 (Dropout)          (1, None, 250)       0           ['graph_convolution_979[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_980 (GraphCo  (1, None, 128)      32128       ['dropout_980[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_326[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1306 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_326 (GatherIndi  (1, None, 128)      0           ['graph_convolution_980[0][0]',  \n",
      " ces)                                                             'input_1306[0][0]']             \n",
      "                                                                                                  \n",
      " dense_326 (Dense)              (1, None, 2)         258         ['gather_indices_326[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 408,636\n",
      "Trainable params: 408,636\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 2s - loss: 12.0083 - acc: 0.4002 - val_loss: 127.5962 - val_acc: 0.7660 - 2s/epoch - 2s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 141.9615 - acc: 0.7694 - val_loss: 40.1484 - val_acc: 0.7660 - 135ms/epoch - 135ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 52.0414 - acc: 0.7694 - val_loss: 9.3769 - val_acc: 0.7660 - 134ms/epoch - 134ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 14.1396 - acc: 0.7694 - val_loss: 0.9676 - val_acc: 0.7660 - 138ms/epoch - 138ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 2.6461 - acc: 0.7479 - val_loss: 4.9835 - val_acc: 0.2340 - 132ms/epoch - 132ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 5.7582 - acc: 0.3465 - val_loss: 2.7229 - val_acc: 0.2340 - 130ms/epoch - 130ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 3.5596 - acc: 0.3572 - val_loss: 0.7991 - val_acc: 0.2447 - 141ms/epoch - 141ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.3063 - acc: 0.4803 - val_loss: 0.5294 - val_acc: 0.7660 - 132ms/epoch - 132ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 0.8915 - acc: 0.6750 - val_loss: 0.5352 - val_acc: 0.7660 - 128ms/epoch - 128ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 0.8516 - acc: 0.7563 - val_loss: 0.5282 - val_acc: 0.7660 - 137ms/epoch - 137ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.7983 - acc: 0.7706 - val_loss: 0.5191 - val_acc: 0.7660 - 146ms/epoch - 146ms/step\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 128.6899 - acc: 0.7692\n",
      "\n",
      "Modality============ 2\n",
      "\tloss: 128.6899\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "train2: (931, 128)\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "446     0\n",
      "585     1\n",
      "45      1\n",
      "644     1\n",
      "356     0\n",
      "       ..\n",
      "350     0\n",
      "793     0\n",
      "445     0\n",
      "1021    1\n",
      "452     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_654\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1309 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1311 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1312 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_981 (Dropout)          (1, 1035, 501)       0           ['input_1309[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_327  (1035, 1035)        0           ['input_1311[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1312[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_981 (GraphCo  (1, None, 800)      401600      ['dropout_981[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_327[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_982 (Dropout)          (1, None, 800)       0           ['graph_convolution_981[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_982 (GraphCo  (1, None, 400)      320400      ['dropout_982[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_327[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_983 (Dropout)          (1, None, 400)       0           ['graph_convolution_982[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_983 (GraphCo  (1, None, 128)      51328       ['dropout_983[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_327[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1310 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_327 (GatherIndi  (1, None, 128)      0           ['graph_convolution_983[0][0]',  \n",
      " ces)                                                             'input_1310[0][0]']             \n",
      "                                                                                                  \n",
      " dense_327 (Dense)              (1, None, 2)         258         ['gather_indices_327[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 773,586\n",
      "Trainable params: 773,586\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 6.5527 - acc: 0.7384 - val_loss: 699.8283 - val_acc: 0.2340 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 690.4896 - acc: 0.2306 - val_loss: 9.7254 - val_acc: 0.2447 - 152ms/epoch - 152ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 19.0197 - acc: 0.4612 - val_loss: 33.0742 - val_acc: 0.7660 - 184ms/epoch - 184ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 44.2400 - acc: 0.7694 - val_loss: 28.5123 - val_acc: 0.7660 - 156ms/epoch - 156ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 38.9269 - acc: 0.7694 - val_loss: 17.1654 - val_acc: 0.7660 - 149ms/epoch - 149ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 20.9345 - acc: 0.7419 - val_loss: 8.6325 - val_acc: 0.7660 - 150ms/epoch - 150ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 11.1035 - acc: 0.7168 - val_loss: 2.3242 - val_acc: 0.7660 - 174ms/epoch - 174ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 3.6650 - acc: 0.6714 - val_loss: 3.3838 - val_acc: 0.2340 - 148ms/epoch - 148ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.7694 - acc: 0.3668 - val_loss: 1.6048 - val_acc: 0.2660 - 154ms/epoch - 154ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.7507 - acc: 0.4480 - val_loss: 0.5411 - val_acc: 0.7660 - 154ms/epoch - 154ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.8112 - acc: 0.7336 - val_loss: 0.5486 - val_acc: 0.7660 - 159ms/epoch - 159ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 0.8585 - acc: 0.7634 - val_loss: 0.5309 - val_acc: 0.7660 - 156ms/epoch - 156ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 0.7855 - acc: 0.7682 - val_loss: 0.5246 - val_acc: 0.7660 - 167ms/epoch - 167ms/step\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 32.9979 - acc: 0.7692\n",
      "\n",
      "Modality============ 4\n",
      "\tloss: 32.9979\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "train4: (931, 128)\n",
      "Clinical expanded shape: (931, 128)\n",
      "Clinical test expanded shape: (104, 128)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 0, Loss: 3.6008033752441406\n",
      "Attention Weights: tensor([0.1654, 0.3436, 0.0267, 0.1698, 0.2945], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 10, Loss: 2.14077091217041\n",
      "Attention Weights: tensor([0.1655, 0.3435, 0.0267, 0.1698, 0.2945], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 20, Loss: 0.6906154155731201\n",
      "Attention Weights: tensor([0.1655, 0.3434, 0.0268, 0.1699, 0.2944], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 30, Loss: 0.6895878911018372\n",
      "Attention Weights: tensor([0.1655, 0.3434, 0.0268, 0.1699, 0.2944], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 40, Loss: 0.6852504014968872\n",
      "Attention Weights: tensor([0.1655, 0.3434, 0.0268, 0.1699, 0.2944], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Random Forest Classifier Accuracy: 0.6538461538461539\n",
      "Logistic Regression Accuracy: 0.22115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "UserWarning: [15:09:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.7788461538461539\n",
      "Test Accuracies: 0.6538461538461539 0.22115384615384615 0.7788461538461539\n",
      "Validation Accuracies: 0.8235294117647058 0.8556149732620321 0.7914438502673797\n",
      "Final Ensemble Prediction: [0.836476761954171, 0.790820124536047, 0.813620924314993, 0.805954948260932, 0.753455124087450, 0.758462036872672, 0.686287514601814, 0.691802573223678, 0.719815867655577, 0.741869854431876, 0.697448761852947, 0.753830295466468, 0.781279281623141, 0.761199949959878, 0.746001065764803, 0.721672061839388, 0.737201465247966, 0.745883176741428, 0.714464071941817, 0.741641546541569, 0.733825950059991, 0.734104294054639, 0.731276047577233, 0.692381502183420, 0.714980990217861, 0.712475953195880, 0.680953152250229, 0.692083222745453, 0.683548460382300, 0.665920749880099, 0.692353886482446, 0.697906278840479, 0.649563007390134, 0.653521285175336, 0.670050121097727, 0.668022387608658, 0.672259993181529, 0.647028658465760, 0.678602394525175, 0.637906696472356, 0.629062573387332, 0.641662304398959, 0.643815876728192, 0.645855016631212, 0.629507326373003, 0.654714156124812, 0.641535736258139, 0.656861216044693, 0.621710598593874, 0.657951857567754, 0.621854492258917, 0.613638517491538, 0.606757505299846, 0.610355529369861, 0.603815408295515, 0.620522023240253, 0.602924460466914, 0.591611669449146, 0.587757287247461, 0.576890993948511, 0.599330498607166, 0.517910611671821, 0.556055352259021, 0.550697820402604, 0.545070139020434, 0.501402859729007, 0.519179283386789, 0.544561905404451, 0.496378893877928, 0.553301131320770, 0.491267752174667, 0.492861434098207, 0.488642770733314, 0.501841627556436, 0.480507914280587, 0.504022405603229, 0.477812478102992, 0.460409049009580, 0.459730255956412, 0.452947122012929, 0.473333278696041, 0.427259047257008, 0.440045310560506, 0.454424453353221, 0.450046283650977, 0.497761162213716, 0.437996347943657, 0.435937919722032, 0.448489153264124, 0.442981321953391, 0.435807292514721, 0.454700804691310, 0.427253004113019, 0.414208791249818, 0.386593521978752, 0.396864865709301, 0.414342719373148, 0.388999948381572, 0.393493050406701, 0.394461904362189, 0.377944077837005, 0.371054030552313, 0.359810921713418, 0.362120863782379]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label Counts:\n",
      " 1    104\n",
      "Name: count, dtype: int64\n",
      "y_pred_actual:\n",
      " 1    81\n",
      "0    23\n",
      "Name: count, dtype: int64\n",
      "Confusion Matrix : \n",
      " [[ 0 23]\n",
      " [ 0 81]]\n",
      "fold number ################################################ 3\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "443     0\n",
      "573     1\n",
      "45      1\n",
      "638     1\n",
      "352     0\n",
      "       ..\n",
      "347     0\n",
      "815     0\n",
      "441     0\n",
      "1021    1\n",
      "448     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_656\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1313 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1315 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1316 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_984 (Dropout)          (1, 1035, 501)       0           ['input_1313[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_328  (1035, 1035)        0           ['input_1315[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1316[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_984 (GraphCo  (1, None, 500)      251000      ['dropout_984[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_328[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_985 (Dropout)          (1, None, 500)       0           ['graph_convolution_984[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_985 (GraphCo  (1, None, 350)      175350      ['dropout_985[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_328[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_986 (Dropout)          (1, None, 350)       0           ['graph_convolution_985[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_986 (GraphCo  (1, None, 128)      44928       ['dropout_986[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_328[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1314 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_328 (GatherIndi  (1, None, 128)      0           ['graph_convolution_986[0][0]',  \n",
      " ces)                                                             'input_1314[0][0]']             \n",
      "                                                                                                  \n",
      " dense_328 (Dense)              (1, None, 2)         258         ['gather_indices_328[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 471,536\n",
      "Trainable params: 471,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 9.8364 - acc: 0.6989 - val_loss: 450.9229 - val_acc: 0.2340 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 487.9945 - acc: 0.2306 - val_loss: 10.7785 - val_acc: 0.2234 - 140ms/epoch - 140ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 16.3542 - acc: 0.4624 - val_loss: 32.3502 - val_acc: 0.7660 - 145ms/epoch - 145ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 40.6489 - acc: 0.7682 - val_loss: 26.2732 - val_acc: 0.7766 - 143ms/epoch - 143ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 37.5972 - acc: 0.7372 - val_loss: 14.6287 - val_acc: 0.7766 - 182ms/epoch - 182ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 17.1406 - acc: 0.7073 - val_loss: 6.7366 - val_acc: 0.7766 - 144ms/epoch - 144ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 10.1667 - acc: 0.7145 - val_loss: 1.2305 - val_acc: 0.5745 - 138ms/epoch - 138ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 2.2347 - acc: 0.5926 - val_loss: 9.2114 - val_acc: 0.2128 - 145ms/epoch - 145ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 8.9154 - acc: 0.3405 - val_loss: 5.4145 - val_acc: 0.2021 - 144ms/epoch - 144ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 5.6220 - acc: 0.3895 - val_loss: 2.0294 - val_acc: 0.2872 - 146ms/epoch - 146ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 2.2159 - acc: 0.4707 - val_loss: 0.5642 - val_acc: 0.7660 - 148ms/epoch - 148ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 0.9163 - acc: 0.7348 - val_loss: 0.6163 - val_acc: 0.7660 - 137ms/epoch - 137ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 1.0242 - acc: 0.7670 - val_loss: 0.6167 - val_acc: 0.7660 - 136ms/epoch - 136ms/step\n",
      "Epoch 14/200\n",
      "1/1 - 0s - loss: 0.9856 - acc: 0.7670 - val_loss: 0.5929 - val_acc: 0.7660 - 141ms/epoch - 141ms/step\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 27.1659 - acc: 0.7692\n",
      "\n",
      "Modality============ 0\n",
      "\tloss: 27.1659\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "train0: (931, 128)\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "443     0\n",
      "573     1\n",
      "45      1\n",
      "638     1\n",
      "352     0\n",
      "       ..\n",
      "347     0\n",
      "815     0\n",
      "441     0\n",
      "1021    1\n",
      "448     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_658\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1317 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1319 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1320 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_987 (Dropout)          (1, 1035, 501)       0           ['input_1317[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_329  (1035, 1035)        0           ['input_1319[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1320[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_987 (GraphCo  (1, None, 500)      251000      ['dropout_987[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_329[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_988 (Dropout)          (1, None, 500)       0           ['graph_convolution_987[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_988 (GraphCo  (1, None, 300)      150300      ['dropout_988[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_329[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_989 (Dropout)          (1, None, 300)       0           ['graph_convolution_988[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_989 (GraphCo  (1, None, 128)      38528       ['dropout_989[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_329[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1318 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_329 (GatherIndi  (1, None, 128)      0           ['graph_convolution_989[0][0]',  \n",
      " ces)                                                             'input_1318[0][0]']             \n",
      "                                                                                                  \n",
      " dense_329 (Dense)              (1, None, 2)         258         ['gather_indices_329[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 440,086\n",
      "Trainable params: 440,086\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 9.8104 - acc: 0.5400 - val_loss: 83.6771 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 130.4311 - acc: 0.7694 - val_loss: 5.6347 - val_acc: 0.7660 - 124ms/epoch - 124ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 14.7349 - acc: 0.7694 - val_loss: 33.1766 - val_acc: 0.2340 - 124ms/epoch - 124ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 31.0806 - acc: 0.3178 - val_loss: 6.4783 - val_acc: 0.2340 - 121ms/epoch - 121ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 6.5070 - acc: 0.4492 - val_loss: 0.9658 - val_acc: 0.7660 - 134ms/epoch - 134ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 2.1372 - acc: 0.7587 - val_loss: 1.4655 - val_acc: 0.7660 - 126ms/epoch - 126ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.9965 - acc: 0.7682 - val_loss: 1.2607 - val_acc: 0.7660 - 122ms/epoch - 122ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 2.5536 - acc: 0.7694 - val_loss: 0.9219 - val_acc: 0.7660 - 136ms/epoch - 136ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.1958 - acc: 0.7682 - val_loss: 0.6334 - val_acc: 0.7660 - 122ms/epoch - 122ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.5960 - acc: 0.7599 - val_loss: 0.5404 - val_acc: 0.7660 - 121ms/epoch - 121ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 1.0917 - acc: 0.7276 - val_loss: 0.8641 - val_acc: 0.2872 - 162ms/epoch - 162ms/step\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 93.4799 - acc: 0.7692\n",
      "\n",
      "Modality============ 1\n",
      "\tloss: 93.4799\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "train1 (931, 128)\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "443     0\n",
      "573     1\n",
      "45      1\n",
      "638     1\n",
      "352     0\n",
      "       ..\n",
      "347     0\n",
      "815     0\n",
      "441     0\n",
      "1021    1\n",
      "448     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_660\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1321 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1323 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1324 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_990 (Dropout)          (1, 1035, 501)       0           ['input_1321[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_330  (1035, 1035)        0           ['input_1323[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1324[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_990 (GraphCo  (1, None, 500)      251000      ['dropout_990[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_330[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_991 (Dropout)          (1, None, 500)       0           ['graph_convolution_990[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_991 (GraphCo  (1, None, 250)      125250      ['dropout_991[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_330[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_992 (Dropout)          (1, None, 250)       0           ['graph_convolution_991[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_992 (GraphCo  (1, None, 128)      32128       ['dropout_992[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_330[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1322 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_330 (GatherIndi  (1, None, 128)      0           ['graph_convolution_992[0][0]',  \n",
      " ces)                                                             'input_1322[0][0]']             \n",
      "                                                                                                  \n",
      " dense_330 (Dense)              (1, None, 2)         258         ['gather_indices_330[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 408,636\n",
      "Trainable params: 408,636\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 13.8022 - acc: 0.7611 - val_loss: 459.2702 - val_acc: 0.2340 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 462.4721 - acc: 0.2306 - val_loss: 38.5663 - val_acc: 0.2340 - 129ms/epoch - 129ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 52.8858 - acc: 0.2843 - val_loss: 13.7075 - val_acc: 0.7660 - 123ms/epoch - 123ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 17.0831 - acc: 0.7694 - val_loss: 15.4656 - val_acc: 0.7660 - 134ms/epoch - 134ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 18.7134 - acc: 0.7694 - val_loss: 12.6717 - val_acc: 0.7660 - 120ms/epoch - 120ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 16.2302 - acc: 0.7670 - val_loss: 8.7322 - val_acc: 0.7660 - 132ms/epoch - 132ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 11.5333 - acc: 0.7611 - val_loss: 4.6236 - val_acc: 0.7660 - 127ms/epoch - 127ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 6.4567 - acc: 0.7467 - val_loss: 1.4032 - val_acc: 0.7660 - 117ms/epoch - 117ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 3.1390 - acc: 0.7204 - val_loss: 1.9185 - val_acc: 0.2340 - 115ms/epoch - 115ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 2.0979 - acc: 0.4851 - val_loss: 2.2022 - val_acc: 0.2340 - 120ms/epoch - 120ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 2.4355 - acc: 0.4170 - val_loss: 0.7265 - val_acc: 0.3617 - 123ms/epoch - 123ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 1.4715 - acc: 0.5102 - val_loss: 0.5760 - val_acc: 0.7660 - 122ms/epoch - 122ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 1.0574 - acc: 0.6679 - val_loss: 0.8106 - val_acc: 0.7660 - 118ms/epoch - 118ms/step\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 13.8160 - acc: 0.7692\n",
      "\n",
      "Modality============ 2\n",
      "\tloss: 13.8160\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "train2: (931, 128)\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "443     0\n",
      "573     1\n",
      "45      1\n",
      "638     1\n",
      "352     0\n",
      "       ..\n",
      "347     0\n",
      "815     0\n",
      "441     0\n",
      "1021    1\n",
      "448     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_662\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1325 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1327 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1328 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_993 (Dropout)          (1, 1035, 501)       0           ['input_1325[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_331  (1035, 1035)        0           ['input_1327[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1328[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_993 (GraphCo  (1, None, 800)      401600      ['dropout_993[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_331[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_994 (Dropout)          (1, None, 800)       0           ['graph_convolution_993[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_994 (GraphCo  (1, None, 400)      320400      ['dropout_994[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_331[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_995 (Dropout)          (1, None, 400)       0           ['graph_convolution_994[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_995 (GraphCo  (1, None, 128)      51328       ['dropout_995[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_331[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1326 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_331 (GatherIndi  (1, None, 128)      0           ['graph_convolution_995[0][0]',  \n",
      " ces)                                                             'input_1326[0][0]']             \n",
      "                                                                                                  \n",
      " dense_331 (Dense)              (1, None, 2)         258         ['gather_indices_331[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 773,586\n",
      "Trainable params: 773,586\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 6.2316 - acc: 0.6786 - val_loss: 571.0536 - val_acc: 0.2340 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 610.1945 - acc: 0.2306 - val_loss: 37.8700 - val_acc: 0.7660 - 148ms/epoch - 148ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 45.2375 - acc: 0.7694 - val_loss: 22.0283 - val_acc: 0.7660 - 248ms/epoch - 248ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 25.1279 - acc: 0.7694 - val_loss: 8.7464 - val_acc: 0.7660 - 150ms/epoch - 150ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 11.8563 - acc: 0.7634 - val_loss: 0.6187 - val_acc: 0.7660 - 144ms/epoch - 144ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 3.6183 - acc: 0.5687 - val_loss: 6.3053 - val_acc: 0.2340 - 139ms/epoch - 139ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 6.8446 - acc: 0.3596 - val_loss: 0.9016 - val_acc: 0.2447 - 153ms/epoch - 153ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 2.3410 - acc: 0.4683 - val_loss: 0.5500 - val_acc: 0.7660 - 171ms/epoch - 171ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 1.2090 - acc: 0.6953 - val_loss: 0.5519 - val_acc: 0.7660 - 141ms/epoch - 141ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 0.9352 - acc: 0.7455 - val_loss: 0.5506 - val_acc: 0.7660 - 148ms/epoch - 148ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.8751 - acc: 0.7634 - val_loss: 0.6853 - val_acc: 0.7660 - 141ms/epoch - 141ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 0.7895 - acc: 0.7646 - val_loss: 0.6861 - val_acc: 0.7660 - 147ms/epoch - 147ms/step\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 38.1110 - acc: 0.7692\n",
      "\n",
      "Modality============ 4\n",
      "\tloss: 38.1110\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "train4: (931, 128)\n",
      "Clinical expanded shape: (931, 128)\n",
      "Clinical test expanded shape: (104, 128)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 0, Loss: 9.758698463439941\n",
      "Attention Weights: tensor([0.1606, 0.1308, 0.0632, 0.2461, 0.3993], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 10, Loss: 1.1498053073883057\n",
      "Attention Weights: tensor([0.1606, 0.1308, 0.0632, 0.2461, 0.3994], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 20, Loss: 0.669633686542511\n",
      "Attention Weights: tensor([0.1606, 0.1308, 0.0632, 0.2461, 0.3994], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 30, Loss: 0.6437521576881409\n",
      "Attention Weights: tensor([0.1606, 0.1308, 0.0632, 0.2461, 0.3994], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 40, Loss: 0.585462749004364\n",
      "Attention Weights: tensor([0.1606, 0.1308, 0.0632, 0.2461, 0.3994], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Random Forest Classifier Accuracy: 0.6442307692307693\n",
      "Logistic Regression Accuracy: 0.3557692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "UserWarning: [15:10:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.7692307692307693\n",
      "Test Accuracies: 0.6442307692307693 0.3557692307692308 0.7692307692307693\n",
      "Validation Accuracies: 0.8502673796791443 0.8609625668449198 0.8556149732620321\n",
      "Final Ensemble Prediction: [0.762501834864521, 0.785231069255160, 0.757879141739437, 0.709102635016245, 0.744294267226432, 0.652203368635588, 0.774816535592886, 0.722732425270697, 0.701156297350633, 0.746979569590686, 0.733941592829700, 0.728718871895549, 0.694549705729311, 0.772827344105226, 0.689411487142829, 0.750112159769343, 0.754143384828579, 0.688183218945893, 0.687373885922789, 0.723112954054291, 0.740050018378800, 0.650972333710795, 0.598160890110468, 0.672551309673643, 0.661002221263243, 0.724056789215464, 0.603038893796736, 0.605090473943195, 0.639065106703064, 0.600090233536786, 0.588538955413736, 0.629094551033847, 0.652489807035774, 0.608364982823816, 0.606964851711743, 0.574246419881313, 0.591178626611693, 0.600164251693996, 0.595462833993789, 0.551101740631598, 0.616513597185660, 0.553207719781803, 0.551822645884128, 0.574371514522316, 0.542926204659210, 0.573480150956602, 0.528238484075464, 0.537460968828723, 0.565153877358299, 0.551750423252726, 0.528893122048048, 0.544248839917891, 0.562271601509926, 0.569693973284049, 0.559442412616074, 0.533557266977156, 0.571270106101696, 0.568833680907983, 0.513538793596115, 0.510164206642810, 0.505651115003113, 0.565954090344883, 0.500994898771347, 0.498530211664286, 0.486968607256022, 0.517252241671307, 0.483877497193173, 0.501420576721272, 0.463465037447234, 0.470872388035192, 0.477780786080341, 0.523185447338909, 0.488363994445522, 0.497108571004915, 0.473398611652167, 0.509987328586134, 0.447050510915206, 0.460431668587713, 0.430056836709327, 0.434764390329418, 0.469770148039719, 0.430850468527826, 0.443397669019969, 0.436009379868517, 0.453786428424314, 0.450575987050632, 0.476977425801531, 0.470280040326725, 0.438911779864044, 0.424056269684639, 0.458817821702423, 0.486125884613758, 0.426361692510347, 0.436801991587254, 0.422416530607281, 0.392349627596405, 0.429752584907317, 0.377439927903876, 0.434025440431653, 0.422619613343714, 0.402978914151478, 0.408456106247935, 0.390256637607015, 0.379661089125134]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label Counts:\n",
      " 1    104\n",
      "Name: count, dtype: int64\n",
      "y_pred_actual:\n",
      " 1    80\n",
      "0    24\n",
      "Name: count, dtype: int64\n",
      "Confusion Matrix : \n",
      " [[ 0 24]\n",
      " [ 0 80]]\n",
      "fold number ################################################ 4\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "448     0\n",
      "576     1\n",
      "45      1\n",
      "637     1\n",
      "368     0\n",
      "       ..\n",
      "352     0\n",
      "808     0\n",
      "447     0\n",
      "1022    1\n",
      "452     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_664\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1329 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1331 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1332 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_996 (Dropout)          (1, 1035, 501)       0           ['input_1329[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_332  (1035, 1035)        0           ['input_1331[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1332[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_996 (GraphCo  (1, None, 500)      251000      ['dropout_996[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_332[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_997 (Dropout)          (1, None, 500)       0           ['graph_convolution_996[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_997 (GraphCo  (1, None, 350)      175350      ['dropout_997[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_332[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_998 (Dropout)          (1, None, 350)       0           ['graph_convolution_997[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_998 (GraphCo  (1, None, 128)      44928       ['dropout_998[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_332[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1330 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_332 (GatherIndi  (1, None, 128)      0           ['graph_convolution_998[0][0]',  \n",
      " ces)                                                             'input_1330[0][0]']             \n",
      "                                                                                                  \n",
      " dense_332 (Dense)              (1, None, 2)         258         ['gather_indices_332[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 471,536\n",
      "Trainable params: 471,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 10.0329 - acc: 0.7360 - val_loss: 594.5002 - val_acc: 0.2340 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 621.9487 - acc: 0.2306 - val_loss: 67.5593 - val_acc: 0.2340 - 130ms/epoch - 130ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 73.3610 - acc: 0.2306 - val_loss: 5.4058 - val_acc: 0.7660 - 164ms/epoch - 164ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 6.5437 - acc: 0.7622 - val_loss: 5.2663 - val_acc: 0.7660 - 142ms/epoch - 142ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 7.4345 - acc: 0.7694 - val_loss: 2.7551 - val_acc: 0.7660 - 127ms/epoch - 127ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 5.1407 - acc: 0.7682 - val_loss: 0.7808 - val_acc: 0.7660 - 138ms/epoch - 138ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.0765 - acc: 0.7443 - val_loss: 2.2733 - val_acc: 0.2340 - 133ms/epoch - 133ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.8627 - acc: 0.4588 - val_loss: 2.0072 - val_acc: 0.2340 - 130ms/epoch - 130ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.0053 - acc: 0.3895 - val_loss: 1.0412 - val_acc: 0.2234 - 134ms/epoch - 134ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.1882 - acc: 0.5078 - val_loss: 0.5513 - val_acc: 0.7660 - 136ms/epoch - 136ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.8121 - acc: 0.7467 - val_loss: 0.5735 - val_acc: 0.7660 - 128ms/epoch - 128ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 0.9709 - acc: 0.7658 - val_loss: 0.5707 - val_acc: 0.7660 - 134ms/epoch - 134ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 0.9309 - acc: 0.7646 - val_loss: 0.5471 - val_acc: 0.7660 - 132ms/epoch - 132ms/step\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.1368 - acc: 0.7692\n",
      "\n",
      "Modality============ 0\n",
      "\tloss: 5.1368\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "train0: (931, 128)\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "448     0\n",
      "576     1\n",
      "45      1\n",
      "637     1\n",
      "368     0\n",
      "       ..\n",
      "352     0\n",
      "808     0\n",
      "447     0\n",
      "1022    1\n",
      "452     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_666\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1333 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1335 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1336 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_999 (Dropout)          (1, 1035, 501)       0           ['input_1333[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_333  (1035, 1035)        0           ['input_1335[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1336[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_999 (GraphCo  (1, None, 500)      251000      ['dropout_999[0][0]',            \n",
      " nvolution)                                                       'squeezed_sparse_conversion_333[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1000 (Dropout)         (1, None, 500)       0           ['graph_convolution_999[0][0]']  \n",
      "                                                                                                  \n",
      " graph_convolution_1000 (GraphC  (1, None, 300)      150300      ['dropout_1000[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_333[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1001 (Dropout)         (1, None, 300)       0           ['graph_convolution_1000[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1001 (GraphC  (1, None, 128)      38528       ['dropout_1001[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_333[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1334 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_333 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1001[0][0]', \n",
      " ces)                                                             'input_1334[0][0]']             \n",
      "                                                                                                  \n",
      " dense_333 (Dense)              (1, None, 2)         258         ['gather_indices_333[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 440,086\n",
      "Trainable params: 440,086\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 20.8706 - acc: 0.2951 - val_loss: 160.1906 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 188.9918 - acc: 0.7694 - val_loss: 54.6762 - val_acc: 0.7660 - 120ms/epoch - 120ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 65.5900 - acc: 0.7694 - val_loss: 13.0134 - val_acc: 0.7660 - 117ms/epoch - 117ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 18.0985 - acc: 0.7694 - val_loss: 1.4486 - val_acc: 0.2553 - 123ms/epoch - 123ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 3.9135 - acc: 0.6714 - val_loss: 9.3718 - val_acc: 0.2447 - 118ms/epoch - 118ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 8.4823 - acc: 0.5137 - val_loss: 4.8532 - val_acc: 0.2340 - 116ms/epoch - 116ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 4.5797 - acc: 0.5329 - val_loss: 1.7935 - val_acc: 0.2234 - 146ms/epoch - 146ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.8461 - acc: 0.5687 - val_loss: 0.5427 - val_acc: 0.7660 - 114ms/epoch - 114ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 0.9504 - acc: 0.7384 - val_loss: 0.6020 - val_acc: 0.7660 - 113ms/epoch - 113ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.0779 - acc: 0.7682 - val_loss: 0.6363 - val_acc: 0.7660 - 117ms/epoch - 117ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 1.2352 - acc: 0.7694 - val_loss: 0.6160 - val_acc: 0.7660 - 125ms/epoch - 125ms/step\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 160.7500 - acc: 0.7692\n",
      "\n",
      "Modality============ 1\n",
      "\tloss: 160.7500\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "train1 (931, 128)\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "448     0\n",
      "576     1\n",
      "45      1\n",
      "637     1\n",
      "368     0\n",
      "       ..\n",
      "352     0\n",
      "808     0\n",
      "447     0\n",
      "1022    1\n",
      "452     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_668\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1337 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1339 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1340 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1002 (Dropout)         (1, 1035, 501)       0           ['input_1337[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_334  (1035, 1035)        0           ['input_1339[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1340[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1002 (GraphC  (1, None, 500)      251000      ['dropout_1002[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_334[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1003 (Dropout)         (1, None, 500)       0           ['graph_convolution_1002[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1003 (GraphC  (1, None, 250)      125250      ['dropout_1003[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_334[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1004 (Dropout)         (1, None, 250)       0           ['graph_convolution_1003[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1004 (GraphC  (1, None, 128)      32128       ['dropout_1004[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_334[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1338 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_334 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1004[0][0]', \n",
      " ces)                                                             'input_1338[0][0]']             \n",
      "                                                                                                  \n",
      " dense_334 (Dense)              (1, None, 2)         258         ['gather_indices_334[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 408,636\n",
      "Trainable params: 408,636\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 15.8355 - acc: 0.3477 - val_loss: 130.9958 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 160.8283 - acc: 0.7694 - val_loss: 43.2468 - val_acc: 0.7660 - 124ms/epoch - 124ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 59.9418 - acc: 0.7694 - val_loss: 9.6842 - val_acc: 0.7660 - 111ms/epoch - 111ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 16.8123 - acc: 0.7694 - val_loss: 2.1558 - val_acc: 0.7660 - 110ms/epoch - 110ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 4.3860 - acc: 0.7646 - val_loss: 3.9865 - val_acc: 0.2340 - 109ms/epoch - 109ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 3.2095 - acc: 0.4731 - val_loss: 3.6603 - val_acc: 0.2340 - 110ms/epoch - 110ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 3.4268 - acc: 0.4074 - val_loss: 1.4181 - val_acc: 0.2340 - 115ms/epoch - 115ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.8246 - acc: 0.4707 - val_loss: 0.7362 - val_acc: 0.2872 - 107ms/epoch - 107ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 1.0643 - acc: 0.6667 - val_loss: 0.5281 - val_acc: 0.7660 - 107ms/epoch - 107ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 0.9520 - acc: 0.7527 - val_loss: 0.5230 - val_acc: 0.7660 - 120ms/epoch - 120ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 1.0803 - acc: 0.7634 - val_loss: 0.5196 - val_acc: 0.7660 - 116ms/epoch - 116ms/step\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 142.4855 - acc: 0.7692\n",
      "\n",
      "Modality============ 2\n",
      "\tloss: 142.4855\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "train2: (931, 128)\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "448     0\n",
      "576     1\n",
      "45      1\n",
      "637     1\n",
      "368     0\n",
      "       ..\n",
      "352     0\n",
      "808     0\n",
      "447     0\n",
      "1022    1\n",
      "452     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_670\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1341 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1343 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1344 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1005 (Dropout)         (1, 1035, 501)       0           ['input_1341[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_335  (1035, 1035)        0           ['input_1343[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1344[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1005 (GraphC  (1, None, 800)      401600      ['dropout_1005[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_335[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1006 (Dropout)         (1, None, 800)       0           ['graph_convolution_1005[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1006 (GraphC  (1, None, 400)      320400      ['dropout_1006[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_335[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1007 (Dropout)         (1, None, 400)       0           ['graph_convolution_1006[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1007 (GraphC  (1, None, 128)      51328       ['dropout_1007[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_335[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1342 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_335 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1007[0][0]', \n",
      " ces)                                                             'input_1342[0][0]']             \n",
      "                                                                                                  \n",
      " dense_335 (Dense)              (1, None, 2)         258         ['gather_indices_335[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 773,586\n",
      "Trainable params: 773,586\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 6.8086 - acc: 0.6487 - val_loss: 106.2198 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 130.5334 - acc: 0.7694 - val_loss: 72.1043 - val_acc: 0.2340 - 136ms/epoch - 136ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 57.7158 - acc: 0.2867 - val_loss: 8.8488 - val_acc: 0.7660 - 135ms/epoch - 135ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 10.3897 - acc: 0.7694 - val_loss: 7.7474 - val_acc: 0.7660 - 136ms/epoch - 136ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 11.9170 - acc: 0.7694 - val_loss: 3.3594 - val_acc: 0.7660 - 162ms/epoch - 162ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 5.8278 - acc: 0.7694 - val_loss: 1.3601 - val_acc: 0.7660 - 129ms/epoch - 129ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.6310 - acc: 0.7658 - val_loss: 0.7358 - val_acc: 0.4043 - 129ms/epoch - 129ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.3565 - acc: 0.6619 - val_loss: 1.6140 - val_acc: 0.2340 - 129ms/epoch - 129ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 1.5020 - acc: 0.5448 - val_loss: 1.0314 - val_acc: 0.2447 - 176ms/epoch - 176ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.3279 - acc: 0.5245 - val_loss: 0.6570 - val_acc: 0.7660 - 125ms/epoch - 125ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.9493 - acc: 0.6022 - val_loss: 0.6084 - val_acc: 0.7660 - 128ms/epoch - 128ms/step\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 115.1038 - acc: 0.7692\n",
      "\n",
      "Modality============ 4\n",
      "\tloss: 115.1038\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "train4: (931, 128)\n",
      "Clinical expanded shape: (931, 128)\n",
      "Clinical test expanded shape: (104, 128)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 0, Loss: 1.1741256713867188\n",
      "Attention Weights: tensor([0.0403, 0.2697, 0.3096, 0.2096, 0.1708], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 10, Loss: 1.5665444135665894\n",
      "Attention Weights: tensor([0.0403, 0.2697, 0.3097, 0.2096, 0.1708], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 20, Loss: 1.1027206182479858\n",
      "Attention Weights: tensor([0.0403, 0.2697, 0.3096, 0.2096, 0.1708], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 30, Loss: 0.7349872589111328\n",
      "Attention Weights: tensor([0.0403, 0.2697, 0.3096, 0.2096, 0.1708], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 40, Loss: 0.5323690176010132\n",
      "Attention Weights: tensor([0.0403, 0.2697, 0.3097, 0.2096, 0.1708], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Random Forest Classifier Accuracy: 0.5961538461538461\n",
      "Logistic Regression Accuracy: 0.6442307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "UserWarning: [15:10:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.7692307692307693\n",
      "Test Accuracies: 0.5961538461538461 0.6442307692307693 0.7692307692307693\n",
      "Validation Accuracies: 0.8502673796791443 0.8877005347593583 0.8074866310160428\n",
      "Final Ensemble Prediction: [0.473947371479003, 0.466936411994375, 0.499524931897065, 0.460201246978335, 0.409022566611136, 0.404358601170453, 0.406027547853283, 0.456017619927047, 0.463409923656767, 0.376241527724953, 0.475717801468338, 0.451928389268795, 0.443465227255385, 0.455099029951803, 0.499500437793205, 0.465278653618592, 0.441468218630579, 0.431267437033401, 0.499700394953467, 0.485279662788644, 0.495464052602253, 0.467388147694417, 0.481588921562272, 0.508638715318471, 0.478630181814483, 0.492961302875732, 0.483444797380634, 0.473456375462958, 0.485384230077914, 0.447002273234961, 0.510314533950469, 0.516007040195008, 0.456860600444565, 0.494739571998086, 0.520353629446593, 0.522548411968014, 0.507530410421209, 0.490606396176220, 0.523033597390217, 0.489596752495007, 0.525437561623588, 0.561603336867580, 0.500345974769187, 0.529438118603833, 0.530500909581678, 0.508290757152571, 0.531211005404916, 0.539976116939588, 0.596116030950942, 0.569753923246104, 0.571581945544510, 0.589082028163212, 0.584394801048493, 0.555635726417754, 0.565174538615999, 0.606986393964459, 0.567028459127009, 0.531970793468752, 0.567030971261570, 0.582096441373464, 0.578319385343985, 0.585947123729368, 0.583364798163244, 0.609843076641243, 0.591681675098838, 0.587577928267448, 0.608863898440044, 0.589178807738038, 0.604503843760068, 0.573220941297877, 0.614845359891688, 0.575929079505579, 0.586029321022205, 0.619425207740261, 0.600415182927483, 0.602919073997952, 0.623264025457532, 0.586592852297351, 0.656334025099257, 0.608063929157589, 0.633280627071401, 0.631289234488073, 0.639789450736571, 0.642403485425829, 0.645464474575821, 0.659592485864957, 0.629842438011707, 0.655927650875265, 0.660723699096982, 0.639999966212859, 0.625496921513946, 0.648179042540091, 0.697427630879281, 0.674340082619457, 0.660897078932209, 0.678656458905221, 0.668650790145179, 0.682917612328428, 0.662729874591031, 0.744780096028786, 0.686139588084354, 0.681905397957531, 0.711283226502614, 0.700372201243679]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0EAAAIjCAYAAADFthA8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABtk0lEQVR4nO3dd3gU5f7+8XvTQwg1gSQQegtdQBABAUGqSJEjKEgR8ByFrwUrnp8CKsXGQVERlSbYQAHRIyJdQZHeOwKhhBJaCIQAyfz+eA6LMQGSJckkmffruuaCmZ2Z/ezs7GbunWeecVmWZQkAAAAAHMLL7gIAAAAAIDsRggAAAAA4CiEIAAAAgKMQggAAAAA4CiEIAAAAgKMQggAAAAA4CiEIAAAAgKMQggAAAAA4CiEIAAAAgKMQggA4wrBhw+RyubLluZo1a6ZmzZq5x5cuXSqXy6VvvvkmW56/T58+KlOmTLY8l6fi4+PVv39/hYWFyeVy6amnnrK7pFRuZZ/JDe+BdG3fXLp0qXtaZtc+ZcoUuVwu7d+/P9PWCQC3ihAEINe5elB1dQgICFBERIRat26t9957T+fOncuU5zly5IiGDRumDRs2ZMr6MlNOri09Ro4cqSlTpuixxx7TtGnT9PDDD1933jJlysjlcqlly5ZpPv7JJ5+494U1a9ZkVclZolmzZin25SJFiuj222/XpEmTlJycbHd5GTJy5EjNmTPH7jIAIF187C4AADz16quvqmzZsrp8+bKOHj2qpUuX6qmnntKYMWM0d+5c1axZ0z3v//t//08vvvhihtZ/5MgRDR8+XGXKlFHt2rXTvdzPP/+coefxxI1q++STT3L8AfTixYt1xx13aOjQoemaPyAgQEuWLNHRo0cVFhaW4rHPP/9cAQEBunjxYlaUmuVKliypUaNGSZJOnDihzz77TP369dOuXbs0evTobK/H0/1n5MiR6tq1qzp16pRi+sMPP6zu3bvL398/kyoEgFvHmSAAuVbbtm3Vs2dP9e3bV0OGDNH8+fO1cOFCHT9+XPfdd58SEhLc8/r4+CggICBL67lw4YIkyc/PT35+fln6XDfi6+ub4w84jx8/rkKFCqV7/kaNGil//vz6+uuvU0w/dOiQfv31V7Vv3z6TK8w+BQsWVM+ePdWzZ089/fTTWrFihUqWLKn3339fly9fTnOZ5OTkLAt9mb3/eHt7KyAgINuaowJAehCCAOQpd999t15++WUdOHBA06dPd09P6/qOBQsWqHHjxipUqJDy58+vypUr66WXXpJkrpW4/fbbJUl9+/Z1N1eaMmWKJNOMqXr16lq7dq3uuusu5cuXz73s368JuiopKUkvvfSSwsLCFBQUpPvuu08HDx5MMU+ZMmXUp0+fVMv+dZ03qy2tazrOnz+vZ555RpGRkfL391flypX19ttvy7KsFPO5XC4NGjRIc+bMUfXq1eXv769q1arpp59+SnuD/83x48fVr18/FS9eXAEBAapVq5amTp3qfvzqNSj79u3Tf//7X3ftN7teJCAgQF26dNEXX3yRYvqXX36pwoULq3Xr1mkut3jxYjVp0kRBQUEqVKiQOnbsqO3bt6eab/ny5br99tsVEBCg8uXLa8KECdetZfr06apbt64CAwNVpEgRde/ePdX7eCvy5cunO+64Q+fPn9eJEyckXXtfPv/8c1WrVk3+/v7u9+Tw4cN65JFHVLx4cff7NWnSpFTrPXTokDp16qSgoCAVK1ZMTz/9tBITE1PNl9b+k5ycrHfffVc1atRQQECAQkND1aZNG3fzQ5fLpfPnz2vq1Knu9/Tqfny9a4I+/PBD92uJiIjQwIEDdebMmRTzXP2cbdu2Tc2bN1e+fPlUokQJvfnmm6nqHjdunKpVq6Z8+fKpcOHCqlevXqr9BQCuojkcgDzn4Ycf1ksvvaSff/5ZAwYMSHOerVu36t5771XNmjX16quvyt/fX3v27NGKFSskSVFRUXr11Vf1yiuv6NFHH1WTJk0kSXfeead7HSdPnlTbtm3VvXt39ezZU8WLF79hXSNGjJDL5dILL7yg48ePa+zYsWrZsqU2bNigwMDAdL++9NT2V5Zl6b777tOSJUvUr18/1a5dW/Pnz9dzzz2nw4cP6z//+U+K+ZcvX65Zs2bp8ccfV3BwsN577z3df//9io6OVtGiRa9bV0JCgpo1a6Y9e/Zo0KBBKlu2rGbOnKk+ffrozJkzevLJJxUVFaVp06bp6aefVsmSJfXMM89IkkJDQ2/6uh966CG1atVKe/fuVfny5SVJX3zxhbp27SpfX99U8y9cuFBt27ZVuXLlNGzYMCUkJGjcuHFq1KiR1q1b5z7Q37x5s1q1aqXQ0FANGzZMV65c0dChQ9N8P0eMGKGXX35ZDzzwgPr3768TJ05o3Lhxuuuuu7R+/foMnd26kT///FPe3t4p1rd48WLNmDFDgwYNUkhIiMqUKaNjx47pjjvucIek0NBQzZs3T/369VNcXJy7w4mEhAS1aNFC0dHReuKJJxQREaFp06Zp8eLF6aqnX79+mjJlitq2bav+/fvrypUr+vXXX7Vy5UrVq1dP06ZNU//+/VW/fn09+uijkuR+j9IybNgwDR8+XC1bttRjjz2mnTt3avz48Vq9erVWrFiR4v08ffq02rRpoy5duuiBBx7QN998oxdeeEE1atRQ27ZtJZkmfE888YS6du2qJ598UhcvXtSmTZv0xx9/6KGHHsrg1gfgCBYA5DKTJ0+2JFmrV6++7jwFCxa0brvtNvf40KFDrb9+5f3nP/+xJFknTpy47jpWr15tSbImT56c6rGmTZtakqyPPvoozceaNm3qHl+yZIklySpRooQVFxfnnj5jxgxLkvXuu++6p5UuXdrq3bv3Tdd5o9p69+5tlS5d2j0+Z84cS5L1+uuvp5iva9eulsvlsvbs2eOeJsny8/NLMW3jxo2WJGvcuHGpnuuvxo4da0mypk+f7p526dIlq2HDhlb+/PlTvPbSpUtb7du3v+H6/j7vlStXrLCwMOu1116zLMuytm3bZkmyli1bluY+Ubt2batYsWLWyZMnU7wWLy8vq1evXu5pnTp1sgICAqwDBw64p23bts3y9vZOsc/s37/f8vb2tkaMGJGivs2bN1s+Pj4ppv/9Pbiepk2bWlWqVLFOnDhhnThxwtq+fbv1xBNPWJKsDh06uOeTZHl5eVlbt25NsXy/fv2s8PBwKzY2NsX07t27WwULFrQuXLhgWda192bGjBnuec6fP29VqFDBkmQtWbLkurUvXrzYkmQ98cQTqepPTk52/z8oKCjNfffqe7Nv3z7Lsizr+PHjlp+fn9WqVSsrKSnJPd/7779vSbImTZqUYvtIsj777DP3tMTERCssLMy6//773dM6duxoVatWLdVzA8D10BwOQJ6UP3/+G/YSd/UX9u+++87jTgT8/f3Vt2/fdM/fq1cvBQcHu8e7du2q8PBw/fjjjx49f3r9+OOP8vb21hNPPJFi+jPPPCPLsjRv3rwU01u2bJniV/yaNWuqQIEC+vPPP2/6PGFhYXrwwQfd03x9ffXEE08oPj5ey5Ytu6XX4e3trQceeEBffvmlJNMhQmRkpPtM2F/FxMRow4YN6tOnj4oUKZLitdxzzz3ubZ6UlKT58+erU6dOKlWqlHu+qKioVE3sZs2apeTkZD3wwAOKjY11D2FhYapYsaKWLFni0evasWOHQkNDFRoaqqioKI0bN07t27dP1aStadOmqlq1qnvcsix9++236tChgyzLSlFT69atdfbsWa1bt06SeW/Cw8PVtWtX9/L58uVzn7W5kW+//VYulyvNTiw8uc5n4cKFunTpkp566il5eV07DBkwYIAKFCig//73vynmz58/v3r27Oke9/PzU/369VPsj4UKFdKhQ4e0evXqDNcDwJkIQQDypPj4+BSB4++6deumRo0aqX///ipevLi6d++uGTNmZCgQlShRIkMdIFSsWDHFuMvlUoUKFbL8/ikHDhxQREREqu0RFRXlfvyv/hoGripcuLBOnz590+epWLFiigPbGz2PJx566CFt27ZNGzdu1BdffKHu3buneSB+9bkqV66c6rGoqCjFxsa6r7lJSEhI9d6ktezu3btlWZYqVqzoDi1Xh+3bt+v48eMevaYyZcpowYIFWrhwoZYvX66jR4/qhx9+UEhISIr5ypYtm2L8xIkTOnPmjD7++ONU9VwN51drOnDggCpUqJBqW6W1ff5u7969ioiISBEmb8X13hs/Pz+VK1cu1X5SsmTJVHX/fX984YUXlD9/ftWvX18VK1bUwIED3U1bASAtXBMEIM85dOiQzp49qwoVKlx3nsDAQP3yyy9asmSJ/vvf/+qnn37S119/rbvvvls///yzvL29b/o8GbmOJ72u98t6UlJSumrKDNd7HutvnSjYoUGDBipfvryeeuop7du3L1uv90hOTpbL5dK8efPS3Eb58+f3aL1BQUHXvQfSX/19f7sa2Hv27KnevXunucxfu4nPrdKzP0ZFRWnnzp364Ycf9NNPP+nbb7/Vhx9+qFdeeUXDhw/PrlIB5CKEIAB5zrRp0yTpuj2GXeXl5aUWLVqoRYsWGjNmjEaOHKl///vfWrJkiVq2bJnpXfru3r07xbhlWdqzZ0+KA9XChQun6iFLMr+elytXzj2ekdpKly6thQsX6ty5cynOBu3YscP9eGYoXbq0Nm3apOTk5BRngzL7eR588EG9/vrrioqKuu79m64+186dO1M9tmPHDoWEhCgoKEgBAQEKDAxM9d6ktWz58uVlWZbKli2rSpUq3foLuUWhoaEKDg5WUlLSTUNU6dKltWXLFlmWlWLfSWv7/F358uU1f/58nTp16oZng9K7T/71vfnrPn3p0iXt27cvXYEwLUFBQerWrZu6deumS5cuqUuXLhoxYoSGDBmS5d3jA8h9aA4HIE9ZvHixXnvtNZUtW1Y9evS47nynTp1KNe3qAfXVboODgoIkKc1Q4onPPvssxXVK33zzjWJiYtw9XEnmgHPlypW6dOmSe9oPP/yQqgvmjNTWrl07JSUl6f33308x/T//+Y9cLleK578V7dq109GjR1Pcy+fKlSsaN26c8ufPr6ZNm2bK8/Tv319Dhw7VO++8c915wsPDVbt2bU2dOjXFNtqyZYt+/vlntWvXTpI5y9C6dWvNmTNH0dHR7vm2b9+u+fPnp1hnly5d5O3treHDh6c6K2ZZlk6ePJkJry79vL29df/99+vbb7/Vli1bUj1+tXttybw3R44c0TfffOOeduHCBX388cc3fZ77779flmWleUblr9shKCgoXftjy5Yt5efnp/feey/F8hMnTtTZs2c9uufT37e9n5+fqlatKsuyrnuvJQDOxpkgALnWvHnztGPHDl25ckXHjh3T4sWLtWDBApUuXVpz58694a+/r776qn755Re1b99epUuX1vHjx/Xhhx+qZMmSaty4sSQTSAoVKqSPPvpIwcHBCgoKUoMGDVJdm5FeRYoUUePGjdW3b18dO3ZMY8eOVYUKFVJ0492/f3998803atOmjR544AHt3btX06dPT9XdcEZq69Chg5o3b65///vf2r9/v2rVqqWff/5Z3333nZ566qkbdmWcEY8++qgmTJigPn36aO3atSpTpoy++eYbrVixQmPHjr3hNVoZUbp0aQ0bNuym87311ltq27atGjZsqH79+rm7yC5YsGCK5YcPH66ffvpJTZo00eOPP+4ObtWqVdOmTZvc85UvX16vv/66hgwZov3796tTp04KDg7Wvn37NHv2bD366KN69tlnM+U1ptfo0aO1ZMkSNWjQQAMGDFDVqlV16tQprVu3TgsXLnSH/QEDBuj9999Xr169tHbtWoWHh2vatGnKly/fTZ+jefPmevjhh/Xee+9p9+7datOmjZKTk/Xrr7+qefPmGjRokCSpbt26WrhwocaMGaOIiAiVLVtWDRo0SLW+0NBQDRkyRMOHD1ebNm103333aefOnfrwww91++23p+gEIb1atWqlsLAwNWrUSMWLF9f27dv1/vvvq3379pm23wHIY2zokQ4AbsnVLnevDn5+flZYWJh1zz33WO+++26Krpiv+nsX2YsWLbI6duxoRUREWH5+flZERIT14IMPWrt27Uqx3HfffWdVrVrV8vHxSdElddOmTa/bJe/1usj+8ssvrSFDhljFihWzAgMDrfbt26folvmqd955xypRooTl7+9vNWrUyFqzZk2qdd6otrS6Zz537pz19NNPWxEREZavr69VsWJF66233krRxbFlma6YBw4cmKqm63Xd/XfHjh2z+vbta4WEhFh+fn5WjRo10uzG25Musm/ket2mL1y40GrUqJEVGBhoFShQwOrQoYO1bdu2VMsvW7bMqlu3ruXn52eVK1fO+uijj1LtM1d9++23VuPGja2goCArKCjIqlKlijVw4EBr586d7nky0kV2erp2vt77Yllmmw8cONCKjIy0fH19rbCwMKtFixbWxx9/nGK+AwcOWPfdd5+VL18+KyQkxHryySetn3766aZdZFuWZV25csV66623rCpVqlh+fn5WaGio1bZtW2vt2rXueXbs2GHdddddVmBgoCXJvb/8vYvsq95//32rSpUqlq+vr1W8eHHrscces06fPp2u7fP3GidMmGDdddddVtGiRS1/f3+rfPny1nPPPWedPXs27Q0KwPFclpUDrnQFAAAAgGzCNUEAAAAAHIUQBAAAAMBRCEEAAAAAHIUQBAAAAMBRCEEAAAAAHIUQBAAAAMBRcvXNUpOTk3XkyBEFBwfL5XLZXQ4AAAAAm1iWpXPnzikiIkJeXjc+15OrQ9CRI0cUGRlpdxkAAAAAcoiDBw+qZMmSN5wnV4eg4OBgSeaFFihQwOZqAAAAANglLi5OkZGR7oxwI7k6BF1tAlegQAFCEAAAAIB0XSZDxwgAAAAAHIUQBAAAAMBRCEEAAAAAHIUQBAAAAMBRCEEAAAAAHIUQBAAAAMBRCEEAAAAAHIUQBAAAAMBRCEEAAAAAHIUQBAAAAMBRCEEAAAAAHIUQBAAAAMBRCEEAAAAAHIUQBAAAAMBRCEEAAAAAHMXWEJSUlKSXX35ZZcuWVWBgoMqXL6/XXntNlmXZWRYAAACAPMzHzid/4403NH78eE2dOlXVqlXTmjVr1LdvXxUsWFBPPPGEnaUBAAAAyKNsDUG//fabOnbsqPbt20uSypQpoy+//FKrVq2ysywAAAAAeZitIejOO+/Uxx9/rF27dqlSpUrauHGjli9frjFjxqQ5f2JiohITE93jcXFx2VUqAACZIjo6WrGxsRleLiQkRKVKlcqCigDAeWwNQS+++KLi4uJUpUoVeXt7KykpSSNGjFCPHj3SnH/UqFEaPnx4NlcJAEDmiI6OVpUqUUpIuJDhZQMD82nHju0EIQDIBLaGoBkzZujzzz/XF198oWrVqmnDhg166qmnFBERod69e6eaf8iQIRo8eLB7PC4uTpGRkdlZMgAAHouNjVVCwgV17jxdoaFR6V7uxIntmj27p2JjYwlBAJAJbA1Bzz33nF588UV1795dklSjRg0dOHBAo0aNSjME+fv7y9/fP7vLBAAgU4WGRik8vI7dZQCAY9naRfaFCxfk5ZWyBG9vbyUnJ9tUEQAAAIC8ztYzQR06dNCIESNUqlQpVatWTevXr9eYMWP0yCOP2FkWAAAAgDzM1hA0btw4vfzyy3r88cd1/PhxRURE6J///KdeeeUVO8sCAAAAkIfZGoKCg4M1duxYjR071s4yAAAAADiIrdcEAQAAAEB2IwQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRCEAAAAABHIQQBAAAAcBRbQ1CZMmXkcrlSDQMHDrSzLAAAAAB5mI+dT7569WolJSW5x7ds2aJ77rlH//jHP2ysCgAAAEBeZmsICg0NTTE+evRolS9fXk2bNrWpIgAAAAB5na0h6K8uXbqk6dOna/DgwXK5XGnOk5iYqMTERPd4XFxcdpUHAAAAII/IMR0jzJkzR2fOnFGfPn2uO8+oUaNUsGBB9xAZGZl9BQIAAADIE3JMCJo4caLatm2riIiI684zZMgQnT171j0cPHgwGysEAAAAkBfkiOZwBw4c0MKFCzVr1qwbzufv7y9/f/9sqgoAAABAXpQjzgRNnjxZxYoVU/v27e0uBQAAAEAeZ3sISk5O1uTJk9W7d2/5+OSIE1MAAAAA8jDbQ9DChQsVHR2tRx55xO5SAAAAADiA7adeWrVqJcuy7C4DAAAAgEPYfiYIAAAAALITIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAoxCCAAAAADgKIQgAAACAo9gegg4fPqyePXuqaNGiCgwMVI0aNbRmzRq7ywIAAACQR/nY+eSnT59Wo0aN1Lx5c82bN0+hoaHavXu3ChcubGdZAAAAAPIwW0PQG2+8ocjISE2ePNk9rWzZsjZWBAAAACCvszUEzZ07V61bt9Y//vEPLVu2TCVKlNDjjz+uAQMGpDl/YmKiEhMT3eNxcXHZVSqAXCI6OlqxsbEZXi4kJESlSpXKgooAAEBOY2sI+vPPPzV+/HgNHjxYL730klavXq0nnnhCfn5+6t27d6r5R40apeHDh9tQKYDcIDo6WlWqRCkh4UKGlw0MzKcdO7YThAAAcABbQ1BycrLq1aunkSNHSpJuu+02bdmyRR999FGaIWjIkCEaPHiwezwuLk6RkZHZVi+AnC02NlYJCRfUufN0hYZGpXu5Eye2a/bsnoqNjSUEAQDgALaGoPDwcFWtWjXFtKioKH377bdpzu/v7y9/f//sKA1ALhYaGqXw8Dp2lwEAAHIoW7vIbtSokXbu3Jli2q5du1S6dGmbKgIAAACQ19kagp5++mmtXLlSI0eO1J49e/TFF1/o448/1sCBA+0sCwAAAEAeZmsIuv322zV79mx9+eWXql69ul577TWNHTtWPXr0sLMsAAAAAHmYrdcESdK9996re++91+4yAAAAADiErWeCAAAAACC7EYIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOIqtIWjYsGFyuVwphipVqthZEgAAAIA8zsfuAqpVq6aFCxe6x318bC8JAAAAQB5me+Lw8fFRWFiY3WUAAAAAcAjbQ9Du3bsVERGhgIAANWzYUKNGjVKpUqXSnDcxMVGJiYnu8bi4uOwqEwAAwBbR0dGKjY3N8HIhISHXPaYCnM7WENSgQQNNmTJFlStXVkxMjIYPH64mTZpoy5YtCg4OTjX/qFGjNHz4cBsqBQAAyH7R0dGqUiVKCQkXMrxsYGA+7dixnSAEpMHWENS2bVv3/2vWrKkGDRqodOnSmjFjhvr165dq/iFDhmjw4MHu8bi4OEVGRmZLrQAAANktNjZWCQkX1LnzdIWGRqV7uRMntmv27J6KjY0lBAFpsL053F8VKlRIlSpV0p49e9J83N/fX/7+/tlcFQAAgL1CQ6MUHl7H7jKAPCNH3ScoPj5ee/fuVXh4uN2lAAAAAMijbA1Bzz77rJYtW6b9+/frt99+U+fOneXt7a0HH3zQzrIAAAAA5GG2Noc7dOiQHnzwQZ08eVKhoaFq3LixVq5cqdDQUDvLAgAAAJCH2RqCvvrqKzufHgAAAIAD5ahrggAAAAAgqxGCAAAAADgKIQgAAACAoxCCAAAAADiKRyHozz//zOw6AAAAACBbeBSCKlSooObNm2v69Om6ePFiZtcEAAAAAFnGoxC0bt061axZU4MHD1ZYWJj++c9/atWqVZldGwAAAABkOo9CUO3atfXuu+/qyJEjmjRpkmJiYtS4cWNVr15dY8aM0YkTJzK7TgAAAADIFLfUMYKPj4+6dOmimTNn6o033tCePXv07LPPKjIyUr169VJMTExm1QkAAAAAmeKWQtCaNWv0+OOPKzw8XGPGjNGzzz6rvXv3asGCBTpy5Ig6duyYWXUCAAAAQKbw8WShMWPGaPLkydq5c6fatWunzz77TO3atZOXl8lUZcuW1ZQpU1SmTJnMrBUAAAAAbplHIWj8+PF65JFH1KdPH4WHh6c5T7FixTRx4sRbKg4AAAAAMptHIWj37t03ncfPz0+9e/f2ZPUAAAAAkGU8uiZo8uTJmjlzZqrpM2fO1NSpU2+5KAAAAADIKh6FoFGjRikkJCTV9GLFimnkyJG3XBQAAAAAZBWPQlB0dLTKli2banrp0qUVHR19y0UBAAAAQFbxKAQVK1ZMmzZtSjV948aNKlq06C0XBQAAAABZxaMQ9OCDD+qJJ57QkiVLlJSUpKSkJC1evFhPPvmkunfvntk1AgAAAECm8ah3uNdee0379+9XixYt5ONjVpGcnKxevXpxTRAAAACAHM2jEOTn56evv/5ar732mjZu3KjAwEDVqFFDpUuXzuz6AAAAACBTeRSCrqpUqZIqVaqUWbUAAAAAQJbzKAQlJSVpypQpWrRokY4fP67k5OQUjy9evDhTigMAAACAzOZRCHryySc1ZcoUtW/fXtWrV5fL5crsugAAAAAgS3gUgr766ivNmDFD7dq1y+x6AAAAACBLedRFtp+fnypUqJDZtQAAAABAlvMoBD3zzDN69913ZVlWZtcDAAAAAFnKo+Zwy5cv15IlSzRv3jxVq1ZNvr6+KR6fNWtWphQHAAAAAJnNoxBUqFAhde7cObNrAQAAAIAs51EImjx5cmbXAQAAAADZwqNrgiTpypUrWrhwoSZMmKBz585Jko4cOaL4+PhMKw4AAAAAMptHZ4IOHDigNm3aKDo6WomJibrnnnsUHBysN954Q4mJifroo48yu04AAAAAyBQenQl68sknVa9ePZ0+fVqBgYHu6Z07d9aiRYsyrTgAAAAAyGwenQn69ddf9dtvv8nPzy/F9DJlyujw4cOZUhgAAAAAZAWPzgQlJycrKSkp1fRDhw4pODj4losCAAAAgKziUQhq1aqVxo4d6x53uVyKj4/X0KFD1a5du8yqDQAAAAAynUfN4d555x21bt1aVatW1cWLF/XQQw9p9+7dCgkJ0ZdffpnZNQIAAABApvEoBJUsWVIbN27UV199pU2bNik+Pl79+vVTjx49UnSUAAAAAAA5jUchSJJ8fHzUs2fPzKwFAAAAALKcRyHos88+u+HjvXr18qgYAAAAAMhqHoWgJ598MsX45cuXdeHCBfn5+SlfvnyEIAAAAAA5lke9w50+fTrFEB8fr507d6px48Z0jAAAAAAgR/MoBKWlYsWKGj16dKqzRAAAAACQk2RaCJJMZwlHjhzJzFUCAAAAQKby6JqguXPnphi3LEsxMTF6//331ahRo0wpDAAAAACygkchqFOnTinGXS6XQkNDdffdd+udd97xqJDRo0dryJAhevLJJzV27FiP1gEAAAAAN+NRCEpOTs7UIlavXq0JEyaoZs2ambpeAAAAAPi7TL0myBPx8fHq0aOHPvnkExUuXNjucgAAAADkcR6dCRo8eHC65x0zZswNHx84cKDat2+vli1b6vXXX7/hvImJiUpMTHSPx8XFpbsOICeKjo5WbGxshpcLCQlRqVKlsqCi6/O01sTERPn7+2d4OTteI3K33PR5yg3YngDyMo9C0Pr167V+/XpdvnxZlStXliTt2rVL3t7eqlOnjns+l8t1w/V89dVXWrdunVavXp2u5x01apSGDx/uSclAjhMdHa0qVaKUkHAhw8sGBubTjh3bs+1A41ZqlVySrAwvld2vEblbbvo85QZsTwB5nUchqEOHDgoODtbUqVPdTdhOnz6tvn37qkmTJnrmmWduuo6DBw/qySef1IIFCxQQEJCu5x0yZEiKs1BxcXGKjIz05CUAtouNjVVCwgV17jxdoaFR6V7uxIntmj27p2JjY7PtIMPTWnfv/lFLlrys5s3fV8WKDdO9nB2vEblbbvo85QZsTwB5nUch6J133tHPP/+c4hqewoUL6/XXX1erVq3SFYLWrl2r48ePpzhzlJSUpF9++UXvv/++EhMT5e3tnWIZf39/j5rVADlZaGiUwsPr3HzGHCCjtcbGbpckFS5cIde8RuRuuenzlBuwPQHkVR6FoLi4OJ04cSLV9BMnTujcuXPpWkeLFi20efPmFNP69u2rKlWq6IUXXkgVgAAAAAAgM3gUgjp37qy+ffvqnXfeUf369SVJf/zxh5577jl16dIlXesIDg5W9erVU0wLCgpS0aJFU00HAAAAgMziUQj66KOP9Oyzz+qhhx7S5cuXzYp8fNSvXz+99dZbmVogAAAAAGQmj0JQvnz59OGHH+qtt97S3r17JUnly5dXUFDQLRWzdOnSW1oeAAAAAG7mlm6WGhMTo5iYGFWsWFFBQUGyrIx3gwsAAAAA2cmjEHTy5Em1aNFClSpVUrt27RQTEyNJ6tevX7p6hgMAAAAAu3gUgp5++mn5+voqOjpa+fLlc0/v1q2bfvrpp0wrDgAAAAAym0fXBP3888+aP3++SpYsmWJ6xYoVdeDAgUwpDAAAAACygkdngs6fP5/iDNBVp06d4mamAAAAAHI0j0JQkyZN9Nlnn7nHXS6XkpOT9eabb6p58+aZVhwAAAAAZDaPmsO9+eabatGihdasWaNLly7p+eef19atW3Xq1CmtWLEis2sEAAAAgEzj0Zmg6tWra9euXWrcuLE6duyo8+fPq0uXLlq/fr3Kly+f2TUCAAAAQKbJ8Jmgy5cvq02bNvroo4/073//OytqAgAAAIAsk+EzQb6+vtq0aVNW1AIAAAAAWc6j5nA9e/bUxIkTM7sWAAAAAMhyHnWMcOXKFU2aNEkLFy5U3bp1FRQUlOLxMWPGZEpxAAAAAJDZMhSC/vzzT5UpU0ZbtmxRnTp1JEm7du1KMY/L5cq86gAAAAAgk2UoBFWsWFExMTFasmSJJKlbt2567733VLx48SwpDgAAAAAyW4auCbIsK8X4vHnzdP78+UwtCAAAAACykkcdI1z191AEAAAAADldhkKQy+VKdc0P1wABAAAAyE0ydE2QZVnq06eP/P39JUkXL17Uv/71r1S9w82aNSvzKgQAAACATJShENS7d+8U4z179szUYgAAAAAgq2UoBE2ePDmr6gAAAACAbHFLHSMAAAAAQG5DCAIAAADgKIQgAAAAAI5CCAIAAADgKIQgAAAAAI5CCAIAAADgKIQgAAAAAI5CCAIAAADgKIQgAAAAAI5CCAIAAADgKIQgAAAAAI5CCAIAAADgKIQgAAAAAI5CCAIAAADgKIQgAAAAAI5CCAIAAADgKIQgAAAAAI5CCAIAAADgKIQgAAAAAI5CCAIAAADgKIQgAAAAAI5CCAIAAADgKIQgAAAAAI5CCAIAAADgKLaGoPHjx6tmzZoqUKCAChQooIYNG2revHl2lgQAAAAgj7M1BJUsWVKjR4/W2rVrtWbNGt19993q2LGjtm7damdZAAAAAPIwHzufvEOHDinGR4wYofHjx2vlypWqVq2aTVUByKmuXJGOH5eOHpXOnJHOnzfDhQvm8ejoIpJ6ac+ewjp3TvL3N0P+/FK+fJIXDYCRh1y5IsXHS5cumf9fvixZluTjI/n6mn/z5zefAQBASraGoL9KSkrSzJkzdf78eTVs2DDNeRITE5WYmOgej4uLy67ygDwhOjpasbGxGV5u+/btWVBN2ixLiovzk9RFo0Z5KyHhpKKj/XX4sL9On/aRZblusHQZSVO1eHHqR1wuKShIKlBAKlxYKlLEDKGhUlKSSUeevM6QkBCVKlUqw8t5+l4kJibK34OjWk/rdApP3ntP3ov0PE9ionTqlAn6Z85IZ89KJ06UkbRYXbtG6cIF6dy5a+H/Zvz8LOXLd0XBwUkqUuTK/4bLCgu7pLCwS4qIuKQSJS4pJOSyXK7015lTePpZkrL/85vXP4dsF+QmtoegzZs3q2HDhrp48aLy58+v2bNnq2rVqmnOO2rUKA0fPjybKwTyhujoaFWpEqWEhHQeOaUhPv5cJlZkXLkiHTok7d8vHTwoxcRICQnVJX2rb75Ja4kkScclnZIUL+m8pARJliSXJC8VL36HvLwK69Il6eJFc7bIssyv5vHx0pEjf19nLUm71LPnBknTJK2QtF7SlZvWHxiYTzt2bM/QH/Bbey9cMq81Yzyp0wni42MkudSzZ08PlvbsvTDPe05XrkixsdKxY+YM54kT5v9p/75XRFJz7duX9vp8fMzgcl07K3TVpUsuXbrkqzNnfHXw4I2qOi1py1+Gu3TyZILCwz16idniVr/Xsvvzm5c/h2wX5Da2h6DKlStrw4YNOnv2rL755hv17t1by5YtSzMIDRkyRIMHD3aPx8XFKTIyMjvLBXKt2NhYJSRcUOfO0xUaGpWhZXfv/lFLlrysixcvZkotZ85IO3ZIu3dL0dHmoO2vvLySlJy8XmFhQYqMLKCCBRNVoECi8uW7rICAK39p1uYrqdD/hmt1Nmr0k2rUaO1eX3KyCULx8eZX9VOnrg3Hj0vnz7skVfzf8A9Jkrd3sooVO6/ixc+rePF4FS9+XgEBSSnqPHFiu2bP7qnY2NgM/fH29L24+vqaN39fFSumfcY8LZ7W6QQXL56RZGV4m2b0vbAs6dw5P23cuFfbtx/VDz/U0blzZnpagoKkQoXMULCgZFkH9fvvz2v8+Fd1xx0VVbCgOauZP7/k5yf3GZy/Pl9SkrRixQY1a9ZBLVqMV758FZWQ4KuEBB8lJPgqPt5P5875KT7eDJZVWFKT/w3Gt99K8+dLkZHXhvBwyds73ZsqS93K91p2f37z+ueQ7YLcxvYQ5OfnpwoVKkiS6tatq9WrV+vdd9/VhAkTUs3r7+/vUTMQANeEhkYpPLxOhpaJjb31pjGnT0ubNknbt5tfu/8qKEgqW1YqXVoqUUI6fnyG5sx5SHfemTLMeFqnl5cUHGyGtH7VXr36W/3443hVq/ahLl+upIMHpYQEL8XEBCsmJtg9X4kSUoUKUsWKUkREusu6roy+F1dfX+HCFTL8HuLGMrpNb/ZeWJa5du3AAXOGMzrahHCpuqRrZ3sCAqTixaVixVIOAQEp1xcTc0K///6V6td/TrVr37w+l8ucGQoOTpZ0SOXLRyg8vPJ15796VurqGak9ew7p6NFLksopPt58bq+2kPPxMZ+FyEipVCnzufXzu3lNWcmT77Xc+Jy5AdsFuYXtIejvkpOTU1z3AyD3unzZR9KjWrasvk6evDbd5TIHT5Urm1AREpLyl+zY2ORsrTMg4KKkRapceZ9q1KgkyzIHhAcPXhtOnpQOHzbDsmWmo4WIiDKSHtLp0znkZ3HY6vx5ae9eM+zZk/qaHS8vqVChEzp1aoruuKOF7ryzjvLnT30Wxw4+PlJYmBkkqVixZZo1q6fuu2+BihZtqejoa5+FhAQT7g4cMPN6e5sgVL68VKhQwPWfBAByEFtD0JAhQ9S2bVuVKlVK586d0xdffKGlS5dq/vz5dpYF4BYdPy6tXi1t2NBFUjedPGkO9MqWlWrUkCpVMiEip3K5TIcJoaFSnf/9oBkXZw5s9+wxB7kXLkh79hSR9LlatbJ0113S/fdLnTubX8nhBF46ebKQFi82+8TfrzXz8zNh/+oQESHt2PGzZs16XhERPyk4OO215iQ+Pknu+iWl+oFg/37TvPXPP80gVZW0XyNG5NPDD0v33GPO9AJATmNrCDp+/Lh69eqlmJgYFSxYUDVr1tT8+fN1zz332FkWAA9YljkQXLHCHBgZvpK2q3p1L7VqVTlXHPRdT4ECJhDVqWOutTh4UNqw4ag2bjym5ORaWrpUWrpU+r//kxo2NIHo/vulMmVsLhyZKinJ7N/r19eXdFjLloWleDwszJwRqVDBNBfLKdfOZJa//0BgWeYs6dUfCPbvT1ZSUmnNmiXNmiUFBkrt2kn/+If5Nzd/BwDIW2wNQRMnTrTz6QFkguRkads2E36OHjXTXC6pShUpJGShfv31HlWq9JOCg69/PUJu4+1two2//xFt3FhX33+/Wbt2Vde330q//Sb9/rsZnn1WqltXeuABMxCIcqfLl03A37FD2rnT9DhoOtGQfH0vq1IlX1WoYMKP0w7yXS7TnDUkRLrjDungwY2aNOnf6tZtilatKqZ9+0znCt9+a65zatNG6tpVuvde0+EDANglx10TBCB3sCxzofSSJaZ5jGRu0Fi3rjkYKlhQ2rz52I1XkkdERFzSvfdKgwebJlGzZ0vffCP98ou0dq0ZXnhBql9f6tZNqlLF1+6ScROJiab3wu3bzb9/7XI6KEgKDd2t/fsHqX37Z1SrViv7Cs1hfHwsSfP0/POHdNttxbR+vfkszJxpzhTNmWMGPz9zZqhXL/MvfR4ByG6EIAAZtmePtGjRtTM/AQEm+NSvb5q/OFlEhDRwoBmOHzeBaMYM01Ru1SozSDUk/aotW0KVP7/zzh7kVBcvmjM927aZMz9Jf+kRvWBBc3YzKso0c9u6dZX27/9ZXl6Dr79Ch3O5rjUhHTFC2rz5WiDaseNaICpcWOre3QSiBg1yRkcRAPI+QhCAdIuLC9L06eYAUTK/5t5xh7kG5u9d+sJ0dfzPf5rh6FHTJOjrr6Xlyy1ZVmP99ptpPle6tFStmlS1KheRZzfTg2EP/fbbbfruu5TBp2hRE3qiokzX6hyce87lkmrWNMOrr5pANG2a9Pnn5uzp+PFmqFhR6tlT6t3bfC4AIKsQggDc1KVLfpLGadGiO2VZpqvf+vWlJk1ydi9vOUlY2LUzRD/9tEVt236q4sVH6Nix/O7uhufNMz3oVa1qDrzZtlkjMfHaGZ/du7tK6uY+qxkSci2QhoYSfLJKjRrSm29Ko0aZJrWffWY6Uti9Wxo6VBo2TGrVSnr0UalDB9PUFgAyEyEIwHVZlrRxo/Tzzx0kBciyTJOge+6RihSxu7rcq1ixy5LeU8eOvRUYWEfbtklbt5pfxK92Nfzjj1K5cuaAvEoVzrTdqsREadcus5337PnrGR9vSdtVpYqvmjevoGLFbCzSgby9pZYtzfDhh6b56NSpprnt/PlmKF5c6tNH6t/f9LoHAJmBEAQgTSdOSP/979UbIgZI2qLGjRPUosXtNleWtxQqJN15pxlOnzYH6Vu3muZzV7sd/uEH0/NYgQJlJHEBUXpdDT7mjE/qpm7Vqkm+vj9o0aIOqlr1JxUrxhG2nfLnlx5+2Ax790oTJ0qTJ5vPwhtvmKF5c+lf/zL34+LsEIBbQQgCkEJysunuetkyc9Do4yNVrrxeW7c2ULFi39tdXp5WuLDUuLEZTp6UtmwxB/DHj5uDeamRpONaufKsXC5z01k/P5uLzmHOn/fVmjWmudu+famDT9WqJvwUK2aaum3efNa+YnFd5ctLI0dKw4ebH2M++cQ0F12yxAwRESYM3XEHhzEAPMO3BwC3Y8ek776TYmLMeMWKpvvagwe3aevWyzdeGJmqaFGpaVMzHD9uzg6tW3dW8fEFdeRIgL791vwSXqmSuX6ofHlnNpmzLBMWP/00TNIf+vzzGikeL1Lk2jU+xYtzjU9u4+srdepkhuho6dNPpY8/Nk1HX3lF8vWtLukzHT+eT+HhNhcLIFchBAFQcrLppWzJEvP/qzc1rFnTHDQePGh3hc5WrJgZihb9QbNnv6nKlWfp+PHyKZrPuVxSyZLmmokKFfJ2b2axseaakYULpQULrjbZjPjfYLZDpUpXb9ibd7eD05QqZXqW+3//z3S1PW6ctHKll6SHNWeO6X6+fn0Ten04ugFwE3xNAA535oy5V4c5kDQHj/fey71rciJzML9J1artUbdu5RUTYwLQrl0mGBw8aIYlS0zPcuXLm84VAgNzd5u5hARp+XITeBYulNavT/l4QIB0++1n9euvz6hnzydUvnxNewpFtvDzkx56yAzTp+/Qww+vlJdXLx054qU5c6SffzY3ba5XTypQwO5qAeRUhCDAwTZvNu3tExPNgUWbNlLt2vxynhu4XOa6iIgI01vfmTPmYvI9e0zvchcumPd382ZJqi7pqJ55xl/t2pn7OtWtmzNvbJucbELdH39cu7nsxo3S5b+1xqxRw/Qods890l13STt37lXduhOVL9/j9hQOW1StekFSX/XoUUeHD9fUmjVSXJz0668mOFevbvZ3msoB+DtCEOBAV66Yi4zXrTPjJUua3pbo9jr3KlTIBJu6dU1nAIcOmR7RDhyQjhxJVnJycS1dKi1daub39TWBt3ZtEyhq1jTXFmXnvXEuXJB27JC7i/DVq80QF5d63hIlTOBp2VJq0cLcdwm4KjDwipo0kRo1MvvUqlVm37/6Q0CZMqYHxgoV+JEHgEEIAhwmLs5P339/rfODu+4yF997edlbFzKPt7dUurQZJOngwY2aNGmgnnxyhqKjS+q330wnGFdDx18FB5sDxfLlTTguUcIMxYqZ3uuuDgEB5uzh3/ebpCQpPl46d86EmVOnzHMdO2a6Ot6/3/Tatn+/dPiw6djg7wIDTZirX19q0MD8W7o0B6+4OS8v0wlG1armO+73303HGfv3myE01JwZqlHjZmsCkNcRggBHuVezZlXRpUvmQLNLF24+6AQ+Ppak39Wr13HVqVNSlmUOCFetMr+Sb9pk/j1wwISX9etTX3dz/XWb0HXlSsruqNMrJMQcsEZFSXXqmNDDhe3IDOHh5juuRQvTvHLtWnP/s7lzTccaUVFhkjj9DTgVf2YAB7hyRRo3LkLS97p0yfzC37WrVLCg3ZXBDi6XVLasGbp1uzb94kVzlmb3bnNd0eHD14bYWHMz19OnzXxXXblihr/z8TEXpRcubLqmvjqULm2aJpUtazptCA3N8pcLhytYUGrVypz1XrfOBKK4OGnNmghJ0XrzzfMaOdLsjwCcgxAE5HHHjkkPPigtWWIuoqhe/bg6dSomb2+bC0OOExBgzshERd14vsTEa8OlS9duquvtbYb8+SV/f5qvIWcJCDDXBTVoYK5B++WXCzp5Mkhffx2kmTOl7t2lF1+kqRzgFFwFAORhq1ZJt912tcvkJEnddOedhwhAuCX+/uYsT2iouV6oVCnTS13x4qZ5W0AAAQg5l7e36QikS5cdku7WnXeeVXKy9MUXZnrHjuZsEYC8jRAE5FFffWU6PIiJMddcfPbZDkkz7C4LAHIEE9SXaNy4vVq3TvrHP8y0uXOlO+4w1xItWpR25x0Acj9CEJDHWJY0fLhpAnfxornx6cqVUtmyiXaXBgA50m23STNmSNu3S337muadixebLtnvuEP67jtzDysAeQchCMhDEhLMXdSHDTPjzzwjzZljuj0GANxY5crSpEnmxsP/93+maeeqVVKnTqap3Oefp90RCIDchxAE5BFHj0rNm5tmcD4+0qefSm+/La7/AYAMKlVKeu890238kCHmGritW6WePaWuXatKepgzQ0AuRwgC8oCNG80NJf/4QypSRFqwQOrXz+6qACB3K1ZMGjnShKERI0zHHwcPBkj6TDNnVtXGjTSTA3IrQhCQy82bJzVqJB08KFWqZK7/adbM7qoAIO8oVEh66SVzH63/+7/DkmJ19myA5syRPvzQ3HCYMATkLoQgIBebMkXq0EE6f970ZLRypVSxot1VAUDelD+/1KfPMUllVL/+YQUGSidPSrNnE4aA3IYQBORSkyYVV9++5kaVPXtKP/4oFS5sd1UA4ATnVbv2MT35pPkB6u9haPNmwhCQ0xGCgFzG/GF9Tx98UEKS9Pzz0tSpkp+frWUBgOP4+0uNG0tPPindffe1MDRrljR+vLRtG/cZAnIqH7sLAJB+V65IixaVlVRHkvSf/0hPPWVrSQDgeP7+UpMmpoOaVauk336TYmOlmTOliIhrZ4sA5ByEICCXuHjRdH994EBhSZc0cuRhPfVUWbvLAgD8z1/D0O+/m+HIEWnaNKlEiQqS6tldIoD/oTkckAucOydNnmy6afX1TZLURq1bn7a7LABAGvz9TS+dTzwhNWhg7td2+HABSav1/PNltWOH3RUCIAQBOdzp0yYAHT9ueibq0GGXpCV2lwUAuImgIKlNG2nQIKlSpZOSkrVoUWFVqyb1729ubQDAHoQgIAc7ccIEoNOnTc9vjzwihYQk2F0WACADChWSmjU7IKmmmjY9o+RkaeJEc0uDZ581nSkAyF6EICCHiokx9wE6d04KDZX69qULbADI3bZqzJg/9dtv0l13SYmJ0jvvSOXLS2+9ZcYBZA9CEJADRUebbq8vXJDCw6U+faTgYLurAgBkhoYNpaVLpXnzpNq1pbNnze0OqlSRZsygW20gOxCCgBxm715p+nTzi2CpUlLv3lK+fHZXBQDITC6XuV5ozRrT7DkiQtq/X+rWTbrzTtOzHICsQwgCcpDt26Uvv5QuX5YqVJB69jS9DAEA8iZvb3O2f9cuafhw86PXypUmCD3wgHToEHfCBrICIQjIITZtMjfWS0qSqlaVuneXfH3trgoAkB2CgqRXXpH27JH69TNnimbOlLp2rSrpdV2+zCEbkJn4RAE5wIYN0uzZph147drS/febXwcBAM4SHi59+qm0fr3UooX+F37+ra+/rqrNm7leCMgshCDAZtu3F9V335n/160r3Xef5MUnEwAcrVYtacEC6e2390r6Uxcu+GnWLHP9UEyM3dUBuR+HWoCtHtOvv5aWJNWvL7Vvb5pAAADgcknNm5+VVFX16h2Rr6+5werHH0vffy+dP293hUDuRQgCbPLFF6GSPpQk3XGH6SWIAAQASC1Rdeoc1aBBUvXqZsq6ddL770urV0vJyfZWB+RGhCDABm+/Lb3zTqQkqVato2rVigAEALixAgXMNaN9+0phYdLFi9KPP0oTJ0pHjthdHZC7EIKAbDZqlPTcc1fHXlP9+kcIQACAdCtVShowQGrb1txG4cgR6ZNPTCC6eNHu6oDcgRAEZKNXX5Veesn8/5//PCLpFQIQACDDvLzMtaQDB0o1aphpq1ebJnKbNtGLHHAzhCAgG1iW9PLL0tChZnzkSOnRR4/aWxQAINcLDpa6dJF69ZKKFjWdJcyeLf3wQ0VJFe0uD8ixbA1Bo0aN0u23367g4GAVK1ZMnTp10s6dO+0sCch0liUNGSK9/roZf+stMw4AQGYpW1b617+ku++WfHykmJhgSZs0cWKYLl2yuzog57E1BC1btkwDBw7UypUrtWDBAl2+fFmtWrXSefp8RB5hWdKzz0pvvGHGx4414wAAZDYfH6lJE+nxx6WSJeMkBejDDyNUr570xx92VwfkLLaGoJ9++kl9+vRRtWrVVKtWLU2ZMkXR0dFau3atnWUBmcKypKeflsaMMeMffCA9+aS9NQEA8r7ChaW2bfdI6qmCBa9o82apYUPpqaek+Hi7qwNyBh+7C/irs2fPSpKKFCmS5uOJiYlKTEx0j8fFxWVLXbgmOjpasbGxGV4uJCREpUqVyoKKcoa/bxfLkt56q6S+/rqYJOnf/z6gO+44qXXrri2zffv2W3rOjC5/q8+H68st74Unz5vXP7u5TV7e1xITE+Xv75/lz3Or68gt36Wm053P9e23z2vKlJqaPl16911zvdD48VK7dnZXeOs4JsGtyDEhKDk5WU899ZQaNWqk6lfvBPY3o0aN0vDhw7O5MlwVHR2tKlWilJBwIcPLBgbm044d2/Pkl07a22WcpEH/+39/jRgxUSNGpL18fPy5DD1ffHyMJJd69uzpQbUZfz5cX255L26lzrz82c1NnLCvSS5JnnVp5snryy3b9FYVLnxF06ZJPXuaa4b275fat5ceftiEosKF7a7QMxyT4FblmBA0cOBAbdmyRcuXL7/uPEOGDNHgwYPd43FxcYqMjMyO8iApNjZWCQkX1LnzdIWGRqV7uRMntmv27J6KjY3Nk184f90uISFRWrEiUtu2hUqydNdd0apS5XFJj6dabvfuH7Vkycu6mMGbOly8eEaSpebN31fFig3TvZynz4fryy3vhad15vXPbm6S1/e1q3Vm5+vLLds0s7RuLW3ZIr3yirk+ddo0aeFCacIEqUMHu6vLOI5JcKtyRAgaNGiQfvjhB/3yyy8qWbLkdefz9/fP8KlyZL7Q0CiFh9exu4wcJyQkSuvW1dG2bWa8Y0eXatcuLal0mvPHxt5ak4rChStk6H241efD9eWW9yKjdSLnyav72tU67Xh9uWWbZoagIOmdd6SuXaW+faWdO6X77jNnid59V7rO1Qg5Gsck8JStHSNYlqVBgwZp9uzZWrx4scqWLWtnOcAtcOnXX0vpap8enTpJtWvbWQ8AAGlr2FBav156/nlz09Xp06Vq1aS5c+2uDMg+toaggQMHavr06friiy8UHByso0eP6ujRo0pISLCzLCBDkpMl6WPt2BEil0vq3FmqVcvuqgAAuL7AQHP7ht9+k6pUkY4elTp2lHr0kE6dsrs6IOvZGoLGjx+vs2fPqlmzZgoPD3cPX3/9tZ1lAemWnCy99lopSf3lclnq1EmqWdPuqgAASJ8GDcxZoRdeMGeFvvjC/B1buNDuyoCsZXtzuLSGPn362FkWkC5JSVK/ftLcuSGSktS8+X4CEAAg1wkIkEaPNmeFKlWSDh+W7rnH3NuOxjnIq2wNQUBulZQkPfKINGWK5O1tSXpIFSqctrssAAA8dvWs0OP/69D0vfekunWV4h53QF5BCAIyKClJ6tNH+uwzydtbGjFin6QZdpcFAMAty5dP+uAD6ccfpbAwaft2E45GjjR//4C8ghAEZMCVK1KvXqYnHR8f6euvpXvuOWN3WQAAZKq2baXNm6X77zd/+/79b+muu6Q//7S7MiBzEIKAdLoagL744loAuv9+u6sCACBrhIRIM2dKU6dKwcHmmqFataSJEyXLsrs64NYQgoB0uHLF3Ezuyy9NAJo5U+rSxe6qAADIWi6X+QFw0yZzJig+Xurf39wO4vhxu6sDPEcIAm7i8mXpoYfMmR9fX+mbb8zNUAEAcIoyZaTFi6U33zR/C7/7TqpRQ/r5Z7srAzxDCAJu4PJl6cEHzZkfX1/p22/NzeQAAHAab2/pueek1aul6tXNmaDWraXnn5cuX3bZXR6QIYQg4DouXZK6dTPBx89Pmj1b6tDB7qoAALBXrVrSqlXXutJ+6y3pkUcqSSpva11ARhCCgDQkJkoPPGCCj7+/NGeO1L693VUBAJAzBAaarrRnzZIKF5a2bQuStF67dxe2uzQgXQhBwN9cuGCavH333bUA1Lat3VUBAJDzdO4sbdwo3XbbOUnBWrKkrObMMT8mAjkZIQj4i3PnpHbtpPnzzQ3j/vtfqU0bu6sCACDnioyUPvpot6ShcrksbdwoffyxdOSI3ZUB10cIAv7nzBmpVStp2TJzP4T586UWLeyuCgCAnM/HR5Je1b337lKBAtKpU+Z+Qr//zj2FkDMRggBJsbHS3XdLK1eats2LFkmNG9tdFQAAuUt4+Hn9619SlSpScrLpQvuLL6Tz5+2uDEiJEATHi4mRmjWT1q+XihWTli6Vbr/d7qoAAMidAgNN50Lt25szRHv2SB99JO3fb3dlwDWEIDjawYNS06bS1q1SRIRpClezpt1VAQCQu7lcUr16Uv/+UkiIFB8vffaZ9OuvNI9DzkAIgmPt3Ss1aSLt3i2VLi398os5fQ8AADJH8eLSgAHmB0bLkhYvlj7/nOZxsB8hCI60Y4d0113SgQNSxYrml6ny3OMNAIBM5+cndeok3XefaR63d680YYL5GwzYhRAEx9m0yQSgI0ekatXMGaDISLurAgAg73K5pNtuu9Y87tw5aepUaf364pJcdpcHByIEwVFWrTKdIJw4IdWpYzpBCAuzuyoAAJzhavO4GjVM87jVq0tI+q9On/a2uzQ4DCEIjrFggekG+/Rp6Y47TDfYISF2VwUAgLP4+UmdO0sdOkje3smS2uqhh6K0fLndlcFJCEFwhBkzTFed589L99xjAlGhQnZXBQCAM7lcpkVGp047Je3U8eN+atZMeuMNc38hIKsRgpDnjR8vde8uXb5s7lvw/fdS/vx2VwUAAIoWTZBUT23anFJSkvTii+YMUWys3ZUhryMEIc+yLOm116THHzf//9e/zF2r/f3trgwAAFwTr9df36+PPzZ/o3/80XSisGKF3XUhLyMEIU9KTpaeekp65RUz/sor0ocfSt5cdwkAQI7jcpkOE/74w9y64tAhczPzN9+keRyyBiEIec7ly1KvXtJ775nxd9+Vhg83X7AAACDnqlVLWrvWNGNPSpJeeMHcX+jkSbsrQ15DCEKeEhdnOkD4/HNzQ7bp06UnnrC7KgAAkF7Bwab5+kcfmeZx//2vaR63cqXdlSEvIQQhzzh82NwEdcECKV8+ae5cqUcPu6sCAAAZ5XJJ//yn9PvvUoUK0sGDUpMm0jvvmOt8gVtFCEKesHWr1LChtHGjVKyYtGyZ1Lat3VUBAIBbcdttpnncP/4hXbkiPfus1LGjdPYsF/ni1hCCkOstWSI1amR+Japc2Zwur1fP7qoAAEBmKFBA+vpr08GRn5+51UWPHlUk1be7NORihCDkap9/LrVuLZ09KzVuLP32m1S2rN1VAQCAzORySY89ZprHlSsnxcT4S/pVmzeH0jwOHiEEIVeyLGnUKKlnz2s3QV2wQCpSxO7KAABAVqlTR1q3TmrR4rQkP/3+e6RmzJASEuyuDLkNIQi5zqVL0qOPSi+9ZMafeUb68kspIMDeugAAQNYrWFB64419kgbJyytZO3ZIH39sOkgC0osQhFwlNla65x7p008lLy9zL6C33zb/BwAAzmDu/feBOnbcpUKFpDNnpEmTzM1WaR6H9ODQEbnG1q1SgwbSL7+Yewh8/730f/9nd1UAAMAuoaEX9M9/SlWqSMnJ0k8/STNnShcv2l0ZcjpCEHKF//7XdIH955/mgsiVK6V27eyuCgAA2C0gwFwb3Lq1aRmyfbtpHnfkiN2VIScjBCFHsyxzY7QOHaRz56SmTc2p7qpV7a4MAADkFC6XdMcd0iOPmGuGTp82zeNWraJ5HNJGCEKOdemS1K+fuTGaZUkDBkg//yyFhNhdGQAAyIlKlJD++U9z38CkJGnePOmbb2geh9QIQciRDh+WmjWTJk82p7bHjpUmTDA3SQMAALiewECpWzepVStzDLFtm2keFxNjd2XISXzsLgD4u2XLTNve48fNKe2vvpLatLG7KgAAkFu4XOZa4shIcybo9Glp4kSpYUOak8DgTBByDMuSxoyRWrQwAahmTWnNGgIQAADwTMmSpnlcpUqmedzy5aUkfalz5zgEdjr2AOQI8fFS9+7mxqdJSVKPHtLvv0sVKthdGQAAyM0CA80xxj33SC6XJam7HnooSr//bndlsBMhCLbbuVOqX1+aMUPy8ZHGjZOmTZPy5bO7MgAAkBe4XNKdd0r33bdT0p86csRfTZpIr71mfnyF8xCCYKtvvpFuv9306R8ebq4HGjTo6p2gAQAAMk/x4hck3aY2bU4pKUl65RXp7rulgwftrgzZjRAEWyQkSP/6l/SPf5j7/9x1l7RunfmVBgAAIOvE6fXX92vqVCl/fumXX6RataRZs+yuC9nJ1hD0yy+/qEOHDoqIiJDL5dKcOXPsLAfZZOtW0/xtwgQz/sIL0sKFUliYvXUBAABncLmkXr2k9etNi5TTp6X775cefVQ6f97u6pAdbA1B58+fV61atfTBBx/YWQayiWVJn3xivmy2bJGKFzc3Px09WvL1tbs6AADgNBUqSMuXSy++aILRJ59I9epJGzfaXRmymq33CWrbtq3atm1rZwnINgX14otltXChGWvVSvrsMxOEAAAA7OLnJ40aJbVsKT38sLRjh2mx8uab0hNPcJ1yXpWrbpaamJioxMRE93hcXJyN1aQWHR2t2NjYDC8XEhKiUqVKZUFF1+dJrdu3b/fouY4dC5K0XgsXFpaPjzRypOkK2ysLz0N6+l4kJibK398/Q8t4ul2A3MKTffxWvtey8/sJyG4Z3Vdvdd/2ZHk7/hZm93ZJS4sW0qZNUr9+0ty50lNPST/+KE2aJJUo4fmxhWTPsZ4nctOx7K3KVSFo1KhRGj58uN1lpCk6OlpVqkQpIeFChpcNDMynHTu2Z9vOcyu1SlJ8/Ll0zXfliuntbcWKSpJcKlEiUbNm+at+fY+eNt1u7fW5JFkePW96twuQW8THx0hyqWfPnhle1tPvtez6fgKy2618nszyGdu3b+35su9vYXZvl5sJCZHmzJHGjzc/2P78s1SjhvTaa7F67jnPv5uy+1jPE7npWDYz5KoQNGTIEA0ePNg9HhcXp8jISBsruiY2NlYJCRfUufN0hYZGpXu5Eye2a/bsnoqNjc22HcfTWnfv/lFLlrysixcv3nTeo0el2bOl48cl82U6TZ9/XkP169f2tOx0u9XX17z5+6pYsWGGl0vPdgFyk4sXz0iyMvyZuJXvtez4fgLs4OnnydN9+1afL7fUmRWfeZdLevxxqXlz0zxu7Vpp0KAQSZ+ofXtflShRPkPrs+NYzxO56Vg2M+SqEOTv75/h07PZLTQ0SuHhdewuI10yWmts7M1PPScnmwsMly0z/8+XT2rU6E8tWNBLwcFrb6XcDPP09RUuXCHTtwuQm2X0M5EZsuL7CcgJsvtvjKfPl1vqzEpRUdLvv0sjRkivv24pKekhLVlySV26+Kl8xnJQrpKbjmVvRa4KQcjZTpwwp5CPHDHjVapI994rxcWdsbMsAAAAj/j6SsOGSeXK7VTv3i5duFBZ06ebnm5btjSdKiB3sjUExcfHa8+ePe7xffv2acOGDSpSpEiuOp3mdMnJ0sqV0uLFUlKSFBAgtW1r2tC6XFIO678CAAAgQ6pXvyCpsapV26+tW4tp9Wppzx7pvvukMmXsrg6esDUErVmzRs2bN3ePX73ep3fv3poyZYpNVSEjjhyRfvhBiokx4xUqSB06SAUK2FsXAABA5kpQo0aHdNttxTR3rrnB6tSpnBXKrWwNQc2aNZNledb7COx16ZK0ZIn0xx/mJqgBAdI990i33UZ/+gAAIO8qX1567DFpwQJp3Tpp9Wpp927zI3C5cnZXh/TimiBkWExMiBYtks6eNePVq0utW0v589tbFwAAQHYICDChp1o16fvvpTNnpGnTpDp1zA3hc3g/XhAhCBlw8WKApK/0++91JUmFCknt25smcAAAAE5Trpw5K7RwoTkjtG6duVbo3nulihXtrg43QgjCTSUlmWZvS5Z0kOQnlytZd9zhpWbNaP8KAACczc9PatdOqlpV7muFvvjCjLdpY3d1uB5CEG5o925p/nzp5ElJ8pO0Ss2bX1GTJnfaXBkAAEDOUaaMOSu0ZInpNXfbNmnvXqlevRBJXnaXh7/hHUGaTp40v2J88YX5f1CQVKfO75LuUKFC5+wuDwAAIMfx9TXXBD36qFSihJSYKK1YUUrSCu3aFWh3efgLQhBSSEw0vZ18+KE5C+TlJTVsKA0aJJUp86ckevMDAAC4kbAw6ZFHTDM5X98kSXeoZ88qeu456fx5u6uDRAjC/yQlmQv6xo2TfvvN3AC1QgVzWrdVK9MLCgAAANLHy8vcQ+iBB7ZJmqGkJJfefluKipJmzDC3GIF9CEEOZ1nSli3mzM+PP5pfJ4oUkR58UOrRQwoJsbtCAACA3Cso6LKkbho7do/KlJEOHpS6dZOaN5c2bbK7OuciBDnYoUPB+uQT6dtvpVOnzHU/7dpJjz8uVapkd3UAAAB5R5Mmcdq2TRo+3LSwWbbM3GR+0CBzHIbsRQhyoO3bAyXN148/VlRMjOnasVkz6YknzGlbb2+7KwQAAMh7AgOlV16RduyQ/vEPc/nBBx+YH58/+shcnoDsQQhykLVrpY4dpZ49oyS1kpdXsho0MOGnaVPu+QMAAJAdSpc21wUtXixVr2564n3sMalOHennn+2uzhkIQQ6werXUoYNUr565iZfLZUmargce2KY2bUwzOAAAAGSv5s2l9etNx1SFCplrhFq3lu65x0xH1iEE5WF//GGu8alfX/rhB9NLSc+e0syZ2yQ9rAIFLtldIgAAgKP5+JjrgvbskZ5+2rTMWbjQnBV6+GHpwAG7K8ybCEF5jGWZOxW3aSPdcYc0b54JP716Sdu3S9OmSWXLJtpdJgAAAP6iaFFpzBhzvdBDD5lp06eb64Wee47OEzIbISiPuHJF+vpr07HB3XdL8+ebDg769JF27pSmTqXHNwAAgJyubFnp88+lNWtMc7lLl6S335bKlTM9y509a3eFeQMhKJc7f960I61USere3XR+EBBgurnetUuaPNnc9BQAAAC5R9260qJF5j6ONWqY8DNsmFSmjPTaa1JcnN0V5m6EoFzqyBHTxWKpUqZ3t337zGnUoUOl6GjT3WK5cnZXCQAAAE+5XFLbttKGDabFT9Wq0pkz5hiwbFlp5Ejp3Dm7q8ydCEG5iGVJy5ebMz6lS5tfAU6dksqXN6EnOtr8QhAaanelAAAAyCxeXtIDD5je4778UqpSxRwD/vvfJgyNGkUzuYwiBOUCFy5In35q7ircpIn5JeDKFalxY2nmTHPNz+OPS/ny2V0pAAAAsoq3t/kxfMuWa50mnDwpvfSSFBkpPf+8aS2EmyME5WA7dkjPPCOVKCENGCBt3GjuNNy/vzkt+uuvUteu5gMBAAAAZ/D2lnr0kLZuNT3/VqtmmsW99Za5ZqhfP3MciesjBOUw58+bntyaNJGiokxXiWfOmFOdb78tHTokffKJVKuW3ZUCAADATj4+5h6QmzaZe0I2aSJdvixNmmSOIzt1kn77zVxSgZQIQTnEtm359K9/SeHhplvr5ctN+89775W+/17avducFSpSxO5KAQAAkJN4eUnt20u//GJCT8eOZvp330mNGplbqEyZIiUk2FpmjkIIstG5c9KmTcUkrdfDD1fRhAlmWrly0ogRpqOD7783QYgmbwAAALiZhg2lOXOk7dulRx6R/P3NLVT69jXXDb34onTggN1V2o8QlM0uXTLX9kyfLv3nP9LKlSUl1ZafX7IeekhavNic9XnpJXMtEAAAAJBRVapIEyeaSylGjza3VTl5UnrjDfODe6dO0oIFUnKy3ZXaw8fuApwgKUn6809p82Zzkdrly9ceK148XseOPa/58/+pZs240AcAAACZJyREeuEF6dlnzXVD778vLVxomsp9953pSKFvX6luXV+7S81WhKAskpRkbmC6bZsJPn9tg1mkiFSzprn7b2LiLn388XgVKNDfvmIBAACQp3l7m2uFOnY0TeU++MD0LLd/vzR0qORyVZc0X3v2FFZoqOl0IS/L4y8vu/no4MECWrXK3Lvnr8EnXz6penUTfiIizB2AJSkmxp5KAQAA4ExRUeaM0JtvSrNnm97kFi92SWqlxYtN5wo1apihZMlrx615CSEok/znPyUkHdW8eUXd04KCTHvMatWk0qVNzx0AAABATpAvn7nfUI8e0vffb9F9932roKAhOn/eT6tXS6tXSwULmh/yq1eXihfPO4GIEJRJzp71kVRUgYGXVbWqL8EHAAAAuUaJEpckDdODD3bQxYt1tGmTuaTj7FlpxQozhISYH/erVzf/z80IQZmkR4/j+v77rurR4x2VKFHH7nIAAACADPPyksqXN8Ply6bX4i1bpF27pNhYadkyMxQrZlo8hYYG2l2yRwhBmaRixQRJSznzAwAAgDzB11eqWtUMiYnmzNCWLabX4+PHzSBFSdqr2Nh4m6vNGEIQAAAAgBvy95dq1TJDQoI5M7Rjh7R7d7KSkrxUtOgVu0vMEM5bAAAAAEi3wEAThrp1k3r12iSpQ67rMIEQBAAAAMAjvr7JkrbYXUaGEYIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICjEIIAAAAAOAohCAAAAICj5IgQ9MEHH6hMmTIKCAhQgwYNtGrVKrtLAgAAAJBH2R6Cvv76aw0ePFhDhw7VunXrVKtWLbVu3VrHjx+3uzQAAAAAeZDtIWjMmDEaMGCA+vbtq6pVq+qjjz5Svnz5NGnSJLtLAwAAAJAH+dj55JcuXdLatWs1ZMgQ9zQvLy+1bNlSv//+e6r5ExMTlZiY6B4/e/asJCkuLi7ri72J+Ph4SdKRI2t16VJ8upeLjd0pSVq7dq17HRnh5eWl5OTkDC2zc6d5zozWeuLE9v/9u1kHDgSme7lbeY254fXl9eXseE6Wy93L3cpnns8vy/G9xnJZuZyn30+efjfdynNKnh0Hebqcp6/x6uuLj4+3/Zj86vNblnXTeV1WeubKIkeOHFGJEiX022+/qWHDhu7pzz//vJYtW6Y//vgjxfzDhg3T8OHDs7tMAAAAALnEwYMHVbJkyRvOY+uZoIwaMmSIBg8e7B5PTk7WqVOnVLRoUblcLhsry73i4uIUGRmpgwcPqkCBAnaX4yhse3ux/e3F9rcP295ebH/7sO3tlR3b37IsnTt3ThERETed19YQFBISIm9vbx07dizF9GPHjiksLCzV/P7+/vL3908xrVChQllZomMUKFCALwSbsO3txfa3F9vfPmx7e7H97cO2t1dWb/+CBQumaz5bO0bw8/NT3bp1tWjRIve05ORkLVq0KEXzOAAAAADILLY3hxs8eLB69+6tevXqqX79+ho7dqzOnz+vvn372l0aAAAAgDzI9hDUrVs3nThxQq+88oqOHj2q2rVr66efflLx4sXtLs0R/P39NXTo0FTNDJH12Pb2Yvvbi+1vH7a9vdj+9mHb2yunbX9be4cDAAAAgOxm+81SAQAAACA7EYIAAAAAOAohCAAAAICjEIIAAAAAOAohKI/54IMPVKZMGQUEBKhBgwZatWpVupb76quv5HK51KlTpxTTLcvSK6+8ovDwcAUGBqply5bavXt3FlSeN2T29u/Tp49cLleKoU2bNllQed6Qke0/ZcqUVNs2ICAgxTzs/+mX2duefT9jMvrdc+bMGQ0cOFDh4eHy9/dXpUqV9OOPP97SOp0qs7f9sGHDUu37VapUyeqXkWtlZPs3a9Ys1bZ1uVxq3769ex6+99Mvs7d9tn/vW8gzvvrqK8vPz8+aNGmStXXrVmvAgAFWoUKFrGPHjt1wuX379lklSpSwmjRpYnXs2DHFY6NHj7YKFixozZkzx9q4caN13333WWXLlrUSEhKy8JXkTlmx/Xv37m21adPGiomJcQ+nTp3KwleRe2V0+0+ePNkqUKBAim179OjRFPOw/6dPVmx79v30y+j2T0xMtOrVq2e1a9fOWr58ubVv3z5r6dKl1oYNGzxep1NlxbYfOnSoVa1atRT7/okTJ7LrJeUqGd3+J0+eTLFdt2zZYnl7e1uTJ092z8P3fvpkxbbP7u99QlAeUr9+fWvgwIHu8aSkJCsiIsIaNWrUdZe5cuWKdeedd1qffvqp1bt37xQH4cnJyVZYWJj11ltvuaedOXPG8vf3t7788ssseQ25WWZvf8uy0pyGtGV0+0+ePNkqWLDgddfH/p9+mb3tLYt9PyMyuv3Hjx9vlStXzrp06VKmrdOpsmLbDx061KpVq1Zml5on3ep++p///McKDg624uPjLcviez8jMnvbW1b2f+/THC6PuHTpktauXauWLVu6p3l5eally5b6/fffr7vcq6++qmLFiqlfv36pHtu3b5+OHj2aYp0FCxZUgwYNbrhOJ8qK7X/V0qVLVaxYMVWuXFmPPfaYTp48mam15wWebv/4+HiVLl1akZGR6tixo7Zu3ep+jP0/fbJi21/Fvn9znmz/uXPnqmHDhho4cKCKFy+u6tWra+TIkUpKSvJ4nU6UFdv+qt27dysiIkLlypVTjx49FB0dnaWvJTfKjP104sSJ6t69u4KCgiTxvZ9eWbHtr8rO731CUB4RGxurpKQkFS9ePMX04sWL6+jRo2kus3z5ck2cOFGffPJJmo9fXS4j63SqrNj+ktSmTRt99tlnWrRokd544w0tW7ZMbdu2TfUH0+k82f6VK1fWpEmT9N1332n69OlKTk7WnXfeqUOHDkli/0+vrNj2Evt+enmy/f/880998803SkpK0o8//qiXX35Z77zzjl5//XWP1+lEWbHtJalBgwaaMmWKfvrpJ40fP1779u1TkyZNdO7cuSx9PbnNre6nq1at0pYtW9S/f3/3NL730ycrtr2U/d/7PlmyVuR4586d08MPP6xPPvlEISEhdpfjOOnd/t27d3f/v0aNGqpZs6bKly+vpUuXqkWLFtlRap7VsGFDNWzY0D1+5513KioqShMmTNBrr71mY2V5X3q2Pft+1klOTlaxYsX08ccfy9vbW3Xr1tXhw4f11ltvaejQoXaXl6elZ9u3bdvWPX/NmjXVoEEDlS5dWjNmzLhhqwFkzMSJE1WjRg3Vr1/f7lIc53rbPru/9zkTlEeEhITI29tbx44dSzH92LFjCgsLSzX/3r17tX//fnXo0EE+Pj7y8fHRZ599prlz58rHx0d79+51L5fedTpZVmz/tJQrV04hISHas2dPlryO3Cqj2z8tvr6+uu2229zblv0/fbJi26eFfT9tnmz/8PBwVapUSd7e3u5pUVFROnr0qC5dupQp76kTZMW2T0uhQoVUqVIl9v2/uZX99Pz58/rqq69ShUq+99MnK7Z9WrL6e58QlEf4+fmpbt26WrRokXtacnKyFi1alOIX16uqVKmizZs3a8OGDe7hvvvuU/PmzbVhwwZFRkaqbNmyCgsLS7HOuLg4/fHHH2mu08myYvun5dChQzp58qTCw8Oz7LXkRhnd/mlJSkrS5s2b3duW/T99smLbp4V9P22ebP9GjRppz549Sk5Odk/btWuXwsPD5efnlynvqRNkxbZPS3x8vPbu3cu+/ze3sp/OnDlTiYmJ6tmzZ4rpfO+nT1Zs+7Rk+fd+tnXBgCz31VdfWf7+/taUKVOsbdu2WY8++qhVqFAhd9ezDz/8sPXiiy9ed/m0euUYPXq0VahQIeu7776zNm3aZHXs2JGuIq8js7f/uXPnrGeffdb6/fffrX379lkLFy606tSpY1WsWNG6ePFiVr+cXCej23/48OHW/Pnzrb1791pr1661unfvbgUEBFhbt251z8P+nz6Zve3Z9zMmo9s/OjraCg4OtgYNGmTt3LnT+uGHH6xixYpZr7/+errXCSMrtv0zzzxjLV261Nq3b5+1YsUKq2XLllZISIh1/PjxbH99OZ2nf3cbN25sdevWLc118r2fPpm97e343icE5THjxo2zSpUqZfn5+Vn169e3Vq5c6X6sadOmVu/eva+7bFohKDk52Xr55Zet4sWLW/7+/laLFi2snTt3ZlH1uV9mbv8LFy5YrVq1skJDQy1fX1+rdOnS1oABAzgIuYGMbP+nnnrKPW/x4sWtdu3aWevWrUuxPvb/9MvMbc++n3EZ/e757bffrAYNGlj+/v5WuXLlrBEjRlhXrlxJ9zpxTWZv+27dulnh4eGWn5+fVaJECatbt27Wnj17suvl5DoZ3f47duywJFk///xzmuvjez/9MnPb2/G977Isy8qac0wAAAAAkPNwTRAAAAAARyEEAQAAAHAUQhAAAAAARyEEAQAAAHAUQhAAAAAARyEEAQAAAHAUQhAAAAAARyEEAQAAAHAUQhAAIEv06dNHnTp1co83a9ZMTz311C2tMzPWkR2WLl0ql8ulM2fO2F0KACANhCAAcJA+ffrI5XLJ5XLJz89PFSpU0KuvvqorV65k+XPPmjVLr732WrrmvV6IyMg6PLF27Vq5XC6tXLkyzcdbtGihLl26ZNnzAwCyByEIABymTZs2iomJ0e7du/XMM89o2LBheuutt9Kc99KlS5n2vEWKFFFwcLDt67iRunXrqlatWpo0aVKqx/bv368lS5aoX79+Wfb8AIDsQQgCAIfx9/dXWFiYSpcurccee0wtW7bU3LlzJV1rwjZixAhFRESocuXKkqSDBw/qgQceUKFChVSkSBF17NhR+/fvd68zKSlJgwcPVqFChVS0aFE9//zzsiwrxfP+vSlbYmKiXnjhBUVGRsrf318VKlTQxIkTtX//fjVv3lySVLhwYblcLvXp0yfNdZw+fVq9evVS4cKFlS9fPrVt21a7d+92Pz5lyhQVKlRI8+fPV1RUlPLnz+8OgdfTr18/ff3117pw4UKK6VOmTFF4eLjatGmjadOmqV69egoODlZYWJgeeughHT9+/LrrHDZsmGrXrp1i2tixY1WmTJkU0z799FNFRUUpICBAVapU0YcffnjddQIAPEcIAgCHCwwMTHHGZ9GiRdq5c6cWLFigH374QZcvX1br1q0VHBysX3/9VStWrHCHiavLvfPOO5oyZYomTZqk5cuX69SpU5o9e/YNn7dXr1768ssv9d5772n79u2aMGGC8ufPr8jISH377beSpJ07dyomJkbvvvtumuvo06eP1qxZo7lz5+r333+XZVlq166dLl++7J7nwoULevvttzVt2jT98ssvio6O1rPPPnvdunr06KHExER988037mmWZWnq1Knq06ePvL29dfnyZb322mvauHGj5syZo/3797uDmqc+//xzvfLKKxoxYoS2b9+ukSNH6uWXX9bUqVNvab0AgNR87C4AAGAPy7K0aNEizZ8/X//3f//nnh4UFKRPP/1Ufn5+kqTp06crOTlZn376qVwulyRp8uTJKlSokJYuXapWrVpp7NixGjJkiPt6mY8++kjz58+/7nPv2rVLM2bM0IIFC9SyZUtJUrly5dyPFylSRJJUrFgxFSpUKM117N69W3PnztWKFSt05513SjJBIjIyUnPmzNE//vEPSdLly5f10UcfqXz58pKkQYMG6dVXX71ubUWKFFHnzp01adIk9erVS5K0ZMkS7d+/X3379pUkPfLII+75y5Urp/fee0+333674uPjlT9//uuu+0aGDh2qd955x70Ny5Ytq23btmnChAnq3bu3R+sEAKSNEAQADvPDDz8of/78unz5spKTk/XQQw9p2LBh7sdr1KjhDkCStHHjRu3ZsyfVtTgXL17U3r17dfbsWcXExKhBgwbux3x8fFSvXr1UTeKu2rBhg7y9vdW0aVOPX8f27dvl4+OT4nmLFi2qypUra/v27e5p+fLlcwcgSQoPD79h0zXJhJzWrVtr7969Kl++vCZNmqSmTZuqQoUKkkwHCsOGDdPGjRt1+vRpJScnS5Kio6NVtWrVDL+W8+fPa+/everXr58GDBjgnn7lyhUVLFgww+sDANwYIQgAHKZ58+YaP368/Pz8FBERIR+flH8KgoKCUozHx8erbt26+vzzz1OtKzQ01KMaAgMDPVrOE76+vinGXS7XdcPZVS1atFCpUqU0ZcoUPffcc5o1a5YmTJggyQSW1q1bq3Xr1vr8888VGhqq6OhotW7d+rodSXh5eaV6zr822YuPj5ckffLJJylCnSR5e3un74UCANKNEAQADhMUFOQ+o5EederU0ddff61ixYqpQIECac4THh6uP/74Q3fddZckcwZj7dq1qlOnTprz16hRQ8nJyVq2bJm7OdxfXT0TlZSUdN26oqKidOXKFf3xxx/u5nAnT57Uzp07PTob81deXl7q27evJk6cqBIlSsjPz09du3aVJO3YsUMnT57U6NGjFRkZKUlas2bNDdcXGhqqo0ePyrIsd5PCDRs2uB8vXry4IiIi9Oeff6pHjx63VDsA4OboGAEAcEM9evRQSEiIOnbsqF9//VX79u3T0qVL9cQTT+jQoUOSpCeffFKjR4/WnDlztGPHDj3++OM3vFFomTJl1Lt3bz3yyCOaM2eOe50zZsyQJJUuXVoul0s//PCDTpw44T5T8lcVK1ZUx44dNWDAAC1fvlwbN25Uz549VaJECXXs2PGWX3ffvn11+PBhvfTSS3rwwQfdZ69KlSolPz8/jRs3Tn/++afmzp1703sXNWvWTCdOnNCbb76pvXv36oMPPtC8efNSzDN8+HCNGjVK7733nnbt2qXNmzdr8uTJGjNmzC2/FgBASoQgAMAN5cuXT7/88otKlSqlLl26KCoqSv369dPFixfdZ4aeeeYZPfzww+rdu7caNmyo4OBgde7c+YbrHT9+vLp27arHH39cVapU0YABA3T+/HlJUokSJTR8+HC9+OKLKl68uAYNGpTmOiZPnqy6devq3nvvVcOGDWVZln788cdUTeA8UapUKbVs2VKnT59O0RFCaGiopkyZopkzZ6pq1aoaPXq03n777RuuKyoqSh9++KE++OAD1apVS6tWrUrVQ13//v316aefavLkyapRo4aaNm2qKVOmqGzZsrf8WgAAKbmsmzWMBgAAAIA8hDNBAAAAAByFEAQAAADAUQhBAAAAAByFEAQAAADAUQhBAAAAAByFEAQAAADAUQhBAAAAAByFEAQAAADAUQhBAAAAAByFEAQAAADAUQhBAAAAABzl/wNOhvPnGBE9+AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label Counts:\n",
      " 1    104\n",
      "Name: count, dtype: int64\n",
      "y_pred_actual:\n",
      " 1    80\n",
      "0    24\n",
      "Name: count, dtype: int64\n",
      "Confusion Matrix : \n",
      " [[ 0 24]\n",
      " [ 0 80]]\n",
      "fold number ################################################ 5\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "441     0\n",
      "576     1\n",
      "40      1\n",
      "639     1\n",
      "349     0\n",
      "       ..\n",
      "346     0\n",
      "801     0\n",
      "440     0\n",
      "1021    1\n",
      "446     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_672\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1345 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1347 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1348 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1008 (Dropout)         (1, 1035, 501)       0           ['input_1345[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_336  (1035, 1035)        0           ['input_1347[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1348[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1008 (GraphC  (1, None, 500)      251000      ['dropout_1008[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_336[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1009 (Dropout)         (1, None, 500)       0           ['graph_convolution_1008[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1009 (GraphC  (1, None, 350)      175350      ['dropout_1009[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_336[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1010 (Dropout)         (1, None, 350)       0           ['graph_convolution_1009[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1010 (GraphC  (1, None, 128)      44928       ['dropout_1010[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_336[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1346 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_336 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1010[0][0]', \n",
      " ces)                                                             'input_1346[0][0]']             \n",
      "                                                                                                  \n",
      " dense_336 (Dense)              (1, None, 2)         258         ['gather_indices_336[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 471,536\n",
      "Trainable params: 471,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 7.6260 - acc: 0.4934 - val_loss: 160.4993 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 195.1978 - acc: 0.7694 - val_loss: 38.0559 - val_acc: 0.7660 - 129ms/epoch - 129ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 47.3182 - acc: 0.7694 - val_loss: 1.8570 - val_acc: 0.7660 - 126ms/epoch - 126ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 4.3710 - acc: 0.7599 - val_loss: 19.8588 - val_acc: 0.2340 - 128ms/epoch - 128ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 17.6295 - acc: 0.3321 - val_loss: 6.0380 - val_acc: 0.2340 - 124ms/epoch - 124ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 7.1475 - acc: 0.3477 - val_loss: 0.5983 - val_acc: 0.7447 - 122ms/epoch - 122ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 1.3999 - acc: 0.5974 - val_loss: 0.7015 - val_acc: 0.7660 - 146ms/epoch - 146ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.3358 - acc: 0.7551 - val_loss: 0.7033 - val_acc: 0.7660 - 125ms/epoch - 125ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 1.4375 - acc: 0.7670 - val_loss: 0.6092 - val_acc: 0.7660 - 121ms/epoch - 121ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.1158 - acc: 0.7670 - val_loss: 0.5374 - val_acc: 0.7660 - 140ms/epoch - 140ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.8679 - acc: 0.7622 - val_loss: 0.5431 - val_acc: 0.7660 - 135ms/epoch - 135ms/step\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 224.6193 - acc: 0.7692\n",
      "\n",
      "Modality============ 0\n",
      "\tloss: 224.6193\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "train0: (931, 128)\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "441     0\n",
      "576     1\n",
      "40      1\n",
      "639     1\n",
      "349     0\n",
      "       ..\n",
      "346     0\n",
      "801     0\n",
      "440     0\n",
      "1021    1\n",
      "446     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_674\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1349 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1351 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1352 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1011 (Dropout)         (1, 1035, 501)       0           ['input_1349[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_337  (1035, 1035)        0           ['input_1351[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1352[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1011 (GraphC  (1, None, 500)      251000      ['dropout_1011[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_337[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1012 (Dropout)         (1, None, 500)       0           ['graph_convolution_1011[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1012 (GraphC  (1, None, 300)      150300      ['dropout_1012[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_337[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1013 (Dropout)         (1, None, 300)       0           ['graph_convolution_1012[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1013 (GraphC  (1, None, 128)      38528       ['dropout_1013[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_337[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1350 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_337 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1013[0][0]', \n",
      " ces)                                                             'input_1350[0][0]']             \n",
      "                                                                                                  \n",
      " dense_337 (Dense)              (1, None, 2)         258         ['gather_indices_337[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 440,086\n",
      "Trainable params: 440,086\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 8.6215 - acc: 0.6487 - val_loss: 126.1794 - val_acc: 0.2340 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 119.6631 - acc: 0.3393 - val_loss: 24.1108 - val_acc: 0.7660 - 111ms/epoch - 111ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 30.2976 - acc: 0.7694 - val_loss: 13.5883 - val_acc: 0.7660 - 109ms/epoch - 109ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 24.5774 - acc: 0.7694 - val_loss: 2.7050 - val_acc: 0.7660 - 125ms/epoch - 125ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 7.3723 - acc: 0.6774 - val_loss: 6.2481 - val_acc: 0.2340 - 114ms/epoch - 114ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 4.7295 - acc: 0.4026 - val_loss: 4.0038 - val_acc: 0.2234 - 121ms/epoch - 121ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 4.1953 - acc: 0.4289 - val_loss: 0.5916 - val_acc: 0.7660 - 151ms/epoch - 151ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.2835 - acc: 0.6726 - val_loss: 0.5288 - val_acc: 0.7660 - 130ms/epoch - 130ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 1.1413 - acc: 0.7515 - val_loss: 0.5243 - val_acc: 0.7660 - 124ms/epoch - 124ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 0.9971 - acc: 0.7706 - val_loss: 0.5176 - val_acc: 0.7660 - 162ms/epoch - 162ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.8526 - acc: 0.7682 - val_loss: 0.5188 - val_acc: 0.7660 - 125ms/epoch - 125ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 0.7899 - acc: 0.7670 - val_loss: 0.5292 - val_acc: 0.7660 - 130ms/epoch - 130ms/step\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 33.6011 - acc: 0.7692\n",
      "\n",
      "Modality============ 1\n",
      "\tloss: 33.6011\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "train1 (931, 128)\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "441     0\n",
      "576     1\n",
      "40      1\n",
      "639     1\n",
      "349     0\n",
      "       ..\n",
      "346     0\n",
      "801     0\n",
      "440     0\n",
      "1021    1\n",
      "446     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_676\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1353 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1355 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1356 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1014 (Dropout)         (1, 1035, 501)       0           ['input_1353[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_338  (1035, 1035)        0           ['input_1355[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1356[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1014 (GraphC  (1, None, 500)      251000      ['dropout_1014[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_338[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1015 (Dropout)         (1, None, 500)       0           ['graph_convolution_1014[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1015 (GraphC  (1, None, 250)      125250      ['dropout_1015[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_338[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1016 (Dropout)         (1, None, 250)       0           ['graph_convolution_1015[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1016 (GraphC  (1, None, 128)      32128       ['dropout_1016[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_338[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1354 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_338 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1016[0][0]', \n",
      " ces)                                                             'input_1354[0][0]']             \n",
      "                                                                                                  \n",
      " dense_338 (Dense)              (1, None, 2)         258         ['gather_indices_338[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 408,636\n",
      "Trainable params: 408,636\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 2s - loss: 6.5565 - acc: 0.6559 - val_loss: 120.3060 - val_acc: 0.2340 - 2s/epoch - 2s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 114.6569 - acc: 0.2891 - val_loss: 45.1284 - val_acc: 0.7660 - 137ms/epoch - 137ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 49.7616 - acc: 0.7694 - val_loss: 34.8077 - val_acc: 0.7660 - 124ms/epoch - 124ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 39.9164 - acc: 0.7694 - val_loss: 20.0168 - val_acc: 0.7660 - 131ms/epoch - 131ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 21.8905 - acc: 0.7694 - val_loss: 7.8139 - val_acc: 0.7660 - 125ms/epoch - 125ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 8.9254 - acc: 0.7622 - val_loss: 2.6258 - val_acc: 0.2447 - 113ms/epoch - 113ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 3.9814 - acc: 0.4444 - val_loss: 2.1157 - val_acc: 0.2340 - 107ms/epoch - 107ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 3.3072 - acc: 0.4648 - val_loss: 0.9495 - val_acc: 0.7660 - 102ms/epoch - 102ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 1.6438 - acc: 0.7001 - val_loss: 1.4022 - val_acc: 0.7660 - 107ms/epoch - 107ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.7779 - acc: 0.7551 - val_loss: 1.1255 - val_acc: 0.7660 - 123ms/epoch - 123ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 1.5588 - acc: 0.7622 - val_loss: 0.8205 - val_acc: 0.7660 - 130ms/epoch - 130ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 1.0991 - acc: 0.7575 - val_loss: 0.5752 - val_acc: 0.7660 - 106ms/epoch - 106ms/step\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 52.3200 - acc: 0.7692\n",
      "\n",
      "Modality============ 2\n",
      "\tloss: 52.3200\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "train2: (931, 128)\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "441     0\n",
      "576     1\n",
      "40      1\n",
      "639     1\n",
      "349     0\n",
      "       ..\n",
      "346     0\n",
      "801     0\n",
      "440     0\n",
      "1021    1\n",
      "446     0\n",
      "Name: labels, Length: 837, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_678\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1357 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1359 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1360 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1017 (Dropout)         (1, 1035, 501)       0           ['input_1357[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_339  (1035, 1035)        0           ['input_1359[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1360[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1017 (GraphC  (1, None, 800)      401600      ['dropout_1017[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_339[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1018 (Dropout)         (1, None, 800)       0           ['graph_convolution_1017[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1018 (GraphC  (1, None, 400)      320400      ['dropout_1018[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_339[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1019 (Dropout)         (1, None, 400)       0           ['graph_convolution_1018[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1019 (GraphC  (1, None, 128)      51328       ['dropout_1019[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_339[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1358 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_339 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1019[0][0]', \n",
      " ces)                                                             'input_1358[0][0]']             \n",
      "                                                                                                  \n",
      " dense_339 (Dense)              (1, None, 2)         258         ['gather_indices_339[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 773,586\n",
      "Trainable params: 773,586\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 7.7555 - acc: 0.6810 - val_loss: 672.1799 - val_acc: 0.2340 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 629.9140 - acc: 0.2401 - val_loss: 64.9645 - val_acc: 0.7660 - 150ms/epoch - 150ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 71.1385 - acc: 0.7694 - val_loss: 31.9742 - val_acc: 0.7660 - 141ms/epoch - 141ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 39.8582 - acc: 0.7694 - val_loss: 10.0631 - val_acc: 0.7660 - 160ms/epoch - 160ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 11.4525 - acc: 0.7575 - val_loss: 1.6385 - val_acc: 0.7553 - 142ms/epoch - 142ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 3.9877 - acc: 0.6022 - val_loss: 5.6833 - val_acc: 0.2340 - 142ms/epoch - 142ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 8.5995 - acc: 0.3548 - val_loss: 0.6224 - val_acc: 0.7660 - 135ms/epoch - 135ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 2.0513 - acc: 0.6595 - val_loss: 1.6122 - val_acc: 0.7660 - 157ms/epoch - 157ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 1.8020 - acc: 0.7407 - val_loss: 1.5948 - val_acc: 0.7660 - 154ms/epoch - 154ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.8883 - acc: 0.7658 - val_loss: 1.3606 - val_acc: 0.7660 - 146ms/epoch - 146ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 1.6802 - acc: 0.7670 - val_loss: 1.0666 - val_acc: 0.7660 - 126ms/epoch - 126ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 1.4283 - acc: 0.7670 - val_loss: 0.7720 - val_acc: 0.7660 - 128ms/epoch - 128ms/step\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 75.0795 - acc: 0.7692\n",
      "\n",
      "Modality============ 4\n",
      "\tloss: 75.0795\n",
      "\tacc: 0.7692\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "train4: (931, 128)\n",
      "Clinical expanded shape: (931, 128)\n",
      "Clinical test expanded shape: (104, 128)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 0, Loss: 1.7740391492843628\n",
      "Attention Weights: tensor([0.0772, 0.3983, 0.1333, 0.2571, 0.1340], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 10, Loss: 1.0358167886734009\n",
      "Attention Weights: tensor([0.0772, 0.3983, 0.1333, 0.2571, 0.1340], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 20, Loss: 0.6865648627281189\n",
      "Attention Weights: tensor([0.0772, 0.3983, 0.1333, 0.2571, 0.1340], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 30, Loss: 0.5475797653198242\n",
      "Attention Weights: tensor([0.0772, 0.3983, 0.1334, 0.2571, 0.1340], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Epoch 40, Loss: 0.52838534116745\n",
      "Attention Weights: tensor([0.0772, 0.3983, 0.1334, 0.2571, 0.1340], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Shape before fusion: [(931, 128), (931, 128), (931, 128), (931, 128), (931, 128)]\n",
      "Shape after fusion: torch.Size([931, 640])\n",
      "Random Forest Classifier Accuracy: 0.8173076923076923\n",
      "Logistic Regression Accuracy: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "UserWarning: [15:10:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.7596153846153846\n",
      "Test Accuracies: 0.8173076923076923 0.25 0.7596153846153846\n",
      "Validation Accuracies: 0.8502673796791443 0.9037433155080213 0.839572192513369\n",
      "Final Ensemble Prediction: [0.725210297213036, 0.714434710315491, 0.764773849802990, 0.767381387454105, 0.728213668865857, 0.757512176372116, 0.779601787858763, 0.758738035801879, 0.770791813270962, 0.760065138197993, 0.738427342716084, 0.722367623730419, 0.737316716175188, 0.739895634007962, 0.740604262889813, 0.744298759682484, 0.712311830247362, 0.726541984600006, 0.724241700362905, 0.750128017476201, 0.779216640226890, 0.771307540621038, 0.742690144820642, 0.753810450151906, 0.707011048675391, 0.727465484939254, 0.698163337417892, 0.717044965304543, 0.700034206130053, 0.691160477355529, 0.681287461122056, 0.684751156052018, 0.666713076518373, 0.667234090178786, 0.651894267434027, 0.635445962229736, 0.644071336525297, 0.630558748342746, 0.616496248193127, 0.633342011060886, 0.644338535563941, 0.619385121549717, 0.618498349131777, 0.606950786185291, 0.615541556044948, 0.627481407076005, 0.609214491643494, 0.633073883778727, 0.636355336363212, 0.604651560086092, 0.616240137936249, 0.634103153423397, 0.619860294242347, 0.639268345915142, 0.593587796983311, 0.628626710655611, 0.643580220591673, 0.624765814856638, 0.637259715669357, 0.627686742724122, 0.629867356445476, 0.595284026477883, 0.635785125625080, 0.620566353551077, 0.636836768315345, 0.630975878422168, 0.593775484982446, 0.624026793274605, 0.613750329654214, 0.582762217374710, 0.609991945050451, 0.609085803243118, 0.615073836826998, 0.590636365820464, 0.600290944524908, 0.598865185924060, 0.609628982336038, 0.574386165525499, 0.597339096566778, 0.599444368741544, 0.564037360060856, 0.533957727807813, 0.564855090214431, 0.547754597874019, 0.557375840659105, 0.568382978936577, 0.566453194280294, 0.523336404506361, 0.554489007010439, 0.547537927522500, 0.514715413493514, 0.515308316808230, 0.490505719381664, 0.512945815654377, 0.480188853676255, 0.506899852016595, 0.491795444862461, 0.464022871445800, 0.490744739337068, 0.481345395985714, 0.487525490584996, 0.483802818426495, 0.464237336466963, 0.454160299620677]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label Counts:\n",
      " 1    104\n",
      "Name: count, dtype: int64\n",
      "y_pred_actual:\n",
      " 1    79\n",
      "0    25\n",
      "Name: count, dtype: int64\n",
      "Confusion Matrix : \n",
      " [[ 0 25]\n",
      " [ 0 79]]\n",
      "fold number ################################################ 6\n",
      "        count\n",
      "labels       \n",
      "1         717\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         645\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          79\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "230    1\n",
      "276    1\n",
      "718    1\n",
      "266    1\n",
      "82     1\n",
      "      ..\n",
      "293    1\n",
      "296    1\n",
      "864    1\n",
      "560    1\n",
      "653    1\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_680\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1361 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1363 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1364 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1020 (Dropout)         (1, 1035, 501)       0           ['input_1361[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_340  (1035, 1035)        0           ['input_1363[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1364[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1020 (GraphC  (1, None, 500)      251000      ['dropout_1020[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_340[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1021 (Dropout)         (1, None, 500)       0           ['graph_convolution_1020[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1021 (GraphC  (1, None, 350)      175350      ['dropout_1021[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_340[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1022 (Dropout)         (1, None, 350)       0           ['graph_convolution_1021[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1022 (GraphC  (1, None, 128)      44928       ['dropout_1022[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_340[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1362 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_340 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1022[0][0]', \n",
      " ces)                                                             'input_1362[0][0]']             \n",
      "                                                                                                  \n",
      " dense_340 (Dense)              (1, None, 2)         258         ['gather_indices_340[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 471,536\n",
      "Trainable params: 471,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 7.6424 - acc: 0.6217 - val_loss: 103.4949 - val_acc: 0.2553 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 87.4346 - acc: 0.4045 - val_loss: 110.9158 - val_acc: 0.7660 - 114ms/epoch - 114ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 134.0655 - acc: 0.7697 - val_loss: 74.6145 - val_acc: 0.7660 - 111ms/epoch - 111ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 89.9588 - acc: 0.7697 - val_loss: 35.6406 - val_acc: 0.7553 - 114ms/epoch - 114ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 44.5865 - acc: 0.6838 - val_loss: 11.6357 - val_acc: 0.7447 - 119ms/epoch - 119ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 15.9333 - acc: 0.7088 - val_loss: 1.3169 - val_acc: 0.7340 - 109ms/epoch - 109ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 3.5919 - acc: 0.7196 - val_loss: 7.2002 - val_acc: 0.2660 - 108ms/epoch - 108ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 7.8427 - acc: 0.3926 - val_loss: 3.7361 - val_acc: 0.3191 - 115ms/epoch - 115ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 4.1232 - acc: 0.4606 - val_loss: 0.9624 - val_acc: 0.7553 - 114ms/epoch - 114ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.9010 - acc: 0.7494 - val_loss: 0.9741 - val_acc: 0.7660 - 112ms/epoch - 112ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 1.9143 - acc: 0.7613 - val_loss: 0.5416 - val_acc: 0.7660 - 115ms/epoch - 115ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 1.3365 - acc: 0.7566 - val_loss: 0.6106 - val_acc: 0.7234 - 129ms/epoch - 129ms/step\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 133.3207 - acc: 0.7670\n",
      "\n",
      "Modality============ 0\n",
      "\tloss: 133.3207\n",
      "\tacc: 0.7670\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "train0: (932, 128)\n",
      "        count\n",
      "labels       \n",
      "1         717\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         645\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          79\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "230    1\n",
      "276    1\n",
      "718    1\n",
      "266    1\n",
      "82     1\n",
      "      ..\n",
      "293    1\n",
      "296    1\n",
      "864    1\n",
      "560    1\n",
      "653    1\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_682\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1365 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1367 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1368 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1023 (Dropout)         (1, 1035, 501)       0           ['input_1365[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_341  (1035, 1035)        0           ['input_1367[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1368[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1023 (GraphC  (1, None, 500)      251000      ['dropout_1023[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_341[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1024 (Dropout)         (1, None, 500)       0           ['graph_convolution_1023[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1024 (GraphC  (1, None, 300)      150300      ['dropout_1024[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_341[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1025 (Dropout)         (1, None, 300)       0           ['graph_convolution_1024[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1025 (GraphC  (1, None, 128)      38528       ['dropout_1025[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_341[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1366 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_341 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1025[0][0]', \n",
      " ces)                                                             'input_1366[0][0]']             \n",
      "                                                                                                  \n",
      " dense_341 (Dense)              (1, None, 2)         258         ['gather_indices_341[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 440,086\n",
      "Trainable params: 440,086\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 25.0186 - acc: 0.3675 - val_loss: 229.1770 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 237.1387 - acc: 0.7697 - val_loss: 95.2283 - val_acc: 0.7660 - 118ms/epoch - 118ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 133.8835 - acc: 0.7697 - val_loss: 26.0130 - val_acc: 0.7660 - 129ms/epoch - 129ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 37.5138 - acc: 0.7697 - val_loss: 3.0243 - val_acc: 0.7660 - 99ms/epoch - 99ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 6.2276 - acc: 0.7697 - val_loss: 1.7100 - val_acc: 0.2447 - 98ms/epoch - 98ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 2.5861 - acc: 0.6134 - val_loss: 2.4331 - val_acc: 0.2234 - 103ms/epoch - 103ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 3.8354 - acc: 0.5215 - val_loss: 1.2880 - val_acc: 0.2234 - 97ms/epoch - 97ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.7423 - acc: 0.5680 - val_loss: 0.7932 - val_acc: 0.2660 - 114ms/epoch - 114ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 1.0629 - acc: 0.6193 - val_loss: 0.5870 - val_acc: 0.7660 - 99ms/epoch - 99ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 0.8187 - acc: 0.7470 - val_loss: 0.5547 - val_acc: 0.7660 - 96ms/epoch - 96ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.8450 - acc: 0.7613 - val_loss: 0.5550 - val_acc: 0.7660 - 138ms/epoch - 138ms/step\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 245.6623 - acc: 0.7670\n",
      "\n",
      "Modality============ 1\n",
      "\tloss: 245.6623\n",
      "\tacc: 0.7670\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "train1 (932, 128)\n",
      "        count\n",
      "labels       \n",
      "1         717\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         645\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          79\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "230    1\n",
      "276    1\n",
      "718    1\n",
      "266    1\n",
      "82     1\n",
      "      ..\n",
      "293    1\n",
      "296    1\n",
      "864    1\n",
      "560    1\n",
      "653    1\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_684\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1369 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1371 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1372 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1026 (Dropout)         (1, 1035, 501)       0           ['input_1369[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_342  (1035, 1035)        0           ['input_1371[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1372[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1026 (GraphC  (1, None, 500)      251000      ['dropout_1026[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_342[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1027 (Dropout)         (1, None, 500)       0           ['graph_convolution_1026[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1027 (GraphC  (1, None, 250)      125250      ['dropout_1027[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_342[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1028 (Dropout)         (1, None, 250)       0           ['graph_convolution_1027[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1028 (GraphC  (1, None, 128)      32128       ['dropout_1028[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_342[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1370 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_342 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1028[0][0]', \n",
      " ces)                                                             'input_1370[0][0]']             \n",
      "                                                                                                  \n",
      " dense_342 (Dense)              (1, None, 2)         258         ['gather_indices_342[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 408,636\n",
      "Trainable params: 408,636\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 10.8850 - acc: 0.4570 - val_loss: 187.5517 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 184.7774 - acc: 0.7697 - val_loss: 60.5822 - val_acc: 0.7660 - 102ms/epoch - 102ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 63.3134 - acc: 0.7697 - val_loss: 13.0253 - val_acc: 0.7660 - 99ms/epoch - 99ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 14.5464 - acc: 0.7697 - val_loss: 10.8523 - val_acc: 0.2340 - 98ms/epoch - 98ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 9.1002 - acc: 0.3926 - val_loss: 2.1710 - val_acc: 0.2340 - 101ms/epoch - 101ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 3.1085 - acc: 0.4499 - val_loss: 1.0033 - val_acc: 0.7660 - 91ms/epoch - 91ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 1.5825 - acc: 0.7196 - val_loss: 1.2368 - val_acc: 0.7660 - 205ms/epoch - 205ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.7037 - acc: 0.7637 - val_loss: 1.0825 - val_acc: 0.7660 - 126ms/epoch - 126ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 1.4746 - acc: 0.7709 - val_loss: 0.8146 - val_acc: 0.7660 - 116ms/epoch - 116ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.1983 - acc: 0.7661 - val_loss: 0.6030 - val_acc: 0.7660 - 93ms/epoch - 93ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.7713 - acc: 0.7601 - val_loss: 0.5411 - val_acc: 0.7660 - 93ms/epoch - 93ms/step\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 205.5965 - acc: 0.7670\n",
      "\n",
      "Modality============ 2\n",
      "\tloss: 205.5965\n",
      "\tacc: 0.7670\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "train2: (932, 128)\n",
      "        count\n",
      "labels       \n",
      "1         717\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         645\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          79\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "230    1\n",
      "276    1\n",
      "718    1\n",
      "266    1\n",
      "82     1\n",
      "      ..\n",
      "293    1\n",
      "296    1\n",
      "864    1\n",
      "560    1\n",
      "653    1\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_686\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1373 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1375 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1376 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1029 (Dropout)         (1, 1035, 501)       0           ['input_1373[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_343  (1035, 1035)        0           ['input_1375[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1376[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1029 (GraphC  (1, None, 800)      401600      ['dropout_1029[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_343[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1030 (Dropout)         (1, None, 800)       0           ['graph_convolution_1029[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1030 (GraphC  (1, None, 400)      320400      ['dropout_1030[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_343[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1031 (Dropout)         (1, None, 400)       0           ['graph_convolution_1030[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1031 (GraphC  (1, None, 128)      51328       ['dropout_1031[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_343[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1374 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_343 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1031[0][0]', \n",
      " ces)                                                             'input_1374[0][0]']             \n",
      "                                                                                                  \n",
      " dense_343 (Dense)              (1, None, 2)         258         ['gather_indices_343[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 773,586\n",
      "Trainable params: 773,586\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 11.5842 - acc: 0.3771 - val_loss: 353.1860 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 370.4363 - acc: 0.7697 - val_loss: 83.4469 - val_acc: 0.7660 - 133ms/epoch - 133ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 86.1727 - acc: 0.7697 - val_loss: 12.5019 - val_acc: 0.7660 - 116ms/epoch - 116ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 17.3347 - acc: 0.7697 - val_loss: 0.8137 - val_acc: 0.7660 - 127ms/epoch - 127ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 2.5517 - acc: 0.7685 - val_loss: 3.2992 - val_acc: 0.2340 - 112ms/epoch - 112ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 2.2860 - acc: 0.4582 - val_loss: 1.9823 - val_acc: 0.2340 - 131ms/epoch - 131ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.0425 - acc: 0.3735 - val_loss: 1.0670 - val_acc: 0.2447 - 116ms/epoch - 116ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 0.9340 - acc: 0.5048 - val_loss: 0.5478 - val_acc: 0.7660 - 171ms/epoch - 171ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 0.7489 - acc: 0.7196 - val_loss: 0.6407 - val_acc: 0.7660 - 110ms/epoch - 110ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 0.7841 - acc: 0.7601 - val_loss: 0.6191 - val_acc: 0.7660 - 112ms/epoch - 112ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.7217 - acc: 0.7649 - val_loss: 0.5639 - val_acc: 0.7660 - 119ms/epoch - 119ms/step\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 387.2633 - acc: 0.7670\n",
      "\n",
      "Modality============ 4\n",
      "\tloss: 387.2633\n",
      "\tacc: 0.7670\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "train4: (932, 128)\n",
      "Clinical expanded shape: (932, 128)\n",
      "Clinical test expanded shape: (103, 128)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 0, Loss: 4.599194049835205\n",
      "Attention Weights: tensor([0.1362, 0.1478, 0.2166, 0.1828, 0.3166], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 10, Loss: 0.900015115737915\n",
      "Attention Weights: tensor([0.1362, 0.1479, 0.2166, 0.1829, 0.3165], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 20, Loss: 0.5882997512817383\n",
      "Attention Weights: tensor([0.1362, 0.1478, 0.2166, 0.1829, 0.3165], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 30, Loss: 0.5581761598587036\n",
      "Attention Weights: tensor([0.1362, 0.1478, 0.2166, 0.1829, 0.3166], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 40, Loss: 0.5422431826591492\n",
      "Attention Weights: tensor([0.1362, 0.1478, 0.2166, 0.1828, 0.3166], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Random Forest Classifier Accuracy: 0.5922330097087378\n",
      "Logistic Regression Accuracy: 0.7281553398058253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "UserWarning: [15:11:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.7669902912621359\n",
      "Test Accuracies: 0.5922330097087378 0.7281553398058253 0.7669902912621359\n",
      "Validation Accuracies: 0.8449197860962567 0.8609625668449198 0.8342245989304813\n",
      "Final Ensemble Prediction: [0.471689959544404, 0.444910781463930, 0.481453640841659, 0.527069361015615, 0.448641020265737, 0.490669710338673, 0.449937879312478, 0.478253206282245, 0.491511751584419, 0.463444399043708, 0.501523960175454, 0.549474767613442, 0.517630917358903, 0.503985915333973, 0.534658024601100, 0.514189509636982, 0.531142449459426, 0.538713619098058, 0.511066577963652, 0.493871376190555, 0.525082521115138, 0.537538746731443, 0.540945340825971, 0.531898051368560, 0.518164030587906, 0.532349553228406, 0.552310678627374, 0.529087517566349, 0.524273528496643, 0.551196825962335, 0.545474658382814, 0.561133654098138, 0.531528582421357, 0.556189820879617, 0.528006948071161, 0.520976613820936, 0.525331465465153, 0.504730537004038, 0.536480236858658, 0.519545100315201, 0.531389412017998, 0.571042157211449, 0.589692679272791, 0.508583656979599, 0.531214287869983, 0.535295191464644, 0.571967667375897, 0.528102803425037, 0.538090330565730, 0.546008621772536, 0.561517211494866, 0.590318860497414, 0.570889934714861, 0.564160321639668, 0.551767053907570, 0.554167581921082, 0.528946710384702, 0.553734108159156, 0.592808776250541, 0.564449100226904, 0.609850709588581, 0.539561844001719, 0.579314917619421, 0.593184701341314, 0.571192787666271, 0.607096241790107, 0.577339660657413, 0.600219798233878, 0.573659104058587, 0.568487816360751, 0.578318589664402, 0.530950906209622, 0.523221354288623, 0.580042120021729, 0.545029209845539, 0.562343293228312, 0.595914480062625, 0.637625649889156, 0.597003715008508, 0.623951008935702, 0.633789939300703, 0.604160673245709, 0.598433920762859, 0.593734703002346, 0.658909051262548, 0.599472778707377, 0.650538617067945, 0.594064714724443, 0.618593625414352, 0.640120023884317, 0.581820951156754, 0.648293865748880, 0.646274387791540, 0.662525657226672, 0.656957820783417, 0.599318815338477, 0.663362660671345, 0.659168260726673, 0.642670609799653, 0.708981477178129, 0.609416678748722, 0.680275283405300, 0.689930455032245]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label Counts:\n",
      " 1    103\n",
      "Name: count, dtype: int64\n",
      "y_pred_actual:\n",
      " 1    79\n",
      "0    24\n",
      "Name: count, dtype: int64\n",
      "Confusion Matrix : \n",
      " [[ 0 24]\n",
      " [ 0 79]]\n",
      "fold number ################################################ 7\n",
      "        count\n",
      "labels       \n",
      "1         717\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         645\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          79\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "230    1\n",
      "279    1\n",
      "710    1\n",
      "269    1\n",
      "80     1\n",
      "      ..\n",
      "296    1\n",
      "298    1\n",
      "861    1\n",
      "561    1\n",
      "649    1\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_688\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1377 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1379 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1380 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1032 (Dropout)         (1, 1035, 501)       0           ['input_1377[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_344  (1035, 1035)        0           ['input_1379[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1380[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1032 (GraphC  (1, None, 500)      251000      ['dropout_1032[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_344[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1033 (Dropout)         (1, None, 500)       0           ['graph_convolution_1032[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1033 (GraphC  (1, None, 350)      175350      ['dropout_1033[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_344[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1034 (Dropout)         (1, None, 350)       0           ['graph_convolution_1033[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1034 (GraphC  (1, None, 128)      44928       ['dropout_1034[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_344[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1378 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_344 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1034[0][0]', \n",
      " ces)                                                             'input_1378[0][0]']             \n",
      "                                                                                                  \n",
      " dense_344 (Dense)              (1, None, 2)         258         ['gather_indices_344[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 471,536\n",
      "Trainable params: 471,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 13.9338 - acc: 0.4379 - val_loss: 263.6115 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 314.0132 - acc: 0.7697 - val_loss: 72.1482 - val_acc: 0.7660 - 178ms/epoch - 178ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 98.7765 - acc: 0.7697 - val_loss: 12.8915 - val_acc: 0.7660 - 109ms/epoch - 109ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 21.1695 - acc: 0.7697 - val_loss: 0.5415 - val_acc: 0.7872 - 114ms/epoch - 114ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 3.7825 - acc: 0.7434 - val_loss: 9.5382 - val_acc: 0.2553 - 107ms/epoch - 107ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 6.9962 - acc: 0.4105 - val_loss: 5.3086 - val_acc: 0.2553 - 101ms/epoch - 101ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 5.0335 - acc: 0.3914 - val_loss: 0.8806 - val_acc: 0.3085 - 101ms/epoch - 101ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.3000 - acc: 0.5597 - val_loss: 0.6787 - val_acc: 0.7660 - 118ms/epoch - 118ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 1.1193 - acc: 0.7506 - val_loss: 0.7510 - val_acc: 0.7660 - 106ms/epoch - 106ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.2619 - acc: 0.7697 - val_loss: 0.7043 - val_acc: 0.7660 - 106ms/epoch - 106ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 1.2240 - acc: 0.7685 - val_loss: 0.6168 - val_acc: 0.7660 - 101ms/epoch - 101ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 0.9491 - acc: 0.7625 - val_loss: 0.5437 - val_acc: 0.7660 - 110ms/epoch - 110ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 0.8607 - acc: 0.7566 - val_loss: 0.5433 - val_acc: 0.7660 - 102ms/epoch - 102ms/step\n",
      "Epoch 14/200\n",
      "1/1 - 0s - loss: 0.7539 - acc: 0.7411 - val_loss: 0.6060 - val_acc: 0.6596 - 103ms/epoch - 103ms/step\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5623 - acc: 0.7670\n",
      "\n",
      "Modality============ 0\n",
      "\tloss: 0.5623\n",
      "\tacc: 0.7670\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "train0: (932, 128)\n",
      "        count\n",
      "labels       \n",
      "1         717\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         645\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          79\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "230    1\n",
      "279    1\n",
      "710    1\n",
      "269    1\n",
      "80     1\n",
      "      ..\n",
      "296    1\n",
      "298    1\n",
      "861    1\n",
      "561    1\n",
      "649    1\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_690\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1381 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1383 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1384 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1035 (Dropout)         (1, 1035, 501)       0           ['input_1381[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_345  (1035, 1035)        0           ['input_1383[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1384[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1035 (GraphC  (1, None, 500)      251000      ['dropout_1035[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_345[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1036 (Dropout)         (1, None, 500)       0           ['graph_convolution_1035[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1036 (GraphC  (1, None, 300)      150300      ['dropout_1036[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_345[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1037 (Dropout)         (1, None, 300)       0           ['graph_convolution_1036[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1037 (GraphC  (1, None, 128)      38528       ['dropout_1037[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_345[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1382 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_345 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1037[0][0]', \n",
      " ces)                                                             'input_1382[0][0]']             \n",
      "                                                                                                  \n",
      " dense_345 (Dense)              (1, None, 2)         258         ['gather_indices_345[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 440,086\n",
      "Trainable params: 440,086\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 9.9292 - acc: 0.5752 - val_loss: 30.6512 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 42.9353 - acc: 0.7697 - val_loss: 120.6607 - val_acc: 0.2340 - 152ms/epoch - 152ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 111.0787 - acc: 0.2303 - val_loss: 2.4633 - val_acc: 0.2447 - 241ms/epoch - 241ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 5.1170 - acc: 0.5358 - val_loss: 6.2435 - val_acc: 0.7660 - 140ms/epoch - 140ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 11.0031 - acc: 0.7697 - val_loss: 5.2476 - val_acc: 0.7660 - 126ms/epoch - 126ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 10.0919 - acc: 0.7697 - val_loss: 3.1685 - val_acc: 0.7660 - 138ms/epoch - 138ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 7.2396 - acc: 0.7697 - val_loss: 1.5626 - val_acc: 0.7660 - 146ms/epoch - 146ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 3.9805 - acc: 0.7697 - val_loss: 0.5429 - val_acc: 0.7660 - 100ms/epoch - 100ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.0103 - acc: 0.7601 - val_loss: 1.9333 - val_acc: 0.2553 - 108ms/epoch - 108ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.3567 - acc: 0.6253 - val_loss: 2.0996 - val_acc: 0.2553 - 111ms/epoch - 111ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 1.4774 - acc: 0.5632 - val_loss: 1.3770 - val_acc: 0.3830 - 109ms/epoch - 109ms/step\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 30.8940 - acc: 0.7670\n",
      "\n",
      "Modality============ 1\n",
      "\tloss: 30.8940\n",
      "\tacc: 0.7670\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "train1 (932, 128)\n",
      "        count\n",
      "labels       \n",
      "1         717\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         645\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          79\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "230    1\n",
      "279    1\n",
      "710    1\n",
      "269    1\n",
      "80     1\n",
      "      ..\n",
      "296    1\n",
      "298    1\n",
      "861    1\n",
      "561    1\n",
      "649    1\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_692\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1385 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1387 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1388 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1038 (Dropout)         (1, 1035, 501)       0           ['input_1385[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_346  (1035, 1035)        0           ['input_1387[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1388[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1038 (GraphC  (1, None, 500)      251000      ['dropout_1038[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_346[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1039 (Dropout)         (1, None, 500)       0           ['graph_convolution_1038[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1039 (GraphC  (1, None, 250)      125250      ['dropout_1039[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_346[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1040 (Dropout)         (1, None, 250)       0           ['graph_convolution_1039[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1040 (GraphC  (1, None, 128)      32128       ['dropout_1040[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_346[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1386 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_346 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1040[0][0]', \n",
      " ces)                                                             'input_1386[0][0]']             \n",
      "                                                                                                  \n",
      " dense_346 (Dense)              (1, None, 2)         258         ['gather_indices_346[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 408,636\n",
      "Trainable params: 408,636\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 11.4016 - acc: 0.4021 - val_loss: 163.1721 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 169.8422 - acc: 0.7697 - val_loss: 48.5887 - val_acc: 0.7660 - 99ms/epoch - 99ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 60.5652 - acc: 0.7697 - val_loss: 5.9524 - val_acc: 0.7660 - 93ms/epoch - 93ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 8.6490 - acc: 0.7697 - val_loss: 10.1362 - val_acc: 0.2340 - 85ms/epoch - 85ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 5.4904 - acc: 0.4582 - val_loss: 5.3199 - val_acc: 0.2340 - 88ms/epoch - 88ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 3.6123 - acc: 0.4403 - val_loss: 0.7183 - val_acc: 0.7660 - 88ms/epoch - 88ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 1.6053 - acc: 0.7327 - val_loss: 1.4678 - val_acc: 0.7660 - 85ms/epoch - 85ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.8511 - acc: 0.7673 - val_loss: 1.4144 - val_acc: 0.7660 - 90ms/epoch - 90ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.0953 - acc: 0.7697 - val_loss: 1.0763 - val_acc: 0.7660 - 85ms/epoch - 85ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.4984 - acc: 0.7661 - val_loss: 0.8002 - val_acc: 0.7660 - 89ms/epoch - 89ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 1.1082 - acc: 0.7637 - val_loss: 0.6308 - val_acc: 0.7660 - 96ms/epoch - 96ms/step\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 166.9554 - acc: 0.7670\n",
      "\n",
      "Modality============ 2\n",
      "\tloss: 166.9554\n",
      "\tacc: 0.7670\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "train2: (932, 128)\n",
      "        count\n",
      "labels       \n",
      "1         717\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         645\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          79\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "230    1\n",
      "279    1\n",
      "710    1\n",
      "269    1\n",
      "80     1\n",
      "      ..\n",
      "296    1\n",
      "298    1\n",
      "861    1\n",
      "561    1\n",
      "649    1\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_694\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1389 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1391 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1392 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1041 (Dropout)         (1, 1035, 501)       0           ['input_1389[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_347  (1035, 1035)        0           ['input_1391[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1392[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1041 (GraphC  (1, None, 800)      401600      ['dropout_1041[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_347[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1042 (Dropout)         (1, None, 800)       0           ['graph_convolution_1041[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1042 (GraphC  (1, None, 400)      320400      ['dropout_1042[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_347[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1043 (Dropout)         (1, None, 400)       0           ['graph_convolution_1042[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1043 (GraphC  (1, None, 128)      51328       ['dropout_1043[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_347[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1390 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_347 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1043[0][0]', \n",
      " ces)                                                             'input_1390[0][0]']             \n",
      "                                                                                                  \n",
      " dense_347 (Dense)              (1, None, 2)         258         ['gather_indices_347[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 773,586\n",
      "Trainable params: 773,586\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 17.7406 - acc: 0.3198 - val_loss: 329.1941 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 379.7016 - acc: 0.7697 - val_loss: 97.7646 - val_acc: 0.7660 - 118ms/epoch - 118ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 114.4743 - acc: 0.7697 - val_loss: 15.5718 - val_acc: 0.7660 - 115ms/epoch - 115ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 20.7517 - acc: 0.7697 - val_loss: 1.6515 - val_acc: 0.7660 - 121ms/epoch - 121ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 3.8406 - acc: 0.7637 - val_loss: 6.6251 - val_acc: 0.2340 - 143ms/epoch - 143ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 5.1519 - acc: 0.4165 - val_loss: 2.3226 - val_acc: 0.2340 - 122ms/epoch - 122ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.7110 - acc: 0.3831 - val_loss: 0.8731 - val_acc: 0.2340 - 112ms/epoch - 112ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.1548 - acc: 0.4272 - val_loss: 0.6813 - val_acc: 0.7660 - 113ms/epoch - 113ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 0.6987 - acc: 0.6754 - val_loss: 0.6387 - val_acc: 0.7660 - 119ms/epoch - 119ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 0.6299 - acc: 0.7470 - val_loss: 0.6215 - val_acc: 0.7660 - 113ms/epoch - 113ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.6594 - acc: 0.7685 - val_loss: 0.6179 - val_acc: 0.7660 - 112ms/epoch - 112ms/step\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 337.2599 - acc: 0.7670\n",
      "\n",
      "Modality============ 4\n",
      "\tloss: 337.2599\n",
      "\tacc: 0.7670\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "train4: (932, 128)\n",
      "Clinical expanded shape: (932, 128)\n",
      "Clinical test expanded shape: (103, 128)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 0, Loss: 0.6973040103912354\n",
      "Attention Weights: tensor([0.0934, 0.2325, 0.2494, 0.1270, 0.2978], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 10, Loss: 3.0039448738098145\n",
      "Attention Weights: tensor([0.0934, 0.2325, 0.2493, 0.1270, 0.2977], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 20, Loss: 1.4784327745437622\n",
      "Attention Weights: tensor([0.0934, 0.2325, 0.2493, 0.1271, 0.2977], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 30, Loss: 0.8539822697639465\n",
      "Attention Weights: tensor([0.0934, 0.2325, 0.2493, 0.1271, 0.2977], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 40, Loss: 0.5606111288070679\n",
      "Attention Weights: tensor([0.0934, 0.2325, 0.2493, 0.1270, 0.2977], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Random Forest Classifier Accuracy: 0.7766990291262136\n",
      "Logistic Regression Accuracy: 0.7669902912621359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "UserWarning: [15:11:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.7669902912621359\n",
      "Test Accuracies: 0.7766990291262136 0.7669902912621359 0.7669902912621359\n",
      "Validation Accuracies: 0.8449197860962567 0.9411764705882353 0.7967914438502673\n",
      "Final Ensemble Prediction: [0.362224615388846, 0.327932756272742, 0.371780395272515, 0.415982772245667, 0.443531117194236, 0.434341783316751, 0.387190973445672, 0.387728105649981, 0.429416995663323, 0.433438447016991, 0.408350795881173, 0.414928389319736, 0.451340175850948, 0.435475982683906, 0.446548293037674, 0.453375409866553, 0.461811141480501, 0.446246422820369, 0.463061504853961, 0.455294678242631, 0.461893584268021, 0.504714821309592, 0.496924154285219, 0.508197198396710, 0.515137239978438, 0.513227399110376, 0.527369585624119, 0.528405925076688, 0.526235444143070, 0.549975940766580, 0.542720153523503, 0.525974653788679, 0.524972842945501, 0.557613308302027, 0.533659554070676, 0.569070820146199, 0.551079719592120, 0.555071031672384, 0.549619370371406, 0.567163034979498, 0.569158569465016, 0.566360880060088, 0.534144650859028, 0.568672541343193, 0.566905858025455, 0.570212773457858, 0.561834151356837, 0.584463889401374, 0.592567046618556, 0.613269667431136, 0.586049600233939, 0.593615436790121, 0.630649759120262, 0.637935751090631, 0.639086598815131, 0.628480430448719, 0.636299950623198, 0.625859272865628, 0.659992347464748, 0.636833816722544, 0.666593525482577, 0.650774932079428, 0.683424366453737, 0.692463719917571, 0.692646331377173, 0.695917793845787, 0.677948038603754, 0.680228195998648, 0.672517429861076, 0.700819347016323, 0.696081921336778, 0.693979376826021, 0.703784648716039, 0.670191154686906, 0.692575933988020, 0.703909645035159, 0.685953662025732, 0.705900722139046, 0.715709929955748, 0.682976324127567, 0.710569444410970, 0.719231719755981, 0.709364658628715, 0.720028511966273, 0.717277266289218, 0.727581995062369, 0.716031040395447, 0.732960895367255, 0.748140101964076, 0.731525296246515, 0.743933629263590, 0.754241026961516, 0.716084267372147, 0.730838775772054, 0.753351451296299, 0.776244214917343, 0.766442254727963, 0.767708406999260, 0.761167692622757, 0.777655685258371, 0.768200411182625, 0.769697828883075, 0.764092791532948]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label Counts:\n",
      " 1    102\n",
      "0      1\n",
      "Name: count, dtype: int64\n",
      "y_pred_actual:\n",
      " 1    79\n",
      "0    24\n",
      "Name: count, dtype: int64\n",
      "Confusion Matrix : \n",
      " [[ 1 23]\n",
      " [ 0 79]]\n",
      "fold number ################################################ 8\n",
      "        count\n",
      "labels       \n",
      "1         717\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         645\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          79\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "231    1\n",
      "279    1\n",
      "710    1\n",
      "269    1\n",
      "81     1\n",
      "      ..\n",
      "298    1\n",
      "300    1\n",
      "862    1\n",
      "554    1\n",
      "651    1\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_696\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1393 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1395 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1396 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1044 (Dropout)         (1, 1035, 501)       0           ['input_1393[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_348  (1035, 1035)        0           ['input_1395[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1396[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1044 (GraphC  (1, None, 500)      251000      ['dropout_1044[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_348[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1045 (Dropout)         (1, None, 500)       0           ['graph_convolution_1044[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1045 (GraphC  (1, None, 350)      175350      ['dropout_1045[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_348[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1046 (Dropout)         (1, None, 350)       0           ['graph_convolution_1045[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1046 (GraphC  (1, None, 128)      44928       ['dropout_1046[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_348[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1394 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_348 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1046[0][0]', \n",
      " ces)                                                             'input_1394[0][0]']             \n",
      "                                                                                                  \n",
      " dense_348 (Dense)              (1, None, 2)         258         ['gather_indices_348[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 471,536\n",
      "Trainable params: 471,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 42.9402 - acc: 0.2327 - val_loss: 172.8788 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 229.6781 - acc: 0.7697 - val_loss: 56.0229 - val_acc: 0.7660 - 154ms/epoch - 154ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 67.3570 - acc: 0.7697 - val_loss: 14.3439 - val_acc: 0.7660 - 99ms/epoch - 99ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 21.6957 - acc: 0.7697 - val_loss: 2.8650 - val_acc: 0.7660 - 102ms/epoch - 102ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 4.8359 - acc: 0.7434 - val_loss: 6.5271 - val_acc: 0.2340 - 119ms/epoch - 119ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 7.9948 - acc: 0.3711 - val_loss: 1.8463 - val_acc: 0.2340 - 107ms/epoch - 107ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 4.0017 - acc: 0.3699 - val_loss: 0.6233 - val_acc: 0.7660 - 102ms/epoch - 102ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.1484 - acc: 0.6384 - val_loss: 0.5898 - val_acc: 0.7660 - 98ms/epoch - 98ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 0.7933 - acc: 0.7232 - val_loss: 0.5690 - val_acc: 0.7660 - 111ms/epoch - 111ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 0.8198 - acc: 0.7339 - val_loss: 0.5620 - val_acc: 0.7660 - 98ms/epoch - 98ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.6994 - acc: 0.7601 - val_loss: 0.5716 - val_acc: 0.7660 - 101ms/epoch - 101ms/step\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 191.7210 - acc: 0.7670\n",
      "\n",
      "Modality============ 0\n",
      "\tloss: 191.7210\n",
      "\tacc: 0.7670\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "train0: (932, 128)\n",
      "        count\n",
      "labels       \n",
      "1         717\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         645\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          79\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "231    1\n",
      "279    1\n",
      "710    1\n",
      "269    1\n",
      "81     1\n",
      "      ..\n",
      "298    1\n",
      "300    1\n",
      "862    1\n",
      "554    1\n",
      "651    1\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_698\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1397 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1399 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1400 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1047 (Dropout)         (1, 1035, 501)       0           ['input_1397[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_349  (1035, 1035)        0           ['input_1399[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1400[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1047 (GraphC  (1, None, 500)      251000      ['dropout_1047[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_349[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1048 (Dropout)         (1, None, 500)       0           ['graph_convolution_1047[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1048 (GraphC  (1, None, 300)      150300      ['dropout_1048[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_349[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1049 (Dropout)         (1, None, 300)       0           ['graph_convolution_1048[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1049 (GraphC  (1, None, 128)      38528       ['dropout_1049[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_349[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1398 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_349 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1049[0][0]', \n",
      " ces)                                                             'input_1398[0][0]']             \n",
      "                                                                                                  \n",
      " dense_349 (Dense)              (1, None, 2)         258         ['gather_indices_349[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 440,086\n",
      "Trainable params: 440,086\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 12.3839 - acc: 0.4212 - val_loss: 166.4486 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 175.9995 - acc: 0.7697 - val_loss: 47.5955 - val_acc: 0.7660 - 126ms/epoch - 126ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 75.7195 - acc: 0.7697 - val_loss: 6.3706 - val_acc: 0.7660 - 135ms/epoch - 135ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 11.7060 - acc: 0.7697 - val_loss: 0.6216 - val_acc: 0.7872 - 140ms/epoch - 140ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 2.4994 - acc: 0.7351 - val_loss: 5.2739 - val_acc: 0.2340 - 149ms/epoch - 149ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 5.7955 - acc: 0.4535 - val_loss: 2.4773 - val_acc: 0.2021 - 167ms/epoch - 167ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 3.0026 - acc: 0.5095 - val_loss: 0.7164 - val_acc: 0.3511 - 141ms/epoch - 141ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.1470 - acc: 0.6062 - val_loss: 0.5375 - val_acc: 0.7660 - 153ms/epoch - 153ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 0.8415 - acc: 0.7387 - val_loss: 0.5444 - val_acc: 0.7660 - 145ms/epoch - 145ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 0.8261 - acc: 0.7589 - val_loss: 0.5414 - val_acc: 0.7660 - 143ms/epoch - 143ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.9207 - acc: 0.7673 - val_loss: 0.5385 - val_acc: 0.7660 - 143ms/epoch - 143ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 0.7398 - acc: 0.7709 - val_loss: 0.5499 - val_acc: 0.7660 - 139ms/epoch - 139ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 0.6813 - acc: 0.7697 - val_loss: 0.5729 - val_acc: 0.7660 - 136ms/epoch - 136ms/step\n",
      "Epoch 14/200\n",
      "1/1 - 0s - loss: 0.6284 - acc: 0.7673 - val_loss: 0.5962 - val_acc: 0.7660 - 142ms/epoch - 142ms/step\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6300 - acc: 0.7573\n",
      "\n",
      "Modality============ 1\n",
      "\tloss: 0.6300\n",
      "\tacc: 0.7573\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "train1 (932, 128)\n",
      "        count\n",
      "labels       \n",
      "1         717\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         645\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          79\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "231    1\n",
      "279    1\n",
      "710    1\n",
      "269    1\n",
      "81     1\n",
      "      ..\n",
      "298    1\n",
      "300    1\n",
      "862    1\n",
      "554    1\n",
      "651    1\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_700\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1401 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1403 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1404 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1050 (Dropout)         (1, 1035, 501)       0           ['input_1401[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_350  (1035, 1035)        0           ['input_1403[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1404[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1050 (GraphC  (1, None, 500)      251000      ['dropout_1050[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_350[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1051 (Dropout)         (1, None, 500)       0           ['graph_convolution_1050[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1051 (GraphC  (1, None, 250)      125250      ['dropout_1051[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_350[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1052 (Dropout)         (1, None, 250)       0           ['graph_convolution_1051[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1052 (GraphC  (1, None, 128)      32128       ['dropout_1052[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_350[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1402 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_350 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1052[0][0]', \n",
      " ces)                                                             'input_1402[0][0]']             \n",
      "                                                                                                  \n",
      " dense_350 (Dense)              (1, None, 2)         258         ['gather_indices_350[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 408,636\n",
      "Trainable params: 408,636\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 7.4264 - acc: 0.5418 - val_loss: 102.2231 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 133.0509 - acc: 0.7697 - val_loss: 14.3991 - val_acc: 0.7660 - 135ms/epoch - 135ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 18.5350 - acc: 0.7697 - val_loss: 16.3397 - val_acc: 0.2340 - 135ms/epoch - 135ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 13.4004 - acc: 0.4045 - val_loss: 0.9547 - val_acc: 0.2234 - 181ms/epoch - 181ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 2.0237 - acc: 0.6337 - val_loss: 1.1928 - val_acc: 0.7660 - 131ms/epoch - 131ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 2.8292 - acc: 0.7649 - val_loss: 1.2034 - val_acc: 0.7660 - 130ms/epoch - 130ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.7460 - acc: 0.7697 - val_loss: 0.7981 - val_acc: 0.7660 - 148ms/epoch - 148ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.7424 - acc: 0.7578 - val_loss: 0.5559 - val_acc: 0.7660 - 130ms/epoch - 130ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 1.1939 - acc: 0.6778 - val_loss: 0.9409 - val_acc: 0.2128 - 134ms/epoch - 134ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.3558 - acc: 0.5489 - val_loss: 0.7124 - val_acc: 0.3404 - 140ms/epoch - 140ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 1.1671 - acc: 0.5979 - val_loss: 0.5151 - val_acc: 0.7660 - 141ms/epoch - 141ms/step\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 116.1909 - acc: 0.7670\n",
      "\n",
      "Modality============ 2\n",
      "\tloss: 116.1909\n",
      "\tacc: 0.7670\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "train2: (932, 128)\n",
      "        count\n",
      "labels       \n",
      "1         717\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         645\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          79\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "231    1\n",
      "279    1\n",
      "710    1\n",
      "269    1\n",
      "81     1\n",
      "      ..\n",
      "298    1\n",
      "300    1\n",
      "862    1\n",
      "554    1\n",
      "651    1\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_702\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1405 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1407 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1408 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1053 (Dropout)         (1, 1035, 501)       0           ['input_1405[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_351  (1035, 1035)        0           ['input_1407[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1408[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1053 (GraphC  (1, None, 800)      401600      ['dropout_1053[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_351[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1054 (Dropout)         (1, None, 800)       0           ['graph_convolution_1053[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1054 (GraphC  (1, None, 400)      320400      ['dropout_1054[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_351[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1055 (Dropout)         (1, None, 400)       0           ['graph_convolution_1054[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1055 (GraphC  (1, None, 128)      51328       ['dropout_1055[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_351[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1406 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_351 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1055[0][0]', \n",
      " ces)                                                             'input_1406[0][0]']             \n",
      "                                                                                                  \n",
      " dense_351 (Dense)              (1, None, 2)         258         ['gather_indices_351[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 773,586\n",
      "Trainable params: 773,586\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 8.5270 - acc: 0.6169 - val_loss: 118.6438 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 148.1687 - acc: 0.7697 - val_loss: 62.4834 - val_acc: 0.2340 - 160ms/epoch - 160ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 43.3948 - acc: 0.3723 - val_loss: 8.9592 - val_acc: 0.7660 - 162ms/epoch - 162ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 14.0130 - acc: 0.7697 - val_loss: 8.3028 - val_acc: 0.7660 - 154ms/epoch - 154ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 12.4747 - acc: 0.7697 - val_loss: 5.1879 - val_acc: 0.7660 - 177ms/epoch - 177ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 7.3540 - acc: 0.7697 - val_loss: 1.9170 - val_acc: 0.7660 - 154ms/epoch - 154ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 3.4867 - acc: 0.7697 - val_loss: 2.2617 - val_acc: 0.2021 - 154ms/epoch - 154ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.6201 - acc: 0.6372 - val_loss: 4.5111 - val_acc: 0.2340 - 152ms/epoch - 152ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.5857 - acc: 0.4714 - val_loss: 2.5485 - val_acc: 0.2340 - 154ms/epoch - 154ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.8449 - acc: 0.5024 - val_loss: 0.6981 - val_acc: 0.4255 - 156ms/epoch - 156ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 1.0261 - acc: 0.6647 - val_loss: 0.5396 - val_acc: 0.7660 - 179ms/epoch - 179ms/step\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 134.9720 - acc: 0.7670\n",
      "\n",
      "Modality============ 4\n",
      "\tloss: 134.9720\n",
      "\tacc: 0.7670\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "train4: (932, 128)\n",
      "Clinical expanded shape: (932, 128)\n",
      "Clinical test expanded shape: (103, 128)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 0, Loss: 1.6177469491958618\n",
      "Attention Weights: tensor([0.2934, 0.0627, 0.0666, 0.3254, 0.2519], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 10, Loss: 0.6290732622146606\n",
      "Attention Weights: tensor([0.2934, 0.0627, 0.0666, 0.3254, 0.2519], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 20, Loss: 0.5705448985099792\n",
      "Attention Weights: tensor([0.2934, 0.0627, 0.0666, 0.3254, 0.2519], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 30, Loss: 0.5520809292793274\n",
      "Attention Weights: tensor([0.2934, 0.0627, 0.0666, 0.3253, 0.2519], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 40, Loss: 0.5460041761398315\n",
      "Attention Weights: tensor([0.2934, 0.0627, 0.0666, 0.3253, 0.2519], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Random Forest Classifier Accuracy: 0.7669902912621359\n",
      "Logistic Regression Accuracy: 0.7669902912621359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "UserWarning: [15:11:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.7669902912621359\n",
      "Test Accuracies: 0.7669902912621359 0.7669902912621359 0.7669902912621359\n",
      "Validation Accuracies: 0.839572192513369 0.8181818181818182 0.8449197860962567\n",
      "Final Ensemble Prediction: [0.461544492931739, 0.420597511354708, 0.419315790659820, 0.501017352453514, 0.397146840483887, 0.489684181440056, 0.484139251485086, 0.506084864479883, 0.523846221933326, 0.502255901966441, 0.522903929693951, 0.545070383038898, 0.545006342013083, 0.587322523172797, 0.590213102915597, 0.557272284201814, 0.595059304167217, 0.607821568960846, 0.574075842787791, 0.569879152038381, 0.563925220432482, 0.591879768269228, 0.560578309753125, 0.599970946975156, 0.597934802958690, 0.606071481812405, 0.615502366893554, 0.607080007131613, 0.611713676084845, 0.621263617853678, 0.616656358214093, 0.609717472331749, 0.611548805494385, 0.612705408241927, 0.616523705855266, 0.588067605366258, 0.606247328120621, 0.580155854069619, 0.597418710951487, 0.602613620710789, 0.610882482375035, 0.591307252133037, 0.596404078850177, 0.550750669441468, 0.595615003663188, 0.624603117195619, 0.645035194924256, 0.599944780844555, 0.607253787445503, 0.603233349541461, 0.610482056502818, 0.605961468409856, 0.638762884065429, 0.647655785204660, 0.628156585204878, 0.635851669638587, 0.622904324820516, 0.649582066478761, 0.652359803944868, 0.621902323439556, 0.652164095002150, 0.662195432321802, 0.656252006955440, 0.667164047808761, 0.663210638636908, 0.663874446534212, 0.656928367253325, 0.667165752372127, 0.686998008866575, 0.672150727266921, 0.689990339034267, 0.688769365382144, 0.707541390861734, 0.704935161680382, 0.689728981863709, 0.686298841435481, 0.702385147096481, 0.701814979131028, 0.702434344962195, 0.686316431519614, 0.700377529724560, 0.701579304365473, 0.727541074559921, 0.709738798165981, 0.700594617608802, 0.735145370899150, 0.731162989978821, 0.719701967199089, 0.730867117972742, 0.727601084566287, 0.738334974495323, 0.715326084176311, 0.759150729509945, 0.733560541236274, 0.729640382470302, 0.732837111032709, 0.751186558478763, 0.767693980109512, 0.766688068128748, 0.767331590643501, 0.770803783497608, 0.779598553243341, 0.777431018070132]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label Counts:\n",
      " 1    103\n",
      "Name: count, dtype: int64\n",
      "y_pred_actual:\n",
      " 1    79\n",
      "0    24\n",
      "Name: count, dtype: int64\n",
      "Confusion Matrix : \n",
      " [[ 0 24]\n",
      " [ 0 79]]\n",
      "fold number ################################################ 9\n",
      "        count\n",
      "labels       \n",
      "1         717\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         645\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          79\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "226    1\n",
      "277    1\n",
      "702    1\n",
      "266    1\n",
      "81     1\n",
      "      ..\n",
      "294    1\n",
      "296    1\n",
      "857    1\n",
      "555    1\n",
      "642    1\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_704\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1409 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1411 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1412 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1056 (Dropout)         (1, 1035, 501)       0           ['input_1409[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_352  (1035, 1035)        0           ['input_1411[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1412[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1056 (GraphC  (1, None, 500)      251000      ['dropout_1056[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_352[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1057 (Dropout)         (1, None, 500)       0           ['graph_convolution_1056[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1057 (GraphC  (1, None, 350)      175350      ['dropout_1057[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_352[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1058 (Dropout)         (1, None, 350)       0           ['graph_convolution_1057[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1058 (GraphC  (1, None, 128)      44928       ['dropout_1058[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_352[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1410 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_352 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1058[0][0]', \n",
      " ces)                                                             'input_1410[0][0]']             \n",
      "                                                                                                  \n",
      " dense_352 (Dense)              (1, None, 2)         258         ['gather_indices_352[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 471,536\n",
      "Trainable params: 471,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 12.4937 - acc: 0.7375 - val_loss: 670.1247 - val_acc: 0.2340 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 724.9374 - acc: 0.2303 - val_loss: 76.9863 - val_acc: 0.2340 - 168ms/epoch - 168ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 92.9317 - acc: 0.2303 - val_loss: 0.9118 - val_acc: 0.7660 - 147ms/epoch - 147ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 2.2144 - acc: 0.7053 - val_loss: 1.9840 - val_acc: 0.7660 - 144ms/epoch - 144ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 4.6355 - acc: 0.7685 - val_loss: 1.0515 - val_acc: 0.7660 - 145ms/epoch - 145ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 3.0471 - acc: 0.7673 - val_loss: 0.5384 - val_acc: 0.7660 - 164ms/epoch - 164ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 1.8653 - acc: 0.7411 - val_loss: 2.0181 - val_acc: 0.2660 - 146ms/epoch - 146ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 2.2369 - acc: 0.4499 - val_loss: 1.0861 - val_acc: 0.3191 - 144ms/epoch - 144ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 1.4326 - acc: 0.4952 - val_loss: 0.5534 - val_acc: 0.7660 - 173ms/epoch - 173ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 0.8947 - acc: 0.6885 - val_loss: 0.5256 - val_acc: 0.7660 - 165ms/epoch - 165ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.7747 - acc: 0.7518 - val_loss: 0.5414 - val_acc: 0.7660 - 158ms/epoch - 158ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 0.8099 - acc: 0.7506 - val_loss: 0.5440 - val_acc: 0.7660 - 149ms/epoch - 149ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 0.8056 - acc: 0.7589 - val_loss: 0.5399 - val_acc: 0.7660 - 157ms/epoch - 157ms/step\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0387 - acc: 0.7670\n",
      "\n",
      "Modality============ 0\n",
      "\tloss: 1.0387\n",
      "\tacc: 0.7670\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "train0: (932, 128)\n",
      "        count\n",
      "labels       \n",
      "1         717\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         645\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          79\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "226    1\n",
      "277    1\n",
      "702    1\n",
      "266    1\n",
      "81     1\n",
      "      ..\n",
      "294    1\n",
      "296    1\n",
      "857    1\n",
      "555    1\n",
      "642    1\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_706\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1413 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1415 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1416 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1059 (Dropout)         (1, 1035, 501)       0           ['input_1413[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_353  (1035, 1035)        0           ['input_1415[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1416[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1059 (GraphC  (1, None, 500)      251000      ['dropout_1059[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_353[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1060 (Dropout)         (1, None, 500)       0           ['graph_convolution_1059[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1060 (GraphC  (1, None, 300)      150300      ['dropout_1060[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_353[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1061 (Dropout)         (1, None, 300)       0           ['graph_convolution_1060[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1061 (GraphC  (1, None, 128)      38528       ['dropout_1061[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_353[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1414 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_353 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1061[0][0]', \n",
      " ces)                                                             'input_1414[0][0]']             \n",
      "                                                                                                  \n",
      " dense_353 (Dense)              (1, None, 2)         258         ['gather_indices_353[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 440,086\n",
      "Trainable params: 440,086\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 11.8529 - acc: 0.4057 - val_loss: 211.3670 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 233.6263 - acc: 0.7697 - val_loss: 58.5779 - val_acc: 0.7660 - 126ms/epoch - 126ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 67.3050 - acc: 0.7697 - val_loss: 8.0109 - val_acc: 0.7660 - 141ms/epoch - 141ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 15.2529 - acc: 0.7697 - val_loss: 14.0491 - val_acc: 0.2340 - 130ms/epoch - 130ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 11.3055 - acc: 0.5322 - val_loss: 3.9133 - val_acc: 0.2128 - 136ms/epoch - 136ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 5.5760 - acc: 0.5406 - val_loss: 0.7458 - val_acc: 0.7660 - 135ms/epoch - 135ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 1.7959 - acc: 0.7387 - val_loss: 1.0246 - val_acc: 0.7660 - 151ms/epoch - 151ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.9212 - acc: 0.7661 - val_loss: 0.9483 - val_acc: 0.7660 - 139ms/epoch - 139ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 1.5261 - acc: 0.7697 - val_loss: 0.7774 - val_acc: 0.7660 - 140ms/epoch - 140ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.2439 - acc: 0.7673 - val_loss: 0.6346 - val_acc: 0.7660 - 142ms/epoch - 142ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.9294 - acc: 0.7697 - val_loss: 0.5675 - val_acc: 0.7660 - 129ms/epoch - 129ms/step\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 234.7891 - acc: 0.7670\n",
      "\n",
      "Modality============ 1\n",
      "\tloss: 234.7891\n",
      "\tacc: 0.7670\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "train1 (932, 128)\n",
      "        count\n",
      "labels       \n",
      "1         717\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         645\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          79\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "226    1\n",
      "277    1\n",
      "702    1\n",
      "266    1\n",
      "81     1\n",
      "      ..\n",
      "294    1\n",
      "296    1\n",
      "857    1\n",
      "555    1\n",
      "642    1\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_708\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1417 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1419 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1420 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1062 (Dropout)         (1, 1035, 501)       0           ['input_1417[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_354  (1035, 1035)        0           ['input_1419[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1420[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1062 (GraphC  (1, None, 500)      251000      ['dropout_1062[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_354[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1063 (Dropout)         (1, None, 500)       0           ['graph_convolution_1062[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1063 (GraphC  (1, None, 250)      125250      ['dropout_1063[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_354[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1064 (Dropout)         (1, None, 250)       0           ['graph_convolution_1063[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1064 (GraphC  (1, None, 128)      32128       ['dropout_1064[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_354[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1418 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_354 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1064[0][0]', \n",
      " ces)                                                             'input_1418[0][0]']             \n",
      "                                                                                                  \n",
      " dense_354 (Dense)              (1, None, 2)         258         ['gather_indices_354[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 408,636\n",
      "Trainable params: 408,636\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 26.2296 - acc: 0.2649 - val_loss: 118.1281 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 154.6161 - acc: 0.7697 - val_loss: 47.8063 - val_acc: 0.7660 - 131ms/epoch - 131ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 68.2924 - acc: 0.7697 - val_loss: 11.9366 - val_acc: 0.7660 - 126ms/epoch - 126ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 21.9947 - acc: 0.7697 - val_loss: 1.0948 - val_acc: 0.7660 - 137ms/epoch - 137ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 3.9555 - acc: 0.7446 - val_loss: 16.5677 - val_acc: 0.2340 - 126ms/epoch - 126ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 13.8485 - acc: 0.3258 - val_loss: 9.7718 - val_acc: 0.2340 - 128ms/epoch - 128ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 8.2840 - acc: 0.3556 - val_loss: 2.3444 - val_acc: 0.2340 - 121ms/epoch - 121ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 3.4446 - acc: 0.4379 - val_loss: 0.7117 - val_acc: 0.7660 - 133ms/epoch - 133ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 1.4719 - acc: 0.7303 - val_loss: 0.9636 - val_acc: 0.7660 - 127ms/epoch - 127ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.5411 - acc: 0.7661 - val_loss: 0.9935 - val_acc: 0.7660 - 130ms/epoch - 130ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 1.6029 - acc: 0.7673 - val_loss: 0.8643 - val_acc: 0.7660 - 134ms/epoch - 134ms/step\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 149.9963 - acc: 0.7670\n",
      "\n",
      "Modality============ 2\n",
      "\tloss: 149.9963\n",
      "\tacc: 0.7670\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "train2: (932, 128)\n",
      "        count\n",
      "labels       \n",
      "1         717\n",
      "0         215\n",
      "        count\n",
      "labels       \n",
      "1         645\n",
      "0         193\n",
      "        count\n",
      "labels       \n",
      "1          79\n",
      "0          24\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "226    1\n",
      "277    1\n",
      "702    1\n",
      "266    1\n",
      "81     1\n",
      "      ..\n",
      "294    1\n",
      "296    1\n",
      "857    1\n",
      "555    1\n",
      "642    1\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_710\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1421 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1423 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1424 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1065 (Dropout)         (1, 1035, 501)       0           ['input_1421[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_355  (1035, 1035)        0           ['input_1423[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1424[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1065 (GraphC  (1, None, 800)      401600      ['dropout_1065[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_355[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1066 (Dropout)         (1, None, 800)       0           ['graph_convolution_1065[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1066 (GraphC  (1, None, 400)      320400      ['dropout_1066[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_355[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1067 (Dropout)         (1, None, 400)       0           ['graph_convolution_1066[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1067 (GraphC  (1, None, 128)      51328       ['dropout_1067[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_355[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1422 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_355 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1067[0][0]', \n",
      " ces)                                                             'input_1422[0][0]']             \n",
      "                                                                                                  \n",
      " dense_355 (Dense)              (1, None, 2)         258         ['gather_indices_355[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 773,586\n",
      "Trainable params: 773,586\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 13.2420 - acc: 0.7625 - val_loss: 1142.2957 - val_acc: 0.2340 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 1050.0854 - acc: 0.2303 - val_loss: 96.9759 - val_acc: 0.2447 - 197ms/epoch - 197ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 95.2907 - acc: 0.2768 - val_loss: 9.7657 - val_acc: 0.7660 - 152ms/epoch - 152ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 12.7431 - acc: 0.7685 - val_loss: 7.8801 - val_acc: 0.7660 - 143ms/epoch - 143ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 10.4407 - acc: 0.7697 - val_loss: 3.3846 - val_acc: 0.7660 - 152ms/epoch - 152ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 5.4411 - acc: 0.7661 - val_loss: 0.7150 - val_acc: 0.3298 - 157ms/epoch - 157ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.1758 - acc: 0.6718 - val_loss: 4.9228 - val_acc: 0.2447 - 157ms/epoch - 157ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 3.2057 - acc: 0.4916 - val_loss: 2.9548 - val_acc: 0.2447 - 157ms/epoch - 157ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 1.7262 - acc: 0.5119 - val_loss: 0.7342 - val_acc: 0.3085 - 148ms/epoch - 148ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 0.8846 - acc: 0.6420 - val_loss: 0.5038 - val_acc: 0.7660 - 148ms/epoch - 148ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.8218 - acc: 0.7566 - val_loss: 0.5312 - val_acc: 0.7660 - 157ms/epoch - 157ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 0.8794 - acc: 0.7661 - val_loss: 0.5165 - val_acc: 0.7660 - 145ms/epoch - 145ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 0.9043 - acc: 0.7625 - val_loss: 0.4959 - val_acc: 0.7660 - 145ms/epoch - 145ms/step\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 12.3165 - acc: 0.7670\n",
      "\n",
      "Modality============ 4\n",
      "\tloss: 12.3165\n",
      "\tacc: 0.7670\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "train4: (932, 128)\n",
      "Clinical expanded shape: (932, 128)\n",
      "Clinical test expanded shape: (103, 128)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 0, Loss: 1.389135479927063\n",
      "Attention Weights: tensor([0.2024, 0.0913, 0.0800, 0.0951, 0.5311], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 10, Loss: 2.3478188514709473\n",
      "Attention Weights: tensor([0.2024, 0.0913, 0.0800, 0.0951, 0.5311], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 20, Loss: 0.7595713138580322\n",
      "Attention Weights: tensor([0.2024, 0.0913, 0.0800, 0.0951, 0.5311], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 30, Loss: 0.659426212310791\n",
      "Attention Weights: tensor([0.2024, 0.0913, 0.0800, 0.0951, 0.5311], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 40, Loss: 0.5716299414634705\n",
      "Attention Weights: tensor([0.2024, 0.0913, 0.0800, 0.0951, 0.5311], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Random Forest Classifier Accuracy: 0.5339805825242718\n",
      "Logistic Regression Accuracy: 0.7669902912621359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "UserWarning: [15:12:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.7669902912621359\n",
      "Test Accuracies: 0.5339805825242718 0.7669902912621359 0.7669902912621359\n",
      "Validation Accuracies: 0.8288770053475936 0.7967914438502673 0.8074866310160428\n",
      "Final Ensemble Prediction: [0.447024997867632, 0.479060111650186, 0.470212164981440, 0.469940359170687, 0.465844023529604, 0.453152055361305, 0.482839838397913, 0.529556361167926, 0.520251871135634, 0.502264165740261, 0.511360900553633, 0.527634081954041, 0.543426843073587, 0.531287347613855, 0.549660892906673, 0.539257266093068, 0.564700573223634, 0.557782784845356, 0.570314775125602, 0.549350823001374, 0.568752661739092, 0.552704364139614, 0.597601650404626, 0.580725111378297, 0.592102520490190, 0.582251461938477, 0.574354477779569, 0.597664163791038, 0.617657822978193, 0.568528887260991, 0.609337451642509, 0.594221525268717, 0.605279903226518, 0.610871346083050, 0.560505734758574, 0.602211873762272, 0.570149887560153, 0.597450447361505, 0.589471710551522, 0.643179123175868, 0.616014243308913, 0.602053781417625, 0.596479572185266, 0.609691138898466, 0.640115760984251, 0.589601790122556, 0.629806799011847, 0.619034023028368, 0.625237651251827, 0.617069999010360, 0.632821001494154, 0.666584162480859, 0.669324941054377, 0.642791322130101, 0.624060725181624, 0.641545554461390, 0.662952707456148, 0.695058813804178, 0.648397121832043, 0.653267174579190, 0.650848927521023, 0.642828851701791, 0.668106777173803, 0.658952722207366, 0.629605023099249, 0.624612347792334, 0.621137691515187, 0.667498402688540, 0.625016331389605, 0.652378760846580, 0.667209018152295, 0.618810972052758, 0.660581731316745, 0.626823722302265, 0.667471626658584, 0.626732547359025, 0.708915590474929, 0.643069980777950, 0.637595623164294, 0.680311413118784, 0.638686300030123, 0.687981075094539, 0.642772374829528, 0.643512893426533, 0.662666641329640, 0.638533564450372, 0.736144205121423, 0.707916162443600, 0.659178543189767, 0.661694164638586, 0.655792387663327, 0.687561724685864, 0.669102526366205, 0.729898786400216, 0.691705627386366, 0.677670032699980, 0.678773368095485, 0.746974440228602, 0.764381427819490, 0.732228067182357, 0.732092590690245, 0.728890612043054, 0.701823019147277]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label Counts:\n",
      " 1    103\n",
      "Name: count, dtype: int64\n",
      "y_pred_actual:\n",
      " 1    79\n",
      "0    24\n",
      "Name: count, dtype: int64\n",
      "Confusion Matrix : \n",
      " [[ 0 24]\n",
      " [ 0 79]]\n",
      "fold number ################################################ 10\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         216\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         194\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          23\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "235    0\n",
      "270    1\n",
      "473    1\n",
      "650    1\n",
      "350    0\n",
      "      ..\n",
      "347    0\n",
      "799    0\n",
      "441    0\n",
      "269    1\n",
      "447    0\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_712\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1425 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1427 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1428 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1068 (Dropout)         (1, 1035, 501)       0           ['input_1425[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_356  (1035, 1035)        0           ['input_1427[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1428[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1068 (GraphC  (1, None, 500)      251000      ['dropout_1068[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_356[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1069 (Dropout)         (1, None, 500)       0           ['graph_convolution_1068[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1069 (GraphC  (1, None, 350)      175350      ['dropout_1069[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_356[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1070 (Dropout)         (1, None, 350)       0           ['graph_convolution_1069[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1070 (GraphC  (1, None, 128)      44928       ['dropout_1070[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_356[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1426 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_356 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1070[0][0]', \n",
      " ces)                                                             'input_1426[0][0]']             \n",
      "                                                                                                  \n",
      " dense_356 (Dense)              (1, None, 2)         258         ['gather_indices_356[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 471,536\n",
      "Trainable params: 471,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 9.6710 - acc: 0.6480 - val_loss: 308.1396 - val_acc: 0.2340 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 302.4817 - acc: 0.2315 - val_loss: 10.1814 - val_acc: 0.7660 - 145ms/epoch - 145ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 12.2455 - acc: 0.7637 - val_loss: 8.3621 - val_acc: 0.7660 - 138ms/epoch - 138ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 12.4303 - acc: 0.7637 - val_loss: 2.7557 - val_acc: 0.7979 - 137ms/epoch - 137ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 6.0486 - acc: 0.6408 - val_loss: 5.4809 - val_acc: 0.2340 - 148ms/epoch - 148ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 5.2345 - acc: 0.3174 - val_loss: 0.5650 - val_acc: 0.7553 - 138ms/epoch - 138ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 1.7691 - acc: 0.6480 - val_loss: 1.3425 - val_acc: 0.7660 - 142ms/epoch - 142ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.9391 - acc: 0.7578 - val_loss: 1.4296 - val_acc: 0.7660 - 133ms/epoch - 133ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 1.9850 - acc: 0.7649 - val_loss: 1.1894 - val_acc: 0.7660 - 135ms/epoch - 135ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.7294 - acc: 0.7649 - val_loss: 0.8390 - val_acc: 0.7660 - 137ms/epoch - 137ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 1.3062 - acc: 0.7589 - val_loss: 0.6829 - val_acc: 0.5532 - 138ms/epoch - 138ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 0.9203 - acc: 0.7232 - val_loss: 1.0762 - val_acc: 0.2340 - 134ms/epoch - 134ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 1.0542 - acc: 0.5668 - val_loss: 1.1693 - val_acc: 0.2447 - 139ms/epoch - 139ms/step\n",
      "Epoch 14/200\n",
      "1/1 - 0s - loss: 0.9861 - acc: 0.5298 - val_loss: 0.8382 - val_acc: 0.4787 - 137ms/epoch - 137ms/step\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.9747 - acc: 0.7379\n",
      "\n",
      "Modality============ 0\n",
      "\tloss: 3.9747\n",
      "\tacc: 0.7379\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "train0: (932, 128)\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         216\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         194\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          23\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "235    0\n",
      "270    1\n",
      "473    1\n",
      "650    1\n",
      "350    0\n",
      "      ..\n",
      "347    0\n",
      "799    0\n",
      "441    0\n",
      "269    1\n",
      "447    0\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_714\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1429 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1431 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1432 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1071 (Dropout)         (1, 1035, 501)       0           ['input_1429[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_357  (1035, 1035)        0           ['input_1431[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1432[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1071 (GraphC  (1, None, 500)      251000      ['dropout_1071[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_357[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1072 (Dropout)         (1, None, 500)       0           ['graph_convolution_1071[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1072 (GraphC  (1, None, 300)      150300      ['dropout_1072[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_357[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1073 (Dropout)         (1, None, 300)       0           ['graph_convolution_1072[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1073 (GraphC  (1, None, 128)      38528       ['dropout_1073[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_357[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1430 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_357 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1073[0][0]', \n",
      " ces)                                                             'input_1430[0][0]']             \n",
      "                                                                                                  \n",
      " dense_357 (Dense)              (1, None, 2)         258         ['gather_indices_357[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 440,086\n",
      "Trainable params: 440,086\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 13.6605 - acc: 0.5573 - val_loss: 194.8181 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 240.2630 - acc: 0.7685 - val_loss: 42.7967 - val_acc: 0.7660 - 119ms/epoch - 119ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 65.2101 - acc: 0.7685 - val_loss: 3.9477 - val_acc: 0.7660 - 121ms/epoch - 121ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 9.7172 - acc: 0.7685 - val_loss: 5.1689 - val_acc: 0.2340 - 123ms/epoch - 123ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 3.5271 - acc: 0.5442 - val_loss: 3.3938 - val_acc: 0.2340 - 129ms/epoch - 129ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 3.1745 - acc: 0.5048 - val_loss: 0.9497 - val_acc: 0.2128 - 124ms/epoch - 124ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 1.2935 - acc: 0.5979 - val_loss: 0.5161 - val_acc: 0.7660 - 129ms/epoch - 129ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 1.0088 - acc: 0.7434 - val_loss: 0.5314 - val_acc: 0.7660 - 131ms/epoch - 131ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 0.9200 - acc: 0.7697 - val_loss: 0.5250 - val_acc: 0.7660 - 123ms/epoch - 123ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 0.9009 - acc: 0.7649 - val_loss: 0.5151 - val_acc: 0.7660 - 126ms/epoch - 126ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.8793 - acc: 0.7685 - val_loss: 0.5168 - val_acc: 0.7660 - 119ms/epoch - 119ms/step\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 222.4136 - acc: 0.7767\n",
      "\n",
      "Modality============ 1\n",
      "\tloss: 222.4136\n",
      "\tacc: 0.7767\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "train1 (932, 128)\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         216\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         194\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          23\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "235    0\n",
      "270    1\n",
      "473    1\n",
      "650    1\n",
      "350    0\n",
      "      ..\n",
      "347    0\n",
      "799    0\n",
      "441    0\n",
      "269    1\n",
      "447    0\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_716\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1433 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1435 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1436 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1074 (Dropout)         (1, 1035, 501)       0           ['input_1433[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_358  (1035, 1035)        0           ['input_1435[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1436[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1074 (GraphC  (1, None, 500)      251000      ['dropout_1074[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_358[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1075 (Dropout)         (1, None, 500)       0           ['graph_convolution_1074[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1075 (GraphC  (1, None, 250)      125250      ['dropout_1075[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_358[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1076 (Dropout)         (1, None, 250)       0           ['graph_convolution_1075[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1076 (GraphC  (1, None, 128)      32128       ['dropout_1076[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_358[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1434 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_358 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1076[0][0]', \n",
      " ces)                                                             'input_1434[0][0]']             \n",
      "                                                                                                  \n",
      " dense_358 (Dense)              (1, None, 2)         258         ['gather_indices_358[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 408,636\n",
      "Trainable params: 408,636\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 7.4277 - acc: 0.7148 - val_loss: 404.0833 - val_acc: 0.2340 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 402.3389 - acc: 0.2315 - val_loss: 1.5439 - val_acc: 0.3191 - 119ms/epoch - 119ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 12.3064 - acc: 0.5382 - val_loss: 29.1847 - val_acc: 0.7660 - 114ms/epoch - 114ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 33.3475 - acc: 0.7685 - val_loss: 22.4587 - val_acc: 0.7660 - 114ms/epoch - 114ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 27.9960 - acc: 0.7685 - val_loss: 10.8809 - val_acc: 0.7660 - 113ms/epoch - 113ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 13.8948 - acc: 0.7339 - val_loss: 2.0125 - val_acc: 0.7553 - 120ms/epoch - 120ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 5.6911 - acc: 0.6957 - val_loss: 1.8715 - val_acc: 0.2340 - 114ms/epoch - 114ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 2.7756 - acc: 0.5680 - val_loss: 2.3894 - val_acc: 0.2447 - 120ms/epoch - 120ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 1.6424 - acc: 0.5513 - val_loss: 0.5719 - val_acc: 0.7766 - 119ms/epoch - 119ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.3119 - acc: 0.6909 - val_loss: 0.6115 - val_acc: 0.7660 - 114ms/epoch - 114ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 1.4324 - acc: 0.7303 - val_loss: 0.6104 - val_acc: 0.7660 - 118ms/epoch - 118ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 1.2326 - acc: 0.7530 - val_loss: 0.5238 - val_acc: 0.7660 - 115ms/epoch - 115ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 0.8717 - acc: 0.7315 - val_loss: 0.6754 - val_acc: 0.7234 - 113ms/epoch - 113ms/step\n",
      "Epoch 14/200\n",
      "1/1 - 0s - loss: 1.0763 - acc: 0.5931 - val_loss: 0.5655 - val_acc: 0.7660 - 118ms/epoch - 118ms/step\n",
      "Epoch 15/200\n",
      "1/1 - 0s - loss: 0.8446 - acc: 0.6635 - val_loss: 0.5274 - val_acc: 0.7660 - 129ms/epoch - 129ms/step\n",
      "Epoch 16/200\n",
      "1/1 - 0s - loss: 0.7794 - acc: 0.7351 - val_loss: 0.5286 - val_acc: 0.7660 - 118ms/epoch - 118ms/step\n",
      "Epoch 17/200\n",
      "1/1 - 0s - loss: 0.8840 - acc: 0.7530 - val_loss: 0.5282 - val_acc: 0.7660 - 114ms/epoch - 114ms/step\n",
      "Epoch 18/200\n",
      "1/1 - 0s - loss: 0.7319 - acc: 0.7387 - val_loss: 0.5762 - val_acc: 0.7660 - 113ms/epoch - 113ms/step\n",
      "Epoch 19/200\n",
      "1/1 - 0s - loss: 0.6936 - acc: 0.7339 - val_loss: 0.6228 - val_acc: 0.7660 - 112ms/epoch - 112ms/step\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6043 - acc: 0.7670\n",
      "\n",
      "Modality============ 2\n",
      "\tloss: 0.6043\n",
      "\tacc: 0.7670\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "train2: (932, 128)\n",
      "        count\n",
      "labels       \n",
      "1         716\n",
      "0         216\n",
      "        count\n",
      "labels       \n",
      "1         644\n",
      "0         194\n",
      "        count\n",
      "labels       \n",
      "1          80\n",
      "0          23\n",
      "        count\n",
      "labels       \n",
      "1          72\n",
      "0          22\n",
      "235    0\n",
      "270    1\n",
      "473    1\n",
      "650    1\n",
      "350    0\n",
      "      ..\n",
      "347    0\n",
      "799    0\n",
      "441    0\n",
      "269    1\n",
      "447    0\n",
      "Name: labels, Length: 838, dtype: int64\n",
      "Using GCN (local pooling) filters...\n",
      "Model: \"model_718\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1437 (InputLayer)        [(1, 1035, 501)]     0           []                               \n",
      "                                                                                                  \n",
      " input_1439 (InputLayer)        [(1, None, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1440 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1077 (Dropout)         (1, 1035, 501)       0           ['input_1437[0][0]']             \n",
      "                                                                                                  \n",
      " squeezed_sparse_conversion_359  (1035, 1035)        0           ['input_1439[0][0]',             \n",
      "  (SqueezedSparseConversion)                                      'input_1440[0][0]']             \n",
      "                                                                                                  \n",
      " graph_convolution_1077 (GraphC  (1, None, 800)      401600      ['dropout_1077[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_359[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1078 (Dropout)         (1, None, 800)       0           ['graph_convolution_1077[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1078 (GraphC  (1, None, 400)      320400      ['dropout_1078[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_359[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " dropout_1079 (Dropout)         (1, None, 400)       0           ['graph_convolution_1078[0][0]'] \n",
      "                                                                                                  \n",
      " graph_convolution_1079 (GraphC  (1, None, 128)      51328       ['dropout_1079[0][0]',           \n",
      " onvolution)                                                      'squeezed_sparse_conversion_359[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " input_1438 (InputLayer)        [(1, None)]          0           []                               \n",
      "                                                                                                  \n",
      " gather_indices_359 (GatherIndi  (1, None, 128)      0           ['graph_convolution_1079[0][0]', \n",
      " ces)                                                             'input_1438[0][0]']             \n",
      "                                                                                                  \n",
      " dense_359 (Dense)              (1, None, 2)         258         ['gather_indices_359[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 773,586\n",
      "Trainable params: 773,586\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 6.0710 - acc: 0.5585 - val_loss: 188.1416 - val_acc: 0.7660 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 244.1981 - acc: 0.7685 - val_loss: 15.2812 - val_acc: 0.7660 - 152ms/epoch - 152ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 19.9145 - acc: 0.7685 - val_loss: 34.4224 - val_acc: 0.2340 - 145ms/epoch - 145ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 26.9483 - acc: 0.2387 - val_loss: 10.3935 - val_acc: 0.2340 - 138ms/epoch - 138ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 7.8077 - acc: 0.3401 - val_loss: 2.4476 - val_acc: 0.7660 - 131ms/epoch - 131ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 4.2656 - acc: 0.7697 - val_loss: 3.1125 - val_acc: 0.7660 - 132ms/epoch - 132ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 4.2617 - acc: 0.7685 - val_loss: 2.2934 - val_acc: 0.7660 - 136ms/epoch - 136ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 3.4790 - acc: 0.7685 - val_loss: 1.4595 - val_acc: 0.7660 - 138ms/epoch - 138ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.0757 - acc: 0.7685 - val_loss: 0.6166 - val_acc: 0.7660 - 139ms/epoch - 139ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 1.1993 - acc: 0.7613 - val_loss: 1.1176 - val_acc: 0.2553 - 136ms/epoch - 136ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 1.0668 - acc: 0.6337 - val_loss: 1.3846 - val_acc: 0.2553 - 147ms/epoch - 147ms/step\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 197.6114 - acc: 0.7767\n",
      "\n",
      "Modality============ 4\n",
      "\tloss: 197.6114\n",
      "\tacc: 0.7767\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "train4: (932, 128)\n",
      "Clinical expanded shape: (932, 128)\n",
      "Clinical test expanded shape: (103, 128)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 0, Loss: 0.9760945439338684\n",
      "Attention Weights: tensor([0.2024, 0.0433, 0.2049, 0.5296, 0.0198], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 10, Loss: 2.688532590866089\n",
      "Attention Weights: tensor([0.2024, 0.0433, 0.2049, 0.5295, 0.0199], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 20, Loss: 0.7418515086174011\n",
      "Attention Weights: tensor([0.2024, 0.0433, 0.2049, 0.5294, 0.0199], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 30, Loss: 0.6056756377220154\n",
      "Attention Weights: tensor([0.2024, 0.0433, 0.2049, 0.5294, 0.0199], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Epoch 40, Loss: 0.562252938747406\n",
      "Attention Weights: tensor([0.2024, 0.0434, 0.2049, 0.5294, 0.0199], grad_fn=<SoftmaxBackward0>)\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Shape before fusion: [(932, 128), (932, 128), (932, 128), (932, 128), (932, 128)]\n",
      "Shape after fusion: torch.Size([932, 640])\n",
      "Random Forest Classifier Accuracy: 0.7766990291262136\n",
      "Logistic Regression Accuracy: 0.7766990291262136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "UserWarning: [15:12:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.7766990291262136\n",
      "Test Accuracies: 0.7766990291262136 0.7766990291262136 0.7766990291262136\n",
      "Validation Accuracies: 0.8181818181818182 0.93048128342246 0.786096256684492\n",
      "Final Ensemble Prediction: [0.427821043947506, 0.459295389576281, 0.342776690125471, 0.445036064330123, 0.429553105010101, 0.502714969508782, 0.536468543045891, 0.530712555502698, 0.520786456784799, 0.528044927198929, 0.565523906487540, 0.491488452419855, 0.556668881126071, 0.534384152339178, 0.530802400318267, 0.540038405859131, 0.507349734361332, 0.541241216959633, 0.486671951542263, 0.496633219614477, 0.486492906846719, 0.470310323881684, 0.493836729797892, 0.471862689700922, 0.483682861833542, 0.499993283413205, 0.491451805748790, 0.527472846854433, 0.531212306550687, 0.521912351418626, 0.528506959171857, 0.481862977158996, 0.511451837902059, 0.551146001851058, 0.531535812411587, 0.562816435710690, 0.538185934724710, 0.547906595820886, 0.549057036591765, 0.556793598749666, 0.585769370472312, 0.522550293882819, 0.548111909406505, 0.565894445914444, 0.588465235261082, 0.594081183939944, 0.560900193504308, 0.594973301814293, 0.573088081796378, 0.558299333590956, 0.571083575443074, 0.549221745024961, 0.512552680139376, 0.570274954694715, 0.584203511642667, 0.572612700985371, 0.589734048313639, 0.581521823023612, 0.601991408635101, 0.621326307742337, 0.588438494779283, 0.598969442904663, 0.614643728953007, 0.632359850699022, 0.632679474516470, 0.610382482136730, 0.623930256162647, 0.613870669660593, 0.638882303229074, 0.662052458906153, 0.665738482772343, 0.668953424130068, 0.725668736274167, 0.696543554126922, 0.708756778541173, 0.694981934945663, 0.650371659267394, 0.699174328319907, 0.666951849954002, 0.670949580786664, 0.702584576763371, 0.698129319557636, 0.699354722383758, 0.708539548347255, 0.729217826544660, 0.726140545495770, 0.769274828068005, 0.702925896408015, 0.766899271677093, 0.755930014400832, 0.746326538076758, 0.732742558713715, 0.723366448506990, 0.754311726596288, 0.743227190460453, 0.749802367405288, 0.725872141171448, 0.798231902808409, 0.743314265694309, 0.772423878027522, 0.757578034925442, 0.764485996725121, 0.775430182166815]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label Counts:\n",
      " 1    102\n",
      "0      1\n",
      "Name: count, dtype: int64\n",
      "y_pred_actual:\n",
      " 1    80\n",
      "0    23\n",
      "Name: count, dtype: int64\n",
      "Confusion Matrix : \n",
      " [[ 0 23]\n",
      " [ 1 79]]\n",
      "Average acc, avgMcc , avg precision , AVG_SENSITIVITY, AVG_SPECIFICITY, avgBalAcc, avg f1 score \n",
      "0.769 , 0.013 , 0.77 , 0.999 , 0.004 , 0.501 , 0.869\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "# from sklearn.metrics import precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# import torch.optim as optim  \n",
    "\n",
    "file2 = open(\"File2.txt\",\"w+\")\n",
    "file3 = open(\"StorefoldRes.txt\",\"w+\")\n",
    "\n",
    "X_1=DATASET_content.values\n",
    "row1,col1=X_1.shape\n",
    "col1=col1-1\n",
    "X_1=X_1[:,1:col1]\n",
    "\n",
    "X3=df3.values\n",
    "ACC_=0\n",
    "MCC_=0\n",
    "PRE_=0\n",
    "SEN_=0\n",
    "SPE_=0\n",
    "BALN=0\n",
    "F1_=0\n",
    "\n",
    "\n",
    "for itr in range (0,1):\n",
    "        AVG_SENSITIVITY=0\n",
    "        AVG_SPECIFICITY=0 \n",
    "        AVG_PRECISION=0\n",
    "        avg_f1=0\n",
    "        avg_acc=0\n",
    "        avgMcc=0\n",
    "        \n",
    "        avgBalAcc=0\n",
    "        no_of_fold=10\n",
    "        i=1\n",
    "        kf=StratifiedKFold(n_splits=no_of_fold, random_state=22, shuffle=True)\n",
    "        # train_index and test_index are an array of indices\n",
    "        for train_index,test_index in kf.split(DATASET_no_labels,node_label):\n",
    "            \n",
    "            print(\"fold number ################################################\",i)\n",
    "            X3_train, X3_test = X3[train_index], X3[test_index]\n",
    "            y3_train, y3_test = y3[train_index], y3[test_index]\n",
    "            train_index=train_index+1\n",
    "            test_index=test_index+1\n",
    "\n",
    "\n",
    "\n",
    "            train_LABELMain, test_LABEL = node_label[train_index], node_label[test_index]\n",
    "            # get the training label index\n",
    "\n",
    "            # train_LABELMain is split into train and validation\n",
    "            train_LABEL, val_LABEL = model_selection.train_test_split(train_LABELMain, test_size=0.10, random_state=20,stratify=train_LABELMain) \n",
    "            # CNV: (931, 100) DNA: (931, 100) MRNA: (931, 150) WSI: (931, 200) Clinical: (931, 21) \n",
    "            # need to increase for cnv, dna, cln\n",
    "            # need to decrease for mrna, wsi\n",
    "            #   for cnv=====\n",
    "            str1=\"CNV\"\n",
    "            # returns the embedding of each node in test and train with the size of last layer of gcn\n",
    "            train_embd0, test_embd0=StellerGraphConvolution(train_LABELMain, train_LABEL,test_LABEL,val_LABEL,G,node_label,str1,0,i)\n",
    "            print(\"train0:\",train_embd0.shape);\n",
    "\n",
    "\n",
    "            str1=\"DNA\" \n",
    "            train_embd1, test_embd1=StellerGraphConvolution(train_LABELMain, train_LABEL,test_LABEL,val_LABEL,G1,node_label,str1,1,i)\n",
    "            print(\"train1\",train_embd1.shape);\n",
    "\n",
    "\n",
    "            str1=\"MRNA\" \n",
    "            train_embd2, test_embd2=StellerGraphConvolution(train_LABELMain, train_LABEL,test_LABEL,val_LABEL,G2,node_label,str1,2,i)\n",
    "            print(\"train2:\",train_embd2.shape);\n",
    "            str1=\"WSI\" \n",
    "            # StellerGraphConvolution(train_LABELMain, train_LABEL,test_LABEL,val_LABEL,G1,node_label,str1,2,i)\n",
    "            train_embd4, test_embd4=StellerGraphConvolution(train_LABELMain, train_LABEL,test_LABEL,val_LABEL,G2,node_label,str1,4,i)\n",
    "            print(\"train4:\",train_embd4.shape);\n",
    "\n",
    "            # add dimentionality\n",
    "            clinical_train = torch.tensor(X3_train, dtype=torch.float32)\n",
    "\n",
    "            # Linear layer to expand dimensions\n",
    "            # When you define nn.Linear(in_features, out_features) where out_features is larger than in_features, \n",
    "            # the layer learns a weight matrix with dimensions (out_features, in_features)\n",
    "            #  which allows it to map your input vector to a higher dimensional space.\n",
    "            expand_layer = nn.Linear(21, 128)\n",
    "            expanded_clinical_train = expand_layer(clinical_train).detach().numpy()\n",
    "\n",
    "            print(\"Clinical expanded shape:\", expanded_clinical_train.shape)  # (931, 128)\n",
    "\n",
    "            # test data\n",
    "            clinical_test = torch.tensor(X3_test, dtype = torch.float32);\n",
    "            expand_layer = nn.Linear(21, 128)\n",
    "            expanded_clinical_test = expand_layer(clinical_test).detach().numpy()\n",
    "\n",
    "            print(\"Clinical test expanded shape:\", expanded_clinical_test.shape)  # (931, 128)\n",
    "\n",
    "            X_train_modalities = [\n",
    "                train_embd0,\n",
    "                train_embd1,  \n",
    "                train_embd2,  \n",
    "                train_embd4,  \n",
    "                expanded_clinical_train\n",
    "            ]\n",
    "\n",
    "            # Train the multi-modal model\n",
    "            trained_model= train_multi_modal_model(X_train_modalities, y3_train)\n",
    "\n",
    "            trained_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "            with torch.no_grad():  # No need to track gradients during inference\n",
    "                X_train = trained_model.fusion(X_train_modalities) \n",
    "\n",
    "            # we want to fuse the modalities \n",
    "            # attention fusion-> not concatenate\n",
    "            # X_train = trained_model([\n",
    "            #     train_embd0,  # First modality\n",
    "            #     train_embd1,  # Second modality\n",
    "            #     train_embd2,  # Third modality\n",
    "            #     train_embd4,  # Fourth modality\n",
    "            #     expanded_clinical_train  #Fifth modality\n",
    "            # ])\n",
    "\n",
    "            X_test_modalities = [\n",
    "                test_embd0,\n",
    "                test_embd1,   # First modality\n",
    "                test_embd2,   # Second modality\n",
    "                test_embd4,   # Third modality\n",
    "                expanded_clinical_test  # Fourth modality\n",
    "            ]\n",
    "            with torch.no_grad():  # No need to track gradients during inference\n",
    "                X_test = trained_model.fusion(X_test_modalities) \n",
    "\n",
    "            # Ensemble prediction AFTER model training\n",
    "            model_predictions = ensemble_model(X_train, y3_train, X_test, y3_test)\n",
    "            model_predictions = np.array(model_predictions, dtype=float) \n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.histplot(model_predictions, bins=50, kde=True, color='blue')\n",
    "            plt.title(\"Distribution of Model Predictions\")\n",
    "            plt.xlabel(\"Prediction Value\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.show()\n",
    "\n",
    "            # Optionally, if you'd like to save the plot to a file instead of showing it:\n",
    "            # plt.savefig('model_predictions_distribution.png')\n",
    "            l=[]\n",
    "            for element in model_predictions:\n",
    "                # 0.49->61.5\n",
    "                # 0.45->71.5\n",
    "                # 0.47->69.5\n",
    "                # 0.43->73.5\n",
    "                # 0.41->76.4\n",
    "                if element >0.35:\n",
    "                    l.append(1)\n",
    "                else:\n",
    "                    l.append(0)\n",
    "                    \n",
    "            y_pred1=l\n",
    "            label_counts = pd.Series(y_pred1).value_counts()\n",
    "            print(\"Predicted Label Counts:\\n\", label_counts)\n",
    "            # print(\"ypred=\",y_pred1)\n",
    "            actual_label_counts = pd.Series(y3_test).value_counts()\n",
    "            print(\"y_pred_actual:\\n\",actual_label_counts)\n",
    "            # break\n",
    "            \n",
    "\n",
    "            cm1 = confusion_matrix(y3_test,y_pred1)\n",
    "            print('Confusion Matrix : \\n', cm1)\n",
    "\n",
    "\n",
    "            TP=cm1[1][1]\n",
    "            TN=cm1[0][0]\n",
    "            FP= cm1[0][1]\n",
    "            FN=cm1[1][0]\n",
    "\n",
    "\n",
    "            TPR = TP/(TP+FN)            \n",
    "            # Specificity or true negative rate\n",
    "            TNR = TN/(TN+FP)             \n",
    "            # Precision or positive predictive value\n",
    "            PPV = TP/(TP+FP)         \n",
    "            # # F- measure          \n",
    "            f1_value=(2*PPV*TPR)/(PPV+TPR)            \n",
    "            AVG_SENSITIVITY=AVG_SENSITIVITY+  TPR\n",
    "            AVG_SPECIFICITY=AVG_SPECIFICITY+TNR\n",
    "            AVG_PRECISION=AVG_PRECISION+ PPV\n",
    "            # balanced accuracy\n",
    "            b_ac=(TPR+TNR)/2\n",
    "            avgBalAcc=avgBalAcc+b_ac            \n",
    "            avg_f1=avg_f1+f1_value  \n",
    "            # accuracy\n",
    "            acc= (TP+TN)/(TP+FP+TN+FN)\n",
    "            avg_acc=avg_acc+acc\n",
    "            mcc=matthews_corrcoef(y3_test,y_pred1)\n",
    "            avgMcc=avgMcc+mcc        \n",
    "            i=i+1\n",
    "            # calculate score of all metices for ove \n",
    "        avg_acc=avg_acc/10\n",
    "        avg_acc = round(avg_acc, 3)\n",
    "        avgMcc=avgMcc/10\n",
    "        avgMcc = round(avgMcc, 3)\n",
    "        AVG_PRECISION=AVG_PRECISION/10\n",
    "        AVG_PRECISION = round(AVG_PRECISION, 3)\n",
    "        AVG_SENSITIVITY=AVG_SENSITIVITY/10\n",
    "        AVG_SENSITIVITY = round(AVG_SENSITIVITY, 3)\n",
    "        AVG_SPECIFICITY=AVG_SPECIFICITY/10\n",
    "        AVG_SPECIFICITY = round(AVG_SPECIFICITY, 3)\n",
    "        avgBalAcc=avgBalAcc/10\n",
    "        avgBalAcc = round(avgBalAcc, 3)\n",
    "        #AVG_PRAUC=AVG_PRAUC/10\n",
    "        avg_f1=avg_f1/10\n",
    "        avg_f1 = round(avg_f1, 3)\n",
    "\n",
    "        print(\"Average acc, avgMcc , avg precision , AVG_SENSITIVITY, AVG_SPECIFICITY, avgBalAcc, avg f1 score \")\n",
    "        print(avg_acc,\",\",avgMcc,\",\",AVG_PRECISION,\",\",AVG_SENSITIVITY,\",\",AVG_SPECIFICITY,\",\",avgBalAcc,\",\", avg_f1)  \n",
    "            # break\n",
    "        \n",
    "\n",
    "file2.close()\n",
    "file3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
